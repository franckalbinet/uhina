[
  {
    "objectID": "example/ringtrial.html",
    "href": "example/ringtrial.html",
    "title": "Ringtrial",
    "section": "",
    "text": "To do:",
    "crumbs": [
      "example",
      "Ringtrial"
    ]
  },
  {
    "objectID": "example/ringtrial.html#runpod-setup",
    "href": "example/ringtrial.html#runpod-setup",
    "title": "Ringtrial",
    "section": "Runpod setup",
    "text": "Runpod setup\n\n# setting up pod and pip install uhina\n# accessing a pod terminal\n\n# 1. To get access to the pod ip adress: runpodctl get pod -a\n# 2. ssh into the pod: ssh root@&lt;ip-address&gt; -p 58871 -i ~/.ssh/id_ed25519\n\n# git clone https://github.com/franckalbinet/uhina.git\n# pip install uhina\n# runpodctl send im-bw \n# runpodctl send ossl-tfm.csv",
    "crumbs": [
      "example",
      "Ringtrial"
    ]
  },
  {
    "objectID": "example/ringtrial.html#loading-data",
    "href": "example/ringtrial.html#loading-data",
    "title": "Ringtrial",
    "section": "Loading data",
    "text": "Loading data\n\nimport pandas as pd\nfrom pathlib import Path\nimport fastcore.all as fc\n\nfrom fastai.data.all import *\nfrom fastai.vision.all import *\nfrom multiprocessing import cpu_count\nfrom sklearn.metrics import r2_score\nfrom uhina.augment import Quantize\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\npd.set_option('display.max_rows', 100)\n\n\nsrc = '../../_data/ringtrial-tfm/im-targets-lut.csv'\ndf = pd.read_csv(src)\ndf['lab'] = df['fname'].str.split('-rt', n=1).str[0]\ndf.head()\n\n\n\n\n\n\n\n\nfname\npotassium_cmolkg\nlab\n\n\n\n\n0\nagrocares-rt-01.png\n0.26906\nagrocares\n\n\n1\nagrocares-rt-02.png\n0.23349\nagrocares\n\n\n2\nagrocares-rt-03.png\n0.29109\nagrocares\n\n\n3\nagrocares-rt-04.png\n0.49925\nagrocares\n\n\n4\nagrocares-rt-05.png\n0.59977\nagrocares\n\n\n\n\n\n\n\n\ndf['potassium_cmolkg'] = df['potassium_cmolkg'].apply(np.log1p)",
    "crumbs": [
      "example",
      "Ringtrial"
    ]
  },
  {
    "objectID": "example/ringtrial.html#fine-tuning-on-ringtrial",
    "href": "example/ringtrial.html#fine-tuning-on-ringtrial",
    "title": "Ringtrial",
    "section": "Fine-tuning on ringtrial",
    "text": "Fine-tuning on ringtrial\n\nclass OrderedQuantize(Quantize):\n    order = 0  # Apply first\n\nclass OrderedRatioResize(RatioResize):\n    order = 1  # Apply second\n\n\n# learn = load_learner('./models/650-4000-epoch-25-lr-3e-3.pkl', cpu=True)\n# learn = load_learner('./models/unfrozen-epoch-30-lr-1.5e-3-12102024.pkl', cpu=True)\n# learn = load_learner('./models/unfrozen-epoch-30-lr-1.5e-3-12102024.pkl', cpu=True)\nlearn = load_learner('./models/frozen-epoch-30-lr-1.5e-3-12102024.pkl', cpu=True)\n\n\ndf.lab.unique()\n\narray(['agrocares', 'argonne', 'csu-il', 'eth-alpha-1', 'eth-alpha-2',\n       'eth-vertex', 'iaea-aug2022', 'kssl', 'landcare', 'lesotho', 'msu',\n       'osu', 'rothamsted', 'scion', 'ughent', 'uiuc', 'usp',\n       'uwisc-fine', 'woodwell-alpha', 'woodwell-vertex'], dtype=object)\n\n\n\n# np.expm1(np.log1p(2))\ndf_selected = df[df.lab == 'kssl']\ndf_selected.head()\n\n\n\n\n\n\n\n\nfname\npotassium_cmolkg\nlab\n\n\n\n\n483\nkssl-rt-01.png\n0.238276\nkssl\n\n\n484\nkssl-rt-02.png\n0.209848\nkssl\n\n\n485\nkssl-rt-03.png\n0.255487\nkssl\n\n\n486\nkssl-rt-04.png\n0.404965\nkssl\n\n\n487\nkssl-rt-05.png\n0.469860\nkssl\n\n\n\n\n\n\n\n\n# def splitter(items): return [idx_train, idx_valid]\n  \neval_on_pretrained = False\nif eval_on_pretrained:  \n    dblock = DataBlock(\n        blocks=(ImageBlock, RegressionBlock),\n        get_x=ColReader(0, pref='../../_data/ringtrial-tfm/im/'),\n        get_y=ColReader(1),\n        # splitter=splitter,\n        splitter=RandomSplitter(valid_pct=0, seed=41),\n        item_tfms=[OrderedQuantize(n_valid=len(df_selected))],\n        batch_tfms=[\n            OrderedRatioResize(224),\n            Normalize.from_stats(*imagenet_stats)\n        ]\n    )\n    dls = dblock.dataloaders(df_selected, bs=len(df_selected))\n    val_preds, val_targets = learn.get_preds(dl=dls.train)\n    r2 = r2_score(val_targets, val_preds)\n    print(r2)\n\n\n# Eval on pre-trained model\n# eval_on_pretrained = True\n# if eval_on_pretrained:\n#     dblock = DataBlock(\n#         blocks=(ImageBlock, RegressionBlock),\n#         get_x=ColReader(0, pref='../../_data/ringtrial-tfm/im/'),\n#         get_y=ColReader(1),\n#         splitter=RandomSplitter(valid_pct=0, seed=41),\n#         batch_tfms=[RatioResize(224)],\n#         item_tfms=[Quantize(n_valid=len(df_selected))])\n\n#     dls = dblock.dataloaders(df_selected, bs=len(df_selected))\n#     val_preds, val_targets = learn.get_preds(dl=dls.train)\n#     r2 = r2_score(val_targets, val_preds)\n#     print(r2)\n\n\ndf_selected.loc[:, 'potassium_cmolkg'] = df_selected['potassium_cmolkg'].apply(np.log1p)\ndf_selected.head()\n\n\n\n\n\n\n\n\nfname\npotassium_cmolkg\nlab\n\n\n\n\n483\nkssl-rt-01.png\n0.213720\nkssl\n\n\n484\nkssl-rt-02.png\n0.190494\nkssl\n\n\n485\nkssl-rt-03.png\n0.227523\nkssl\n\n\n486\nkssl-rt-04.png\n0.340012\nkssl\n\n\n487\nkssl-rt-05.png\n0.385167\nkssl\n\n\n\n\n\n\n\n\ndf_selected\n\n\n\n\n\n\n\n\nfname\npotassium_cmolkg\nlab\n\n\n\n\n483\nkssl-rt-01.png\n0.213720\nkssl\n\n\n484\nkssl-rt-02.png\n0.190494\nkssl\n\n\n485\nkssl-rt-03.png\n0.227523\nkssl\n\n\n486\nkssl-rt-04.png\n0.340012\nkssl\n\n\n487\nkssl-rt-05.png\n0.385167\nkssl\n\n\n488\nkssl-rt-06.png\n0.402441\nkssl\n\n\n489\nkssl-rt-07.png\n0.331974\nkssl\n\n\n490\nkssl-rt-08.png\n0.101317\nkssl\n\n\n491\nkssl-rt-09.png\n0.681530\nkssl\n\n\n492\nkssl-rt-10.png\n0.274231\nkssl\n\n\n493\nkssl-rt-11.png\n0.289119\nkssl\n\n\n494\nkssl-rt-12.png\n0.256386\nkssl\n\n\n495\nkssl-rt-13.png\n0.369230\nkssl\n\n\n496\nkssl-rt-14.png\n0.191284\nkssl\n\n\n497\nkssl-rt-15.png\n0.393472\nkssl\n\n\n498\nkssl-rt-16.png\n0.508054\nkssl\n\n\n499\nkssl-rt-17.png\n0.467364\nkssl\n\n\n500\nkssl-rt-18.png\n0.308044\nkssl\n\n\n501\nkssl-rt-19.png\n0.292841\nkssl\n\n\n502\nkssl-rt-20.png\n0.294769\nkssl\n\n\n503\nkssl-rt-21.png\n0.335060\nkssl\n\n\n504\nkssl-rt-22.png\n0.079189\nkssl\n\n\n505\nkssl-rt-23.png\n0.272119\nkssl\n\n\n506\nkssl-rt-24.png\n0.160069\nkssl\n\n\n507\nkssl-rt-25.png\n0.158562\nkssl\n\n\n508\nkssl-rt-26.png\n0.144258\nkssl\n\n\n509\nkssl-rt-27.png\n0.137756\nkssl\n\n\n510\nkssl-rt-28.png\n0.516908\nkssl\n\n\n511\nkssl-rt-29.png\n0.267374\nkssl\n\n\n512\nkssl-rt-30.png\n0.301326\nkssl\n\n\n513\nkssl-rt-31.png\n0.306298\nkssl\n\n\n514\nkssl-rt-32.png\n0.291591\nkssl\n\n\n515\nkssl-rt-33.png\n0.373274\nkssl\n\n\n516\nkssl-rt-34.png\n0.100724\nkssl\n\n\n517\nkssl-rt-35.png\n0.082217\nkssl\n\n\n518\nkssl-rt-36.png\n0.142215\nkssl\n\n\n519\nkssl-rt-37.png\n0.126304\nkssl\n\n\n520\nkssl-rt-38.png\n0.045243\nkssl\n\n\n521\nkssl-rt-39.png\n0.334103\nkssl\n\n\n522\nkssl-rt-40.png\n0.515146\nkssl\n\n\n523\nkssl-rt-41.png\n0.531581\nkssl\n\n\n524\nkssl-rt-42.png\n0.351257\nkssl\n\n\n525\nkssl-rt-43.png\n0.233260\nkssl\n\n\n526\nkssl-rt-45.png\n0.271288\nkssl\n\n\n527\nkssl-rt-46.png\n0.307444\nkssl\n\n\n528\nkssl-rt-47.png\n0.256559\nkssl\n\n\n529\nkssl-rt-48.png\n0.544772\nkssl\n\n\n530\nkssl-rt-49.png\n0.366122\nkssl\n\n\n531\nkssl-rt-50.png\n0.542601\nkssl\n\n\n532\nkssl-rt-51.png\n0.547084\nkssl\n\n\n533\nkssl-rt-52.png\n0.283886\nkssl\n\n\n534\nkssl-rt-53.png\n0.337035\nkssl\n\n\n535\nkssl-rt-54.png\n0.284184\nkssl\n\n\n536\nkssl-rt-55.png\n0.306663\nkssl\n\n\n537\nkssl-rt-56.png\n0.541332\nkssl\n\n\n538\nkssl-rt-57.png\n0.548911\nkssl\n\n\n539\nkssl-rt-58.png\n0.551454\nkssl\n\n\n540\nkssl-rt-59.png\n0.380625\nkssl\n\n\n541\nkssl-rt-60.png\n0.462484\nkssl\n\n\n542\nkssl-rt-61.png\n0.379143\nkssl\n\n\n543\nkssl-rt-62.png\n0.223065\nkssl\n\n\n544\nkssl-rt-63.png\n0.223065\nkssl\n\n\n545\nkssl-rt-64.png\n0.131506\nkssl\n\n\n546\nkssl-rt-65.png\n0.226245\nkssl\n\n\n547\nkssl-rt-66.png\n0.852376\nkssl\n\n\n548\nkssl-rt-67.png\n0.619430\nkssl\n\n\n549\nkssl-rt-68.png\n0.486798\nkssl\n\n\n550\nkssl-rt-69.png\n0.519743\nkssl\n\n\n551\nkssl-rt-70.png\n0.551429\nkssl\n\n\n\n\n\n\n\n\ndf_selected['potassium_cmolkg'].hist()\n\n\n\n\n\n\n\n\n\nTrain/valid/test split\n\nUsing Kennard-Stone\n\ndf.lab.unique()\n\narray(['agrocares', 'argonne', 'csu-il', 'eth-alpha-1', 'eth-alpha-2',\n       'eth-vertex', 'iaea-aug2022', 'kssl', 'landcare', 'lesotho', 'msu',\n       'osu', 'rothamsted', 'scion', 'ughent', 'uiuc', 'usp',\n       'uwisc-fine', 'woodwell-alpha', 'woodwell-vertex'], dtype=object)\n\n\n\ndf_selected = df[df.lab == 'kssl']\n\n\nlen(df_selected)\n\n69\n\n\n\nfrom uhina.loading import LoaderFactory\n\nsrc = Path.home() / 'pro/data/woodwell-ringtrial/drive-download-20231013T123706Z-001'\nloader = LoaderFactory.get_loader(src, 'ringtrial')\ndata = loader.load_data(analytes='potassium_cmolkg')\nprint(f'X shape: {data.X.shape}')\n\nX shape: (1400, 1676)\n\n\n\n# 44 is missing\nindices_df = [name.split('.png')[0] for name in df_selected.fname]; indices_df\n\n['kssl-rt-01',\n 'kssl-rt-02',\n 'kssl-rt-03',\n 'kssl-rt-04',\n 'kssl-rt-05',\n 'kssl-rt-06',\n 'kssl-rt-07',\n 'kssl-rt-08',\n 'kssl-rt-09',\n 'kssl-rt-10',\n 'kssl-rt-11',\n 'kssl-rt-12',\n 'kssl-rt-13',\n 'kssl-rt-14',\n 'kssl-rt-15',\n 'kssl-rt-16',\n 'kssl-rt-17',\n 'kssl-rt-18',\n 'kssl-rt-19',\n 'kssl-rt-20',\n 'kssl-rt-21',\n 'kssl-rt-22',\n 'kssl-rt-23',\n 'kssl-rt-24',\n 'kssl-rt-25',\n 'kssl-rt-26',\n 'kssl-rt-27',\n 'kssl-rt-28',\n 'kssl-rt-29',\n 'kssl-rt-30',\n 'kssl-rt-31',\n 'kssl-rt-32',\n 'kssl-rt-33',\n 'kssl-rt-34',\n 'kssl-rt-35',\n 'kssl-rt-36',\n 'kssl-rt-37',\n 'kssl-rt-38',\n 'kssl-rt-39',\n 'kssl-rt-40',\n 'kssl-rt-41',\n 'kssl-rt-42',\n 'kssl-rt-43',\n 'kssl-rt-45',\n 'kssl-rt-46',\n 'kssl-rt-47',\n 'kssl-rt-48',\n 'kssl-rt-49',\n 'kssl-rt-50',\n 'kssl-rt-51',\n 'kssl-rt-52',\n 'kssl-rt-53',\n 'kssl-rt-54',\n 'kssl-rt-55',\n 'kssl-rt-56',\n 'kssl-rt-57',\n 'kssl-rt-58',\n 'kssl-rt-59',\n 'kssl-rt-60',\n 'kssl-rt-61',\n 'kssl-rt-62',\n 'kssl-rt-63',\n 'kssl-rt-64',\n 'kssl-rt-65',\n 'kssl-rt-66',\n 'kssl-rt-67',\n 'kssl-rt-68',\n 'kssl-rt-69',\n 'kssl-rt-70']\n\n\n\nmask = np.isin(data.sample_indices, np.array(indices_df))\n\n\ndata.sample_indices[mask]\n\narray(['kssl-rt-01', 'kssl-rt-02', 'kssl-rt-03', 'kssl-rt-04',\n       'kssl-rt-05', 'kssl-rt-06', 'kssl-rt-07', 'kssl-rt-08',\n       'kssl-rt-09', 'kssl-rt-10', 'kssl-rt-11', 'kssl-rt-12',\n       'kssl-rt-13', 'kssl-rt-14', 'kssl-rt-15', 'kssl-rt-16',\n       'kssl-rt-17', 'kssl-rt-18', 'kssl-rt-19', 'kssl-rt-20',\n       'kssl-rt-21', 'kssl-rt-22', 'kssl-rt-23', 'kssl-rt-24',\n       'kssl-rt-25', 'kssl-rt-26', 'kssl-rt-27', 'kssl-rt-28',\n       'kssl-rt-29', 'kssl-rt-30', 'kssl-rt-31', 'kssl-rt-32',\n       'kssl-rt-33', 'kssl-rt-34', 'kssl-rt-35', 'kssl-rt-36',\n       'kssl-rt-37', 'kssl-rt-38', 'kssl-rt-39', 'kssl-rt-40',\n       'kssl-rt-41', 'kssl-rt-42', 'kssl-rt-43', 'kssl-rt-45',\n       'kssl-rt-46', 'kssl-rt-47', 'kssl-rt-48', 'kssl-rt-49',\n       'kssl-rt-50', 'kssl-rt-51', 'kssl-rt-52', 'kssl-rt-53',\n       'kssl-rt-54', 'kssl-rt-55', 'kssl-rt-56', 'kssl-rt-57',\n       'kssl-rt-58', 'kssl-rt-59', 'kssl-rt-60', 'kssl-rt-61',\n       'kssl-rt-62', 'kssl-rt-63', 'kssl-rt-64', 'kssl-rt-65',\n       'kssl-rt-66', 'kssl-rt-67', 'kssl-rt-68', 'kssl-rt-69',\n       'kssl-rt-70'], dtype=object)\n\n\n\ndata.sample_indices[mask]\n\narray(['kssl-rt-01', 'kssl-rt-02', 'kssl-rt-03', 'kssl-rt-04',\n       'kssl-rt-05', 'kssl-rt-06', 'kssl-rt-07', 'kssl-rt-08',\n       'kssl-rt-09', 'kssl-rt-10', 'kssl-rt-11', 'kssl-rt-12',\n       'kssl-rt-13', 'kssl-rt-14', 'kssl-rt-15', 'kssl-rt-16',\n       'kssl-rt-17', 'kssl-rt-18', 'kssl-rt-19', 'kssl-rt-20',\n       'kssl-rt-21', 'kssl-rt-22', 'kssl-rt-23', 'kssl-rt-24',\n       'kssl-rt-25', 'kssl-rt-26', 'kssl-rt-27', 'kssl-rt-28',\n       'kssl-rt-29', 'kssl-rt-30', 'kssl-rt-31', 'kssl-rt-32',\n       'kssl-rt-33', 'kssl-rt-34', 'kssl-rt-35', 'kssl-rt-36',\n       'kssl-rt-37', 'kssl-rt-38', 'kssl-rt-39', 'kssl-rt-40',\n       'kssl-rt-41', 'kssl-rt-42', 'kssl-rt-43', 'kssl-rt-45',\n       'kssl-rt-46', 'kssl-rt-47', 'kssl-rt-48', 'kssl-rt-49',\n       'kssl-rt-50', 'kssl-rt-51', 'kssl-rt-52', 'kssl-rt-53',\n       'kssl-rt-54', 'kssl-rt-55', 'kssl-rt-56', 'kssl-rt-57',\n       'kssl-rt-58', 'kssl-rt-59', 'kssl-rt-60', 'kssl-rt-61',\n       'kssl-rt-62', 'kssl-rt-63', 'kssl-rt-64', 'kssl-rt-65',\n       'kssl-rt-66', 'kssl-rt-67', 'kssl-rt-68', 'kssl-rt-69',\n       'kssl-rt-70'], dtype=object)\n\n\n\ndf_selected.reset_index(inplace=True, drop=True)\n\n\ndata.sample_indices[mask]\n\narray(['kssl-rt-01', 'kssl-rt-02', 'kssl-rt-03', 'kssl-rt-04',\n       'kssl-rt-05', 'kssl-rt-06', 'kssl-rt-07', 'kssl-rt-08',\n       'kssl-rt-09', 'kssl-rt-10', 'kssl-rt-11', 'kssl-rt-12',\n       'kssl-rt-13', 'kssl-rt-14', 'kssl-rt-15', 'kssl-rt-16',\n       'kssl-rt-17', 'kssl-rt-18', 'kssl-rt-19', 'kssl-rt-20',\n       'kssl-rt-21', 'kssl-rt-22', 'kssl-rt-23', 'kssl-rt-24',\n       'kssl-rt-25', 'kssl-rt-26', 'kssl-rt-27', 'kssl-rt-28',\n       'kssl-rt-29', 'kssl-rt-30', 'kssl-rt-31', 'kssl-rt-32',\n       'kssl-rt-33', 'kssl-rt-34', 'kssl-rt-35', 'kssl-rt-36',\n       'kssl-rt-37', 'kssl-rt-38', 'kssl-rt-39', 'kssl-rt-40',\n       'kssl-rt-41', 'kssl-rt-42', 'kssl-rt-43', 'kssl-rt-45',\n       'kssl-rt-46', 'kssl-rt-47', 'kssl-rt-48', 'kssl-rt-49',\n       'kssl-rt-50', 'kssl-rt-51', 'kssl-rt-52', 'kssl-rt-53',\n       'kssl-rt-54', 'kssl-rt-55', 'kssl-rt-56', 'kssl-rt-57',\n       'kssl-rt-58', 'kssl-rt-59', 'kssl-rt-60', 'kssl-rt-61',\n       'kssl-rt-62', 'kssl-rt-63', 'kssl-rt-64', 'kssl-rt-65',\n       'kssl-rt-66', 'kssl-rt-67', 'kssl-rt-68', 'kssl-rt-69',\n       'kssl-rt-70'], dtype=object)\n\n\n\n# mask = np.char.find(data.sample_indices.astype(str), 'kssl') != -1\nX_lab, y_lab = data.X[mask], np.log1p(data.y[mask])\n\n\ndata.sample_indices[mask]\n\narray(['kssl-rt-01', 'kssl-rt-02', 'kssl-rt-03', 'kssl-rt-04',\n       'kssl-rt-05', 'kssl-rt-06', 'kssl-rt-07', 'kssl-rt-08',\n       'kssl-rt-09', 'kssl-rt-10', 'kssl-rt-11', 'kssl-rt-12',\n       'kssl-rt-13', 'kssl-rt-14', 'kssl-rt-15', 'kssl-rt-16',\n       'kssl-rt-17', 'kssl-rt-18', 'kssl-rt-19', 'kssl-rt-20',\n       'kssl-rt-21', 'kssl-rt-22', 'kssl-rt-23', 'kssl-rt-24',\n       'kssl-rt-25', 'kssl-rt-26', 'kssl-rt-27', 'kssl-rt-28',\n       'kssl-rt-29', 'kssl-rt-30', 'kssl-rt-31', 'kssl-rt-32',\n       'kssl-rt-33', 'kssl-rt-34', 'kssl-rt-35', 'kssl-rt-36',\n       'kssl-rt-37', 'kssl-rt-38', 'kssl-rt-39', 'kssl-rt-40',\n       'kssl-rt-41', 'kssl-rt-42', 'kssl-rt-43', 'kssl-rt-45',\n       'kssl-rt-46', 'kssl-rt-47', 'kssl-rt-48', 'kssl-rt-49',\n       'kssl-rt-50', 'kssl-rt-51', 'kssl-rt-52', 'kssl-rt-53',\n       'kssl-rt-54', 'kssl-rt-55', 'kssl-rt-56', 'kssl-rt-57',\n       'kssl-rt-58', 'kssl-rt-59', 'kssl-rt-60', 'kssl-rt-61',\n       'kssl-rt-62', 'kssl-rt-63', 'kssl-rt-64', 'kssl-rt-65',\n       'kssl-rt-66', 'kssl-rt-67', 'kssl-rt-68', 'kssl-rt-69',\n       'kssl-rt-70'], dtype=object)\n\n\n\ndf_selected\n\n\n\n\n\n\n\n\nfname\npotassium_cmolkg\nlab\n\n\n\n\n0\nkssl-rt-01.png\n0.238276\nkssl\n\n\n1\nkssl-rt-02.png\n0.209848\nkssl\n\n\n2\nkssl-rt-03.png\n0.255487\nkssl\n\n\n3\nkssl-rt-04.png\n0.404965\nkssl\n\n\n4\nkssl-rt-05.png\n0.469860\nkssl\n\n\n5\nkssl-rt-06.png\n0.495470\nkssl\n\n\n6\nkssl-rt-07.png\n0.393716\nkssl\n\n\n7\nkssl-rt-08.png\n0.106628\nkssl\n\n\n8\nkssl-rt-09.png\n0.976900\nkssl\n\n\n9\nkssl-rt-10.png\n0.315519\nkssl\n\n\n10\nkssl-rt-11.png\n0.335250\nkssl\n\n\n11\nkssl-rt-12.png\n0.292252\nkssl\n\n\n12\nkssl-rt-13.png\n0.446620\nkssl\n\n\n13\nkssl-rt-14.png\n0.210804\nkssl\n\n\n14\nkssl-rt-15.png\n0.482117\nkssl\n\n\n15\nkssl-rt-16.png\n0.662054\nkssl\n\n\n16\nkssl-rt-17.png\n0.595782\nkssl\n\n\n17\nkssl-rt-18.png\n0.360761\nkssl\n\n\n18\nkssl-rt-19.png\n0.340229\nkssl\n\n\n19\nkssl-rt-20.png\n0.342816\nkssl\n\n\n20\nkssl-rt-21.png\n0.398024\nkssl\n\n\n21\nkssl-rt-22.png\n0.082409\nkssl\n\n\n22\nkssl-rt-23.png\n0.312743\nkssl\n\n\n23\nkssl-rt-24.png\n0.173592\nkssl\n\n\n24\nkssl-rt-25.png\n0.171825\nkssl\n\n\n25\nkssl-rt-26.png\n0.155182\nkssl\n\n\n26\nkssl-rt-27.png\n0.147696\nkssl\n\n\n27\nkssl-rt-28.png\n0.676835\nkssl\n\n\n28\nkssl-rt-29.png\n0.306528\nkssl\n\n\n29\nkssl-rt-30.png\n0.351649\nkssl\n\n\n30\nkssl-rt-31.png\n0.358387\nkssl\n\n\n31\nkssl-rt-32.png\n0.338556\nkssl\n\n\n32\nkssl-rt-33.png\n0.452482\nkssl\n\n\n33\nkssl-rt-34.png\n0.105971\nkssl\n\n\n34\nkssl-rt-35.png\n0.085691\nkssl\n\n\n35\nkssl-rt-36.png\n0.152824\nkssl\n\n\n36\nkssl-rt-37.png\n0.134627\nkssl\n\n\n37\nkssl-rt-38.png\n0.046282\nkssl\n\n\n38\nkssl-rt-39.png\n0.396687\nkssl\n\n\n39\nkssl-rt-40.png\n0.673883\nkssl\n\n\n40\nkssl-rt-41.png\n0.701621\nkssl\n\n\n41\nkssl-rt-42.png\n0.420853\nkssl\n\n\n42\nkssl-rt-43.png\n0.262710\nkssl\n\n\n43\nkssl-rt-45.png\n0.311652\nkssl\n\n\n44\nkssl-rt-46.png\n0.359945\nkssl\n\n\n45\nkssl-rt-47.png\n0.292476\nkssl\n\n\n46\nkssl-rt-48.png\n0.724215\nkssl\n\n\n47\nkssl-rt-49.png\n0.442131\nkssl\n\n\n48\nkssl-rt-50.png\n0.720475\nkssl\n\n\n49\nkssl-rt-51.png\n0.728205\nkssl\n\n\n50\nkssl-rt-52.png\n0.328282\nkssl\n\n\n51\nkssl-rt-53.png\n0.400788\nkssl\n\n\n52\nkssl-rt-54.png\n0.328678\nkssl\n\n\n53\nkssl-rt-55.png\n0.358884\nkssl\n\n\n54\nkssl-rt-56.png\n0.718293\nkssl\n\n\n55\nkssl-rt-57.png\n0.731367\nkssl\n\n\n56\nkssl-rt-58.png\n0.735776\nkssl\n\n\n57\nkssl-rt-59.png\n0.463199\nkssl\n\n\n58\nkssl-rt-60.png\n0.588014\nkssl\n\n\n59\nkssl-rt-61.png\n0.461032\nkssl\n\n\n60\nkssl-rt-62.png\n0.249902\nkssl\n\n\n61\nkssl-rt-63.png\n0.249902\nkssl\n\n\n62\nkssl-rt-64.png\n0.140544\nkssl\n\n\n63\nkssl-rt-65.png\n0.253882\nkssl\n\n\n64\nkssl-rt-66.png\n1.345212\nkssl\n\n\n65\nkssl-rt-67.png\n0.857869\nkssl\n\n\n66\nkssl-rt-68.png\n0.627098\nkssl\n\n\n67\nkssl-rt-69.png\n0.681596\nkssl\n\n\n68\nkssl-rt-70.png\n0.735732\nkssl\n\n\n\n\n\n\n\n\nX_lab\n\narray([[1.2708 , 1.26602, 1.26191, ..., 0.15597, 0.15574, 0.15549],\n       [1.68078, 1.69329, 1.70438, ..., 0.22922, 0.22891, 0.22859],\n       [1.69767, 1.69935, 1.70112, ..., 0.38133, 0.38056, 0.3798 ],\n       ...,\n       [1.65483, 1.65777, 1.6626 , ..., 0.22134, 0.22078, 0.2202 ],\n       [1.86684, 1.86213, 1.85727, ..., 0.14837, 0.14783, 0.14725],\n       [1.62302, 1.62296, 1.62328, ..., 0.2393 , 0.23909, 0.23888]])\n\n\n\nfrom uhina.preprocessing import SNV, TakeDerivative\nfrom sklearn.pipeline import Pipeline\n\npipe = Pipeline([\n    ('SNV', SNV()),\n    ('Derivative', TakeDerivative())\n])\n\nX_lab_trans = pipe.fit_transform(X_lab)\n\n\ndf_selected\n\n\n\n\n\n\n\n\nfname\npotassium_cmolkg\nlab\n\n\n\n\n0\nkssl-rt-01.png\n0.238276\nkssl\n\n\n1\nkssl-rt-02.png\n0.209848\nkssl\n\n\n2\nkssl-rt-03.png\n0.255487\nkssl\n\n\n3\nkssl-rt-04.png\n0.404965\nkssl\n\n\n4\nkssl-rt-05.png\n0.469860\nkssl\n\n\n5\nkssl-rt-06.png\n0.495470\nkssl\n\n\n6\nkssl-rt-07.png\n0.393716\nkssl\n\n\n7\nkssl-rt-08.png\n0.106628\nkssl\n\n\n8\nkssl-rt-09.png\n0.976900\nkssl\n\n\n9\nkssl-rt-10.png\n0.315519\nkssl\n\n\n10\nkssl-rt-11.png\n0.335250\nkssl\n\n\n11\nkssl-rt-12.png\n0.292252\nkssl\n\n\n12\nkssl-rt-13.png\n0.446620\nkssl\n\n\n13\nkssl-rt-14.png\n0.210804\nkssl\n\n\n14\nkssl-rt-15.png\n0.482117\nkssl\n\n\n15\nkssl-rt-16.png\n0.662054\nkssl\n\n\n16\nkssl-rt-17.png\n0.595782\nkssl\n\n\n17\nkssl-rt-18.png\n0.360761\nkssl\n\n\n18\nkssl-rt-19.png\n0.340229\nkssl\n\n\n19\nkssl-rt-20.png\n0.342816\nkssl\n\n\n20\nkssl-rt-21.png\n0.398024\nkssl\n\n\n21\nkssl-rt-22.png\n0.082409\nkssl\n\n\n22\nkssl-rt-23.png\n0.312743\nkssl\n\n\n23\nkssl-rt-24.png\n0.173592\nkssl\n\n\n24\nkssl-rt-25.png\n0.171825\nkssl\n\n\n25\nkssl-rt-26.png\n0.155182\nkssl\n\n\n26\nkssl-rt-27.png\n0.147696\nkssl\n\n\n27\nkssl-rt-28.png\n0.676835\nkssl\n\n\n28\nkssl-rt-29.png\n0.306528\nkssl\n\n\n29\nkssl-rt-30.png\n0.351649\nkssl\n\n\n30\nkssl-rt-31.png\n0.358387\nkssl\n\n\n31\nkssl-rt-32.png\n0.338556\nkssl\n\n\n32\nkssl-rt-33.png\n0.452482\nkssl\n\n\n33\nkssl-rt-34.png\n0.105971\nkssl\n\n\n34\nkssl-rt-35.png\n0.085691\nkssl\n\n\n35\nkssl-rt-36.png\n0.152824\nkssl\n\n\n36\nkssl-rt-37.png\n0.134627\nkssl\n\n\n37\nkssl-rt-38.png\n0.046282\nkssl\n\n\n38\nkssl-rt-39.png\n0.396687\nkssl\n\n\n39\nkssl-rt-40.png\n0.673883\nkssl\n\n\n40\nkssl-rt-41.png\n0.701621\nkssl\n\n\n41\nkssl-rt-42.png\n0.420853\nkssl\n\n\n42\nkssl-rt-43.png\n0.262710\nkssl\n\n\n43\nkssl-rt-45.png\n0.311652\nkssl\n\n\n44\nkssl-rt-46.png\n0.359945\nkssl\n\n\n45\nkssl-rt-47.png\n0.292476\nkssl\n\n\n46\nkssl-rt-48.png\n0.724215\nkssl\n\n\n47\nkssl-rt-49.png\n0.442131\nkssl\n\n\n48\nkssl-rt-50.png\n0.720475\nkssl\n\n\n49\nkssl-rt-51.png\n0.728205\nkssl\n\n\n50\nkssl-rt-52.png\n0.328282\nkssl\n\n\n51\nkssl-rt-53.png\n0.400788\nkssl\n\n\n52\nkssl-rt-54.png\n0.328678\nkssl\n\n\n53\nkssl-rt-55.png\n0.358884\nkssl\n\n\n54\nkssl-rt-56.png\n0.718293\nkssl\n\n\n55\nkssl-rt-57.png\n0.731367\nkssl\n\n\n56\nkssl-rt-58.png\n0.735776\nkssl\n\n\n57\nkssl-rt-59.png\n0.463199\nkssl\n\n\n58\nkssl-rt-60.png\n0.588014\nkssl\n\n\n59\nkssl-rt-61.png\n0.461032\nkssl\n\n\n60\nkssl-rt-62.png\n0.249902\nkssl\n\n\n61\nkssl-rt-63.png\n0.249902\nkssl\n\n\n62\nkssl-rt-64.png\n0.140544\nkssl\n\n\n63\nkssl-rt-65.png\n0.253882\nkssl\n\n\n64\nkssl-rt-66.png\n1.345212\nkssl\n\n\n65\nkssl-rt-67.png\n0.857869\nkssl\n\n\n66\nkssl-rt-68.png\n0.627098\nkssl\n\n\n67\nkssl-rt-69.png\n0.681596\nkssl\n\n\n68\nkssl-rt-70.png\n0.735732\nkssl\n\n\n\n\n\n\n\n\nX_lab_trans.shape\n\n(69, 1676)\n\n\n\nimport kennard_stone as ks\n\n# train_idx, valid_idx, X_train, X_valid = ks.train_test_split(np.array(range(len(X_lab_trans))).reshape(-1, 1), \n#                                                              X_lab_trans, test_size = 0.2)\n\n# train_idx = train_idx.ravel()\n# valid_idx = valid_idx.ravel()\nX_train, X_valid, train_idx, valid_idx = ks.train_test_split(X_lab_trans, \n                                                             range(len(X_lab_trans)), \n                                                             test_size = 0.2)\n\nCalculating pairwise distances using scikit-learn.\nCalculating pairwise distances using scikit-learn.\n\n\n\nvalid_idx\n\n[35, 6, 24, 12, 3, 31, 30, 5, 2, 25, 49, 28, 44, 40]\n\n\n\ndf_selected.loc[train_idx, :]['potassium_cmolkg'].hist()\n\n\n\n\n\n\n\n\n\ndf_selected.loc[valid_idx, :]['potassium_cmolkg'].hist()\n\n\n\n\n\n\n\n\n\nfrom sklearn.cross_decomposition import PLSRegression\nscores = []\nfor n in range(1,20):\n    pls = PLSRegression(n_components=n)\n    pls.fit(X_lab_trans[train_idx], y_lab[train_idx])\n    y_predicted = pls.predict(X_lab_trans[valid_idx])\n    print(n, r2_score(y_predicted, y_lab[valid_idx]))\n    scores.append(r2_score(y_predicted, y_lab[valid_idx]))\n\nplt.plot(range(1, 20), scores)\n\n1 0.9167139331659132\n2 0.8169940843443368\n3 0.8201480463134329\n4 0.8330463354402591\n5 0.8336164418584839\n6 0.8066819139016866\n7 0.8063689082131712\n8 0.8476483270390328\n9 0.8442719648387733\n10 0.8550880328401899\n11 0.85550155049048\n12 0.8773457853046793\n13 0.8640833529184554\n14 0.8467865332449903\n15 0.8598890265246808\n16 0.860227416062531\n17 0.8890976617393181\n18 0.8975066928044428\n19 0.9022963785020354\n\n\n\n\n\n\n\n\n\n\npls = PLSRegression(n_components=1)\npls.fit(X_lab_trans[train_idx], np.log1p(data.y[mask][train_idx]))\ny_predicted = pls.predict(X_lab_trans[valid_idx])\n\n\nx, y = y_predicted, np.log1p(data.y[mask][valid_idx])\nplt.plot(x, y, '.')\n# Add the diagonal line\nmin_val = min(y.min(), x.min())\nmax_val = max(y.max(), x.max())\nplt.plot([min_val, max_val], [min_val, max_val], 'k--', lw=1)\n\n\n\n\n\n\n\n\n\n# dblock = DataBlock(blocks=(ImageBlock, RegressionBlock),\n#                    get_x=ColReader(0, pref='../../_data/ringtrial-tfm/im/'),\n#                    get_y=ColReader(1),\n#                    splitter=RandomSplitter(valid_pct=0, seed=41),\n#                    batch_tfms=[RatioResize(224)],\n#                    item_tfms=[Quantize()])\n\n\n# class ModelEvaluator:\n#     def __init__(self, model_path, dblock):\n#         self.learn = load_learner(model_path, cpu=True)\n#         self.dblock = dblock\n\n#     def evaluate(self, df_selected, batch_size=16, use_tta=False, tta_n=4):\n#         dls = self.dblock.dataloaders(df_selected, bs=batch_size)\n#         if use_tta:\n#             val_preds, val_targets = self.learn.tta(dl=dls.train, n=tta_n)\n#         else:\n#             val_preds, val_targets = self.learn.get_preds(dl=dls.train)\n        \n#         r2 = r2_score(val_targets, val_preds)\n#         return val_preds, val_targets, r2\n\n\n# model_path = './models/650-4000-epoch-25-lr-3e-3.pkl'\n# evaluator = ModelEvaluator(model_path, dblock)\n\n\nlen(train_idx), len(valid_idx)\n\n(55, 14)\n\n\n\ndef has_common_elements(list1, list2): return bool(set(list1) & set(list2))\nfc.test_eq(has_common_elements(train_idx, valid_idx), False)\n\n\ndf_selected\n\n\n\n\n\n\n\n\nfname\npotassium_cmolkg\nlab\n\n\n\n\n0\neth-alpha-1-rt-01.png\n0.238276\neth-alpha-1\n\n\n1\neth-alpha-1-rt-02.png\n0.209848\neth-alpha-1\n\n\n2\neth-alpha-1-rt-03.png\n0.255487\neth-alpha-1\n\n\n3\neth-alpha-1-rt-04.png\n0.404965\neth-alpha-1\n\n\n4\neth-alpha-1-rt-05.png\n0.469860\neth-alpha-1\n\n\n5\neth-alpha-1-rt-06.png\n0.495470\neth-alpha-1\n\n\n6\neth-alpha-1-rt-07.png\n0.393716\neth-alpha-1\n\n\n7\neth-alpha-1-rt-08.png\n0.106628\neth-alpha-1\n\n\n8\neth-alpha-1-rt-09.png\n0.976900\neth-alpha-1\n\n\n9\neth-alpha-1-rt-10.png\n0.315519\neth-alpha-1\n\n\n10\neth-alpha-1-rt-11.png\n0.335250\neth-alpha-1\n\n\n11\neth-alpha-1-rt-12.png\n0.292252\neth-alpha-1\n\n\n12\neth-alpha-1-rt-13.png\n0.446620\neth-alpha-1\n\n\n13\neth-alpha-1-rt-14.png\n0.210804\neth-alpha-1\n\n\n14\neth-alpha-1-rt-15.png\n0.482117\neth-alpha-1\n\n\n15\neth-alpha-1-rt-16.png\n0.662054\neth-alpha-1\n\n\n16\neth-alpha-1-rt-17.png\n0.595782\neth-alpha-1\n\n\n17\neth-alpha-1-rt-18.png\n0.360761\neth-alpha-1\n\n\n18\neth-alpha-1-rt-19.png\n0.340229\neth-alpha-1\n\n\n19\neth-alpha-1-rt-20.png\n0.342816\neth-alpha-1\n\n\n20\neth-alpha-1-rt-21.png\n0.398024\neth-alpha-1\n\n\n21\neth-alpha-1-rt-22.png\n0.082409\neth-alpha-1\n\n\n22\neth-alpha-1-rt-23.png\n0.312743\neth-alpha-1\n\n\n23\neth-alpha-1-rt-24.png\n0.173592\neth-alpha-1\n\n\n24\neth-alpha-1-rt-25.png\n0.171825\neth-alpha-1\n\n\n25\neth-alpha-1-rt-26.png\n0.155182\neth-alpha-1\n\n\n26\neth-alpha-1-rt-27.png\n0.147696\neth-alpha-1\n\n\n27\neth-alpha-1-rt-28.png\n0.676835\neth-alpha-1\n\n\n28\neth-alpha-1-rt-29.png\n0.306528\neth-alpha-1\n\n\n29\neth-alpha-1-rt-30.png\n0.351649\neth-alpha-1\n\n\n30\neth-alpha-1-rt-31.png\n0.358387\neth-alpha-1\n\n\n31\neth-alpha-1-rt-32.png\n0.338556\neth-alpha-1\n\n\n32\neth-alpha-1-rt-33.png\n0.452482\neth-alpha-1\n\n\n33\neth-alpha-1-rt-34.png\n0.105971\neth-alpha-1\n\n\n34\neth-alpha-1-rt-35.png\n0.085691\neth-alpha-1\n\n\n35\neth-alpha-1-rt-36.png\n0.152824\neth-alpha-1\n\n\n36\neth-alpha-1-rt-37.png\n0.134627\neth-alpha-1\n\n\n37\neth-alpha-1-rt-38.png\n0.046282\neth-alpha-1\n\n\n38\neth-alpha-1-rt-39.png\n0.396687\neth-alpha-1\n\n\n39\neth-alpha-1-rt-40.png\n0.673883\neth-alpha-1\n\n\n40\neth-alpha-1-rt-41.png\n0.701621\neth-alpha-1\n\n\n41\neth-alpha-1-rt-42.png\n0.420853\neth-alpha-1\n\n\n42\neth-alpha-1-rt-43.png\n0.262710\neth-alpha-1\n\n\n43\neth-alpha-1-rt-45.png\n0.311652\neth-alpha-1\n\n\n44\neth-alpha-1-rt-46.png\n0.359945\neth-alpha-1\n\n\n45\neth-alpha-1-rt-47.png\n0.292476\neth-alpha-1\n\n\n46\neth-alpha-1-rt-48.png\n0.724215\neth-alpha-1\n\n\n47\neth-alpha-1-rt-49.png\n0.442131\neth-alpha-1\n\n\n48\neth-alpha-1-rt-50.png\n0.720475\neth-alpha-1\n\n\n49\neth-alpha-1-rt-51.png\n0.728205\neth-alpha-1\n\n\n50\neth-alpha-1-rt-52.png\n0.328282\neth-alpha-1\n\n\n51\neth-alpha-1-rt-53.png\n0.400788\neth-alpha-1\n\n\n52\neth-alpha-1-rt-54.png\n0.328678\neth-alpha-1\n\n\n53\neth-alpha-1-rt-55.png\n0.358884\neth-alpha-1\n\n\n54\neth-alpha-1-rt-56.png\n0.718293\neth-alpha-1\n\n\n55\neth-alpha-1-rt-57.png\n0.731367\neth-alpha-1\n\n\n56\neth-alpha-1-rt-58.png\n0.735776\neth-alpha-1\n\n\n57\neth-alpha-1-rt-59.png\n0.463199\neth-alpha-1\n\n\n58\neth-alpha-1-rt-60.png\n0.588014\neth-alpha-1\n\n\n59\neth-alpha-1-rt-61.png\n0.461032\neth-alpha-1\n\n\n60\neth-alpha-1-rt-62.png\n0.249902\neth-alpha-1\n\n\n61\neth-alpha-1-rt-63.png\n0.249902\neth-alpha-1\n\n\n62\neth-alpha-1-rt-64.png\n0.140544\neth-alpha-1\n\n\n63\neth-alpha-1-rt-65.png\n0.253882\neth-alpha-1\n\n\n64\neth-alpha-1-rt-66.png\n1.345212\neth-alpha-1\n\n\n65\neth-alpha-1-rt-67.png\n0.857869\neth-alpha-1\n\n\n66\neth-alpha-1-rt-68.png\n0.627098\neth-alpha-1\n\n\n67\neth-alpha-1-rt-69.png\n0.681596\neth-alpha-1\n\n\n68\neth-alpha-1-rt-70.png\n0.735732\neth-alpha-1\n\n\n\n\n\n\n\n\ndf_selected.loc[train_idx, :]\n\n\n\n\n\n\n\n\nfname\npotassium_cmolkg\nlab\n\n\n\n\n15\neth-alpha-1-rt-16.png\n0.662054\neth-alpha-1\n\n\n16\neth-alpha-1-rt-17.png\n0.595782\neth-alpha-1\n\n\n46\neth-alpha-1-rt-48.png\n0.724215\neth-alpha-1\n\n\n49\neth-alpha-1-rt-51.png\n0.728205\neth-alpha-1\n\n\n48\neth-alpha-1-rt-50.png\n0.720475\neth-alpha-1\n\n\n59\neth-alpha-1-rt-61.png\n0.461032\neth-alpha-1\n\n\n47\neth-alpha-1-rt-49.png\n0.442131\neth-alpha-1\n\n\n54\neth-alpha-1-rt-56.png\n0.718293\neth-alpha-1\n\n\n39\neth-alpha-1-rt-40.png\n0.673883\neth-alpha-1\n\n\n36\neth-alpha-1-rt-37.png\n0.134627\neth-alpha-1\n\n\n55\neth-alpha-1-rt-57.png\n0.731367\neth-alpha-1\n\n\n53\neth-alpha-1-rt-55.png\n0.358884\neth-alpha-1\n\n\n56\neth-alpha-1-rt-58.png\n0.735776\neth-alpha-1\n\n\n7\neth-alpha-1-rt-08.png\n0.106628\neth-alpha-1\n\n\n30\neth-alpha-1-rt-31.png\n0.358387\neth-alpha-1\n\n\n61\neth-alpha-1-rt-63.png\n0.249902\neth-alpha-1\n\n\n45\neth-alpha-1-rt-47.png\n0.292476\neth-alpha-1\n\n\n52\neth-alpha-1-rt-54.png\n0.328678\neth-alpha-1\n\n\n37\neth-alpha-1-rt-38.png\n0.046282\neth-alpha-1\n\n\n51\neth-alpha-1-rt-53.png\n0.400788\neth-alpha-1\n\n\n44\neth-alpha-1-rt-46.png\n0.359945\neth-alpha-1\n\n\n5\neth-alpha-1-rt-06.png\n0.495470\neth-alpha-1\n\n\n65\neth-alpha-1-rt-67.png\n0.857869\neth-alpha-1\n\n\n11\neth-alpha-1-rt-12.png\n0.292252\neth-alpha-1\n\n\n58\neth-alpha-1-rt-60.png\n0.588014\neth-alpha-1\n\n\n64\neth-alpha-1-rt-66.png\n1.345212\neth-alpha-1\n\n\n57\neth-alpha-1-rt-59.png\n0.463199\neth-alpha-1\n\n\n68\neth-alpha-1-rt-70.png\n0.735732\neth-alpha-1\n\n\n0\neth-alpha-1-rt-01.png\n0.238276\neth-alpha-1\n\n\n13\neth-alpha-1-rt-14.png\n0.210804\neth-alpha-1\n\n\n66\neth-alpha-1-rt-68.png\n0.627098\neth-alpha-1\n\n\n63\neth-alpha-1-rt-65.png\n0.253882\neth-alpha-1\n\n\n38\neth-alpha-1-rt-39.png\n0.396687\neth-alpha-1\n\n\n43\neth-alpha-1-rt-45.png\n0.311652\neth-alpha-1\n\n\n33\neth-alpha-1-rt-34.png\n0.105971\neth-alpha-1\n\n\n25\neth-alpha-1-rt-26.png\n0.155182\neth-alpha-1\n\n\n19\neth-alpha-1-rt-20.png\n0.342816\neth-alpha-1\n\n\n27\neth-alpha-1-rt-28.png\n0.676835\neth-alpha-1\n\n\n60\neth-alpha-1-rt-62.png\n0.249902\neth-alpha-1\n\n\n10\neth-alpha-1-rt-11.png\n0.335250\neth-alpha-1\n\n\n34\neth-alpha-1-rt-35.png\n0.085691\neth-alpha-1\n\n\n40\neth-alpha-1-rt-41.png\n0.701621\neth-alpha-1\n\n\n67\neth-alpha-1-rt-69.png\n0.681596\neth-alpha-1\n\n\n20\neth-alpha-1-rt-21.png\n0.398024\neth-alpha-1\n\n\n1\neth-alpha-1-rt-02.png\n0.209848\neth-alpha-1\n\n\n24\neth-alpha-1-rt-25.png\n0.171825\neth-alpha-1\n\n\n8\neth-alpha-1-rt-09.png\n0.976900\neth-alpha-1\n\n\n32\neth-alpha-1-rt-33.png\n0.452482\neth-alpha-1\n\n\n2\neth-alpha-1-rt-03.png\n0.255487\neth-alpha-1\n\n\n21\neth-alpha-1-rt-22.png\n0.082409\neth-alpha-1\n\n\n42\neth-alpha-1-rt-43.png\n0.262710\neth-alpha-1\n\n\n22\neth-alpha-1-rt-23.png\n0.312743\neth-alpha-1\n\n\n62\neth-alpha-1-rt-64.png\n0.140544\neth-alpha-1\n\n\n26\neth-alpha-1-rt-27.png\n0.147696\neth-alpha-1\n\n\n41\neth-alpha-1-rt-42.png\n0.420853\neth-alpha-1\n\n\n\n\n\n\n\n\ndef ks_splitter(items): return [train_idx, valid_idx]\n\ndblock = DataBlock(\n    blocks=(ImageBlock, RegressionBlock),\n    get_x=ColReader(0, pref='../../_data/ringtrial-tfm/im/'),\n    get_y=ColReader(1),\n    splitter = ks_splitter,\n    item_tfms=[OrderedQuantize(n_valid=len(valid_idx))],\n    batch_tfms=[\n    OrderedRatioResize(224),\n    Normalize.from_stats(*imagenet_stats)\n    ]\n)\ndls = dblock.dataloaders(df_selected, bs=16)\n\nlearn = load_learner('./models/frozen-epoch-30-lr-1.5e-3-12102024.pkl', cpu=True)\nlearn.dls = dls\nlearn.freeze()\n\n\nlearn.lr_find()\n\n\n\n\n\n\n\n\nSuggestedLRs(valley=0.001737800776027143)\n\n\n\n\n\n\n\n\n\n\nlearn.fit_one_cycle(10, 1.5e-3)\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nr2_score\ntime\n\n\n\n\n0\n0.062678\n0.070659\n-7.250715\n00:02\n\n\n1\n0.060883\n0.032091\n-2.747149\n00:01\n\n\n2\n0.064407\n0.013675\n-0.596789\n00:01\n\n\n3\n0.052951\n0.005511\n0.356464\n00:01\n\n\n4\n0.048459\n0.005013\n0.414687\n00:01\n\n\n5\n0.043682\n0.005526\n0.354736\n00:01\n\n\n6\n0.039910\n0.006038\n0.294921\n00:02\n\n\n7\n0.036788\n0.006592\n0.230292\n00:01\n\n\n8\n0.034137\n0.006361\n0.257186\n00:01\n\n\n9\n0.032073\n0.006753\n0.211423\n00:01\n\n\n\n\n\n\n# val_preds, val_targets = learn.get_preds(dl=dls.valid)\nval_preds, val_targets = learn.tta(dl=dls.valid, n=30)\nr2_score(val_targets, val_preds)\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n0.8524203732220106\n\n\n\nx, y = val_preds, val_targets\nplt.plot(x, y, '.')\n# Add the diagonal line\nmin_val = min(y.min(), x.min())\nmax_val = max(y.max(), x.max())\nplt.plot([min_val, max_val], [min_val, max_val], 'k--', lw=1)\n\n\n\n\n\n\n\n\n\n\nUsing cross-validation\n\ndef cross_validation(df, target, valid_size=0.2, \n                     num_bins=2, epochs=1, lr=1.5e-3, \n                     n_tta=10, seed=31):\n    from sklearn.model_selection import train_test_split\n    df = df.copy()\n    df.reset_index(inplace=True, drop=True)\n    train_df, valid_df = train_test_split(df, test_size=valid_size, \n                                          stratify=pd.qcut(df[target], q=num_bins, labels=False), \n                                          random_state=seed)\n    \n    train_idx, valid_idx = train_df.index, valid_df.index\n    \n    def stratified_splitter(items): return [train_idx, valid_idx]\n   \n    dblock = DataBlock(\n        blocks=(ImageBlock, RegressionBlock),\n        get_x=ColReader(0, pref='../../_data/ringtrial-tfm/im/'),\n        get_y=ColReader(1),\n        splitter=stratified_splitter,\n        item_tfms=[OrderedQuantize(n_valid=len(valid_idx))],\n        batch_tfms=[\n        OrderedRatioResize(224),\n        Normalize.from_stats(*imagenet_stats)\n        ]\n    )\n    dls = dblock.dataloaders(df, bs=16)\n    learn = load_learner('./models/frozen-epoch-30-lr-1.5e-3-12102024.pkl', cpu=True)\n    learn.dls = dls\n    learn.freeze()\n    learn.fit_one_cycle(epochs, lr)\n    # val_preds, val_targets = learn.get_preds(dl=dls.valid)\n    val_preds, val_targets = learn.tta(dl=dls.valid, n=n_tta)\n    return r2_score(val_targets, val_preds)\n\n\ndf_selected = df[df.lab == 'kssl']\nscores = []\nfor seed in range(1, 10):\n    score = cross_validation(df_selected, 'potassium_cmolkg', \n                             valid_size=0.2, num_bins=4, \n                             epochs=3, seed=seed)\n    scores.append(score )\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nr2_score\ntime\n\n\n\n\n0\n0.080839\n0.318125\n0.302815\n00:02\n\n\n1\n0.073392\n0.298006\n0.346907\n00:01\n\n\n2\n0.065199\n0.292256\n0.359508\n00:01\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nr2_score\ntime\n\n\n\n\n0\n0.078712\n0.058278\n0.567448\n00:01\n\n\n1\n0.103297\n0.037975\n0.718140\n00:01\n\n\n2\n0.106955\n0.029388\n0.781878\n00:01\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nr2_score\ntime\n\n\n\n\n0\n0.040163\n0.132989\n0.170330\n00:02\n\n\n1\n0.085821\n0.117681\n0.265833\n00:02\n\n\n2\n0.085760\n0.110825\n0.308603\n00:02\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nr2_score\ntime\n\n\n\n\n0\n0.073621\n0.045193\n0.553941\n00:02\n\n\n1\n0.106387\n0.029305\n0.710762\n00:03\n\n\n2\n0.082117\n0.021391\n0.788873\n00:02\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nr2_score\ntime\n\n\n\n\n0\n0.077322\n0.299385\n0.362233\n00:02\n\n\n1\n0.071211\n0.292716\n0.376440\n00:01\n\n\n2\n0.061952\n0.281709\n0.399887\n00:01\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nr2_score\ntime\n\n\n\n\n0\n0.155731\n0.052831\n0.586981\n00:02\n\n\n1\n0.147657\n0.045921\n0.641001\n00:03\n\n\n2\n0.127009\n0.043383\n0.660838\n00:02\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nr2_score\ntime\n\n\n\n\n0\n0.130341\n0.135900\n0.309171\n00:01\n\n\n1\n0.119079\n0.105886\n0.461744\n00:01\n\n\n2\n0.102005\n0.097154\n0.506130\n00:01\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nr2_score\ntime\n\n\n\n\n0\n0.159416\n0.036709\n0.643722\n00:02\n\n\n1\n0.147401\n0.028988\n0.718660\n00:02\n\n\n2\n0.133312\n0.023979\n0.767270\n00:01\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nr2_score\ntime\n\n\n\n\n0\n0.186754\n0.042557\n0.596722\n00:01\n\n\n1\n0.122767\n0.023109\n0.781009\n00:01\n\n\n2\n0.114166\n0.018596\n0.823780\n00:01\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\nplt.hist(np.array(scores))\n\n(array([1., 1., 1., 0., 1., 0., 0., 1., 0., 4.]),\n array([0.26426539, 0.31865215, 0.37303891, 0.42742567, 0.48181243,\n        0.53619919, 0.59058595, 0.64497271, 0.69935947, 0.75374623,\n        0.80813299]),\n &lt;BarContainer object of 10 artists&gt;)\n\n\n\n\n\n\n\n\n\n\ndef stratified_split(df, target, valid_size=0.2, test_size=0.2, num_bins=2, seed=41):\n    from sklearn.model_selection import train_test_split\n    df = df.copy()\n    df.reset_index(inplace=True, drop=True)\n    train_df, test_df = train_test_split(df, test_size=test_size, \n                                        stratify=pd.qcut(df[target], q=num_bins, labels=False), \n                                        random_state=seed)\n\n    train_df, valid_df = train_test_split(train_df, test_size=test_size, \n                                        stratify=pd.qcut(train_df[target], q=num_bins, labels=False), \n                                        random_state=seed)\n    \n    return train_df, train_df.index, valid_df, valid_df.index, test_df, test_df.index\n\n\ndata = stratified_split(df_selected, 'potassium_cmolkg', valid_size=0.3, test_size=0.2, num_bins=2)\ntrain_df, train_idx, valid_df, valid_idx, test_df, test_idx = data\n\n\n# Check they have nothing in common\ndef has_common_elements(list1, list2): return bool(set(list1) & set(list2))\n\nfc.test_eq(has_common_elements(train_idx, test_idx), False)\nfc.test_eq(has_common_elements(train_idx, valid_idx), False)\nfc.test_eq(has_common_elements(test_idx, valid_idx), False)\n\n\n---------------------------------------------------------------------------\nAssertionError                            Traceback (most recent call last)\nCell In[422], line 4\n      1 # Check they have nothing in common\n      2 def has_common_elements(list1, list2): return bool(set(list1) & set(list2))\n----&gt; 4 fc.test_eq(has_common_elements(train_idx, test_idx), False)\n      5 fc.test_eq(has_common_elements(train_idx, valid_idx), False)\n      6 fc.test_eq(has_common_elements(test_idx, valid_idx), False)\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/fastcore/test.py:39, in test_eq(a, b)\n     37 def test_eq(a,b):\n     38     \"`test` that `a==b`\"\n---&gt; 39     test(a,b,equals, cname='==')\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/fastcore/test.py:29, in test(a, b, cmp, cname)\n     27 \"`assert` that `cmp(a,b)`; display inputs and `cname or cmp.__name__` if it fails\"\n     28 if cname is None: cname=cmp.__name__\n---&gt; 29 assert cmp(a,b),f\"{cname}:\\n{a}\\n{b}\"\n\nAssertionError: ==:\nTrue\nFalse\n\n\n\n\ntrain_idx, valid_idx\n\n(Index([26, 40, 17, 67, 22, 13, 16, 41, 49, 18,  2,  9, 47, 44, 52, 63, 61, 37,\n        57, 59, 66, 30, 54, 33,  7, 55, 15, 46, 19, 53, 29, 60,  4,  3, 64, 45,\n        11, 20],\n       dtype='int64'),\n Index([21, 58, 14, 65, 34, 56, 50, 6, 35, 62, 68, 32, 25, 24, 43, 10, 48], dtype='int64'))\n\n\n\nlen(train_df), len(valid_df), len(test_df)\n\n(38, 17, 14)\n\n\n\ntest_df\n\n\n\n\n\n\n\n\nfname\npotassium_cmolkg\nlab\n\n\n\n\n28\nkssl-rt-29.png\n0.306528\nkssl\n\n\n39\nkssl-rt-40.png\n0.673883\nkssl\n\n\n23\nkssl-rt-24.png\n0.173592\nkssl\n\n\n0\nkssl-rt-01.png\n0.238276\nkssl\n\n\n42\nkssl-rt-43.png\n0.262710\nkssl\n\n\n27\nkssl-rt-28.png\n0.676835\nkssl\n\n\n31\nkssl-rt-32.png\n0.338556\nkssl\n\n\n38\nkssl-rt-39.png\n0.396687\nkssl\n\n\n8\nkssl-rt-09.png\n0.976900\nkssl\n\n\n1\nkssl-rt-02.png\n0.209848\nkssl\n\n\n36\nkssl-rt-37.png\n0.134627\nkssl\n\n\n51\nkssl-rt-53.png\n0.400788\nkssl\n\n\n5\nkssl-rt-06.png\n0.495470\nkssl\n\n\n12\nkssl-rt-13.png\n0.446620\nkssl\n\n\n\n\n\n\n\n\ndef stratified_splitter(items): return [train_idx, valid_idx]\n\n# dblock = DataBlock(blocks=(ImageBlock, RegressionBlock),\n#                    get_x=ColReader(0, pref='../../_data/ringtrial-tfm/im/'),\n#                    get_y=ColReader(1),\n#                    splitter=stratified_splitter,\n#                    batch_tfms=[RatioResize(224)],\n#                    item_tfms=[Quantize(n_valid=len(valid_idx))])\n\ndblock = DataBlock(\n    blocks=(ImageBlock, RegressionBlock),\n    get_x=ColReader(0, pref='../../_data/ringtrial-tfm/im/'),\n    get_y=ColReader(1),\n    splitter=stratified_splitter,\n    item_tfms=[OrderedQuantize(n_valid=len(valid_idx))],\n    batch_tfms=[\n        OrderedRatioResize(224),\n        Normalize.from_stats(*imagenet_stats)\n    ]\n)\n\n\n# dblock.summary(df_selected)\n\nSetting-up type transforms pipelines\nCollecting items from               fname  potassium_cmolkg   lab\n483  kssl-rt-01.png          0.238276  kssl\n484  kssl-rt-02.png          0.209848  kssl\n485  kssl-rt-03.png          0.255487  kssl\n486  kssl-rt-04.png          0.404965  kssl\n487  kssl-rt-05.png          0.469860  kssl\n488  kssl-rt-06.png          0.495470  kssl\n489  kssl-rt-07.png          0.393716  kssl\n490  kssl-rt-08.png          0.106628  kssl\n491  kssl-rt-09.png          0.976900  kssl\n492  kssl-rt-10.png          0.315519  kssl\n493  kssl-rt-11.png          0.335250  kssl\n494  kssl-rt-12.png          0.292252  kssl\n495  kssl-rt-13.png          0.446620  kssl\n496  kssl-rt-14.png          0.210804  kssl\n497  kssl-rt-15.png          0.482117  kssl\n498  kssl-rt-16.png          0.662054  kssl\n499  kssl-rt-17.png          0.595782  kssl\n500  kssl-rt-18.png          0.360761  kssl\n501  kssl-rt-19.png          0.340229  kssl\n502  kssl-rt-20.png          0.342816  kssl\n503  kssl-rt-21.png          0.398024  kssl\n504  kssl-rt-22.png          0.082409  kssl\n505  kssl-rt-23.png          0.312743  kssl\n506  kssl-rt-24.png          0.173592  kssl\n507  kssl-rt-25.png          0.171825  kssl\n508  kssl-rt-26.png          0.155182  kssl\n509  kssl-rt-27.png          0.147696  kssl\n510  kssl-rt-28.png          0.676835  kssl\n511  kssl-rt-29.png          0.306528  kssl\n512  kssl-rt-30.png          0.351649  kssl\n513  kssl-rt-31.png          0.358387  kssl\n514  kssl-rt-32.png          0.338556  kssl\n515  kssl-rt-33.png          0.452482  kssl\n516  kssl-rt-34.png          0.105971  kssl\n517  kssl-rt-35.png          0.085691  kssl\n518  kssl-rt-36.png          0.152824  kssl\n519  kssl-rt-37.png          0.134627  kssl\n520  kssl-rt-38.png          0.046282  kssl\n521  kssl-rt-39.png          0.396687  kssl\n522  kssl-rt-40.png          0.673883  kssl\n523  kssl-rt-41.png          0.701621  kssl\n524  kssl-rt-42.png          0.420853  kssl\n525  kssl-rt-43.png          0.262710  kssl\n526  kssl-rt-45.png          0.311652  kssl\n527  kssl-rt-46.png          0.359945  kssl\n528  kssl-rt-47.png          0.292476  kssl\n529  kssl-rt-48.png          0.724215  kssl\n530  kssl-rt-49.png          0.442131  kssl\n531  kssl-rt-50.png          0.720475  kssl\n532  kssl-rt-51.png          0.728205  kssl\n533  kssl-rt-52.png          0.328282  kssl\n534  kssl-rt-53.png          0.400788  kssl\n535  kssl-rt-54.png          0.328678  kssl\n536  kssl-rt-55.png          0.358884  kssl\n537  kssl-rt-56.png          0.718293  kssl\n538  kssl-rt-57.png          0.731367  kssl\n539  kssl-rt-58.png          0.735776  kssl\n540  kssl-rt-59.png          0.463199  kssl\n541  kssl-rt-60.png          0.588014  kssl\n542  kssl-rt-61.png          0.461032  kssl\n543  kssl-rt-62.png          0.249902  kssl\n544  kssl-rt-63.png          0.249902  kssl\n545  kssl-rt-64.png          0.140544  kssl\n546  kssl-rt-65.png          0.253882  kssl\n547  kssl-rt-66.png          1.345212  kssl\n548  kssl-rt-67.png          0.857869  kssl\n549  kssl-rt-68.png          0.627098  kssl\n550  kssl-rt-69.png          0.681596  kssl\n551  kssl-rt-70.png          0.735732  kssl\nFound 69 items\n2 datasets of sizes 38,17\nSetting up Pipeline: ColReader -- {'cols': 0, 'pref': '../../_data/ringtrial-tfm/im/', 'suff': '', 'label_delim': None} -&gt; PILBase.create\nSetting up Pipeline: ColReader -- {'cols': 1, 'pref': '', 'suff': '', 'label_delim': None} -&gt; RegressionSetup -- {'c': None}\n\nBuilding one sample\n  Pipeline: ColReader -- {'cols': 0, 'pref': '../../_data/ringtrial-tfm/im/', 'suff': '', 'label_delim': None} -&gt; PILBase.create\n    starting from\n      fname               kssl-rt-27.png\npotassium_cmolkg          0.147696\nlab                           kssl\nName: 509, dtype: object\n    applying ColReader -- {'cols': 0, 'pref': '../../_data/ringtrial-tfm/im/', 'suff': '', 'label_delim': None} gives\n      ../../_data/ringtrial-tfm/im/kssl-rt-27.png\n    applying PILBase.create gives\n      PILImage mode=RGB size=669x221\n  Pipeline: ColReader -- {'cols': 1, 'pref': '', 'suff': '', 'label_delim': None} -&gt; RegressionSetup -- {'c': None}\n    starting from\n      fname               kssl-rt-27.png\npotassium_cmolkg          0.147696\nlab                           kssl\nName: 509, dtype: object\n    applying ColReader -- {'cols': 1, 'pref': '', 'suff': '', 'label_delim': None} gives\n      0.14769560487272498\n    applying RegressionSetup -- {'c': None} gives\n      tensor(0.1477)\n\nFinal sample: (PILImage mode=RGB size=669x221, tensor(0.1477))\n\n\nCollecting items from               fname  potassium_cmolkg   lab\n483  kssl-rt-01.png          0.238276  kssl\n484  kssl-rt-02.png          0.209848  kssl\n485  kssl-rt-03.png          0.255487  kssl\n486  kssl-rt-04.png          0.404965  kssl\n487  kssl-rt-05.png          0.469860  kssl\n488  kssl-rt-06.png          0.495470  kssl\n489  kssl-rt-07.png          0.393716  kssl\n490  kssl-rt-08.png          0.106628  kssl\n491  kssl-rt-09.png          0.976900  kssl\n492  kssl-rt-10.png          0.315519  kssl\n493  kssl-rt-11.png          0.335250  kssl\n494  kssl-rt-12.png          0.292252  kssl\n495  kssl-rt-13.png          0.446620  kssl\n496  kssl-rt-14.png          0.210804  kssl\n497  kssl-rt-15.png          0.482117  kssl\n498  kssl-rt-16.png          0.662054  kssl\n499  kssl-rt-17.png          0.595782  kssl\n500  kssl-rt-18.png          0.360761  kssl\n501  kssl-rt-19.png          0.340229  kssl\n502  kssl-rt-20.png          0.342816  kssl\n503  kssl-rt-21.png          0.398024  kssl\n504  kssl-rt-22.png          0.082409  kssl\n505  kssl-rt-23.png          0.312743  kssl\n506  kssl-rt-24.png          0.173592  kssl\n507  kssl-rt-25.png          0.171825  kssl\n508  kssl-rt-26.png          0.155182  kssl\n509  kssl-rt-27.png          0.147696  kssl\n510  kssl-rt-28.png          0.676835  kssl\n511  kssl-rt-29.png          0.306528  kssl\n512  kssl-rt-30.png          0.351649  kssl\n513  kssl-rt-31.png          0.358387  kssl\n514  kssl-rt-32.png          0.338556  kssl\n515  kssl-rt-33.png          0.452482  kssl\n516  kssl-rt-34.png          0.105971  kssl\n517  kssl-rt-35.png          0.085691  kssl\n518  kssl-rt-36.png          0.152824  kssl\n519  kssl-rt-37.png          0.134627  kssl\n520  kssl-rt-38.png          0.046282  kssl\n521  kssl-rt-39.png          0.396687  kssl\n522  kssl-rt-40.png          0.673883  kssl\n523  kssl-rt-41.png          0.701621  kssl\n524  kssl-rt-42.png          0.420853  kssl\n525  kssl-rt-43.png          0.262710  kssl\n526  kssl-rt-45.png          0.311652  kssl\n527  kssl-rt-46.png          0.359945  kssl\n528  kssl-rt-47.png          0.292476  kssl\n529  kssl-rt-48.png          0.724215  kssl\n530  kssl-rt-49.png          0.442131  kssl\n531  kssl-rt-50.png          0.720475  kssl\n532  kssl-rt-51.png          0.728205  kssl\n533  kssl-rt-52.png          0.328282  kssl\n534  kssl-rt-53.png          0.400788  kssl\n535  kssl-rt-54.png          0.328678  kssl\n536  kssl-rt-55.png          0.358884  kssl\n537  kssl-rt-56.png          0.718293  kssl\n538  kssl-rt-57.png          0.731367  kssl\n539  kssl-rt-58.png          0.735776  kssl\n540  kssl-rt-59.png          0.463199  kssl\n541  kssl-rt-60.png          0.588014  kssl\n542  kssl-rt-61.png          0.461032  kssl\n543  kssl-rt-62.png          0.249902  kssl\n544  kssl-rt-63.png          0.249902  kssl\n545  kssl-rt-64.png          0.140544  kssl\n546  kssl-rt-65.png          0.253882  kssl\n547  kssl-rt-66.png          1.345212  kssl\n548  kssl-rt-67.png          0.857869  kssl\n549  kssl-rt-68.png          0.627098  kssl\n550  kssl-rt-69.png          0.681596  kssl\n551  kssl-rt-70.png          0.735732  kssl\nFound 69 items\n2 datasets of sizes 38,17\nSetting up Pipeline: ColReader -- {'cols': 0, 'pref': '../../_data/ringtrial-tfm/im/', 'suff': '', 'label_delim': None} -&gt; PILBase.create\nSetting up Pipeline: ColReader -- {'cols': 1, 'pref': '', 'suff': '', 'label_delim': None} -&gt; RegressionSetup -- {'c': None}\nSetting up after_item: Pipeline: OrderedQuantize -- {'n_valid': 17, 'p': 1.0} -&gt; ToTensor\nSetting up before_batch: Pipeline: \nSetting up after_batch: Pipeline: OrderedRatioResize -- {'max_sz': 224, 'resamples': (&lt;Resampling.BILINEAR: 2&gt;, &lt;Resampling.NEAREST: 0&gt;)} -&gt; IntToFloatTensor -- {'div': 255.0, 'div_mask': 1} -&gt; Normalize -- {'mean': tensor([[[[0.4850]],\n\n         [[0.4560]],\n\n         [[0.4060]]]], device='mps:0'), 'std': tensor([[[[0.2290]],\n\n         [[0.2240]],\n\n         [[0.2250]]]], device='mps:0'), 'axes': (0, 2, 3)}\n\nBuilding one batch\nApplying item_tfms to the first sample:\n  Pipeline: OrderedQuantize -- {'n_valid': 17, 'p': 1.0} -&gt; ToTensor\n    starting from\n      (PILImage mode=RGB size=669x221, tensor(0.1477))\n    applying OrderedQuantize -- {'n_valid': 17, 'p': 1.0} gives\n      (PILImage mode=RGB size=669x221, tensor(0.1477))\n    applying ToTensor gives\n      (TensorImage of size 3x221x669, tensor(0.1477))\n\nAdding the next 3 samples\n\nNo before_batch transform to apply\n\nCollating items in a batch\n\nApplying batch_tfms to the batch built\n  Pipeline: OrderedRatioResize -- {'max_sz': 224, 'resamples': (&lt;Resampling.BILINEAR: 2&gt;, &lt;Resampling.NEAREST: 0&gt;)} -&gt; IntToFloatTensor -- {'div': 255.0, 'div_mask': 1} -&gt; Normalize -- {'mean': tensor([[[[0.4850]],\n\n         [[0.4560]],\n\n         [[0.4060]]]], device='mps:0'), 'std': tensor([[[[0.2290]],\n\n         [[0.2240]],\n\n         [[0.2250]]]], device='mps:0'), 'axes': (0, 2, 3)}\n    starting from\n      (TensorImage of size 4x3x221x669, tensor([0.1477, 0.7016, 0.3608, 0.6816], device='mps:0'))\n    applying OrderedRatioResize -- {'max_sz': 224, 'resamples': (&lt;Resampling.BILINEAR: 2&gt;, &lt;Resampling.NEAREST: 0&gt;)} gives\n      (TensorImage of size 4x3x221x669, tensor([0.1477, 0.7016, 0.3608, 0.6816], device='mps:0'))\n    applying IntToFloatTensor -- {'div': 255.0, 'div_mask': 1} gives\n      (TensorImage of size 4x3x221x669, tensor([0.1477, 0.7016, 0.3608, 0.6816], device='mps:0'))\n    applying Normalize -- {'mean': tensor([[[[0.4850]],\n\n         [[0.4560]],\n\n         [[0.4060]]]], device='mps:0'), 'std': tensor([[[[0.2290]],\n\n         [[0.2240]],\n\n         [[0.2250]]]], device='mps:0'), 'axes': (0, 2, 3)} gives\n      (TensorImage of size 4x3x221x669, tensor([0.1477, 0.7016, 0.3608, 0.6816], device='mps:0'))\n\n\n\ndls = dblock.dataloaders(df_selected, bs=16)\n\n\ndls.train.n, dls.valid.n\n\n(38, 17)\n\n\n\ndls.show_batch(nrows=6, ncols=2, figsize=(12, 13))\n\n\n\n\n\n\n\n\n\nlearn.dls = dls\n\n\n# learn.summary()\n\n\nlearn.freeze()\n\n\n# learn.summary()\n\n\nlearn.lr_find()\n\n\n\n\n\n\n\n\nSuggestedLRs(valley=0.0014454397605732083)\n\n\n\n\n\n\n\n\n\n\nlearn.fit_one_cycle(1, 1.5e-3)\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nr2_score\ntime\n\n\n\n\n0\n0.033352\n0.007514\n0.877129\n00:02\n\n\n\n\n\n\nval_preds, val_targets = learn.get_preds(dl=dls.valid)\nr2_score(val_targets, val_preds)\n\n\n\n\n\n\n\n\n\n---------------------------------------------------------------------------\nInvalidParameterError                     Traceback (most recent call last)\nCell In[131], line 2\n      1 val_preds, val_targets = learn.get_preds(dl=dls.valid)\n----&gt; 2 r2_score(val_targets, val_preds)\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:203, in validate_params.&lt;locals&gt;.decorator.&lt;locals&gt;.wrapper(*args, **kwargs)\n    200 to_ignore += [\"self\", \"cls\"]\n    201 params = {k: v for k, v in params.arguments.items() if k not in to_ignore}\n--&gt; 203 validate_parameter_constraints(\n    204     parameter_constraints, params, caller_name=func.__qualname__\n    205 )\n    207 try:\n    208     with config_context(\n    209         skip_parameter_validation=(\n    210             prefer_skip_nested_validation or global_skip_validation\n    211         )\n    212     ):\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:95, in validate_parameter_constraints(parameter_constraints, params, caller_name)\n     89 else:\n     90     constraints_str = (\n     91         f\"{', '.join([str(c) for c in constraints[:-1]])} or\"\n     92         f\" {constraints[-1]}\"\n     93     )\n---&gt; 95 raise InvalidParameterError(\n     96     f\"The {param_name!r} parameter of {caller_name} must be\"\n     97     f\" {constraints_str}. Got {param_val!r} instead.\"\n     98 )\n\nInvalidParameterError: The 'y_true' parameter of r2_score must be an array-like. Got None instead.\n\n\n\n\n\n\nEvaluate fine-tuned model\n\nlen(test_df)\n\n14\n\n\n\ndblock = DataBlock(blocks=(ImageBlock, RegressionBlock),\n                   get_x=ColReader(0, pref='../../_data/ringtrial-tfm/im/'),\n                   get_y=ColReader(1),\n                   splitter=RandomSplitter(valid_pct=0, seed=41),\n                   item_tfms=[OrderedQuantize(n_valid=len(test_df))],\n                   batch_tfms=[\n                       OrderedRatioResize(224),\n                       Normalize.from_stats(*imagenet_stats)]\n                   )\n\ndls = dblock.dataloaders(test_df, bs=len(test_df))\n\n\nval_preds, val_targets = learn.get_preds(dl=dls.train)\n\n\n\n\n\n\n\n\n\nr2_score(val_targets, val_preds)\n\n0.18065004067315227\n\n\n\nval_preds, val_targets = learn.tta(dl=dls.train, n=30)\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\nr2_score(val_targets, val_preds)\n\n0.31174768615708437\n\n\n\nnp.c_[val_preds, val_targets]\n\narray([[0.28596842, 0.33855578],\n       [0.34872288, 0.30652836],\n       [0.16156155, 0.1735919 ],\n       [0.15021066, 0.20984755],\n       [0.7913804 , 0.6738828 ],\n       [0.6016631 , 0.9769003 ],\n       [0.12963496, 0.23827647],\n       [0.476924  , 0.3966867 ],\n       [0.41498667, 0.44661984],\n       [0.3885079 , 0.26271036],\n       [0.4440051 , 0.49547035],\n       [0.1741274 , 0.13462704],\n       [0.38449523, 0.40078753],\n       [0.5929916 , 0.6768349 ]], dtype=float32)\n\n\n\n\n\nlab\nlr\nn_epochs (fine-tuning)\nr2_score\nn_tta\n\n\n\n\niaea-aug2022\n1.5e-3\n20\n0.867\n30\n\n\nkssl\n1.5e-3\n20\n0.931\n30\n\n\n\n\n\nlearn.predict('/Users/franckalbinet/pro/dev/uhina/_data/ringtrial-tfm/im/kssl-rt-01.png')\n\n\n\n\n\n\n\n\n((0.2232206165790558,), tensor([0.2232]), tensor([0.2232]))\n\n\n\nnp.c_[val_preds, val_targets]\n\narray([[0.573713  , 0.66205376],\n       [0.23120013, 0.25548682],\n       [0.29060498, 0.23827647],\n       [0.3890785 , 0.3588835 ],\n       [0.72690636, 0.6738828 ],\n       [0.52095914, 0.48211747],\n       [0.5956749 , 0.6768349 ],\n       [0.55163294, 0.71829337],\n       [0.41514462, 0.46985987],\n       [0.6461811 , 0.73577553],\n       [0.3656289 , 0.24990232],\n       [0.6311119 , 0.68159574],\n       [0.16741446, 0.1476956 ],\n       [0.3227809 , 0.31551853]], dtype=float32)\n\n\n\nx, y = val_preds, val_targets\nplt.plot(x, y, '.')\n# Add the diagonal line\nmin_val = min(y.min(), x.min())\nmax_val = max(y.max(), x.max())\nplt.plot([min_val, max_val], [min_val, max_val], 'k--', lw=1)\n\n\n\n\n\n\n\n\n\n\nOn single images\n\ndef predict_with_transforms(learn, img_path, n_predictions=5):\n    # Load the image\n    img = PILImage.create(img_path)\n    \n    # Create instances of the transforms\n    ratio_resize = RatioResize(224)\n    quantize = Quantize()\n    \n    predictions = []\n    for _ in range(n_predictions):\n        # Apply transforms\n        img_resized = ratio_resize(img)\n        img_quantized = quantize(img_resized)\n        \n        # Predict\n        pred, _, _ = learn.predict(img_quantized)\n        predictions.append(pred[0])\n    \n    from statistics import mode\n    # Calculate mean and standard deviation\n    mean_pred = np.mean(predictions)\n    std_pred = np.std(predictions)\n    median_pred = np.median(predictions)\n    mode_pred = mode(predictions)\n    return mean_pred, std_pred, median_pred, mode_pred, predictions\n\n\ntest_df\n\n\n\n\n\n\n\n\nfname\npotassium_cmolkg\nlab\n\n\n\n\n416\niaea-aug2022-rt-03.png\n0.255487\niaea-aug2022\n\n\n453\niaea-aug2022-rt-40.png\n0.673883\niaea-aug2022\n\n\n414\niaea-aug2022-rt-01.png\n0.238276\niaea-aug2022\n\n\n441\niaea-aug2022-rt-28.png\n0.676835\niaea-aug2022\n\n\n470\niaea-aug2022-rt-58.png\n0.735776\niaea-aug2022\n\n\n423\niaea-aug2022-rt-10.png\n0.315519\niaea-aug2022\n\n\n429\niaea-aug2022-rt-16.png\n0.662054\niaea-aug2022\n\n\n468\niaea-aug2022-rt-56.png\n0.718293\niaea-aug2022\n\n\n428\niaea-aug2022-rt-15.png\n0.482117\niaea-aug2022\n\n\n467\niaea-aug2022-rt-55.png\n0.358884\niaea-aug2022\n\n\n481\niaea-aug2022-rt-69.png\n0.681596\niaea-aug2022\n\n\n440\niaea-aug2022-rt-27.png\n0.147696\niaea-aug2022\n\n\n475\niaea-aug2022-rt-63.png\n0.249902\niaea-aug2022\n\n\n418\niaea-aug2022-rt-05.png\n0.469860\niaea-aug2022\n\n\n\n\n\n\n\n\nlearn.predict('/Users/franckalbinet/pro/dev/uhina/_data/ringtrial-tfm/im/iaea-aug2022-rt-03.png')\n\n\n\n\n\n\n\n\n((0.22924283146858215,), tensor([0.2292]), tensor([0.2292]))\n\n\n\ndef predict_with_tta_histogram(learn, img_path, n_tta=40):\n    # Load the image\n    img = PILImage.create(img_path)\n    \n    # Create a test DataLoader with a single image\n    test_dl = learn.dls.test_dl([img])\n    \n    # Collect predictions\n    all_preds = []\n    for _ in range(n_tta):\n        # Get prediction with TTA (n=1 for a single augmentation each time)\n        preds, _ = learn.tta(dl=test_dl, n=1)\n        all_preds.append(preds[0][0].item())  # Assuming single output\n    \n    all_preds = np.array(all_preds)\n    \n    # Calculate statistics\n    mean_pred = np.mean(all_preds)\n    std_pred = np.std(all_preds)\n    median_pred = np.median(all_preds)\n    \n    return mean_pred, std_pred, median_pred, all_preds\n\n\n# Use the function\nfname = 'iaea-aug2022-rt-03.png'\nimg_path = Path('/Users/franckalbinet/pro/dev/uhina/_data/ringtrial-tfm/im/') / fname\nmean, std, median, all_preds = predict_with_tta_histogram(learn, img_path, n_tta=30)\n\nprint(f\"Mean prediction: {mean:.4f}\")\nprint(f\"Standard deviation: {std:.4f}\")\nprint(f\"Median prediction: {median:.4f}\")\nprint(f\"All predictions: {all_preds}\")\n\n# If you want to compare with the ground truth\nprint('Ground truth:', df[df.fname == fname]['potassium_cmolkg'].values[0])\n\n# Plot histogram\nplt.hist(all_preds, bins=10)\nplt.title('Histogram of TTA Predictions')\nplt.xlabel('Predicted Value')\nplt.ylabel('Frequency')\nplt.show()\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\nMean prediction: 0.2245\nStandard deviation: 0.0293\nMedian prediction: 0.2370\nAll predictions: [0.2538105  0.20756826 0.16517167 0.18890977 0.23950726 0.25089669\n 0.23727572 0.1606092  0.23708239 0.24203241 0.24409012 0.23063052\n 0.22467479 0.22609089 0.21201754 0.24700734 0.24322104 0.1814348\n 0.23694187 0.21401702 0.24518737 0.23962407 0.24665055 0.23783752\n 0.23432088 0.13502732 0.24622732 0.22676304 0.24990481 0.23013265]\nGround truth: 0.29109\n\n\n\n\n\n\n\n\n\n\nplt.plot(all_preds)\n\n\n# Canonical fine-tuning\n# from fastai.vision.all import *\n\n# # Load the pretrained model\n# learn = load_learner('./models/650-4000-epoch-25-lr-3e-3.pkl', cpu=False)\n\n# # Prepare your new data\n# path = 'path/to/your/data'\n# dls = ImageDataLoaders.from_folder(path, valid_pct=0.2, item_tfms=Resize(224), batch_tfms=aug_transforms())\n\n# # Set the new data\n# learn.dls = dls\n\n# # Fine-tune the head of the model\n# learn.freeze()\n# # alternatively: learn.freeze_to(n)\n# learn.lr_find()\n# learn.fit_one_cycle(5, 3e-3)\n\n# # Fine-tune the entire model\n# learn.unfreeze()\n# learn.lr_find()\n# learn.fit_one_cycle(5, slice(1e-5, 1e-3))\n\n\n# learn = vision_learner(dls, resnet18, pretrained=False, metrics=R2Score()).to_fp16()\n\n\n# learn.lr_find()\n\n\n# learn.lr_find()\n\n\n\n\n\n\n\n\nSuggestedLRs(valley=0.002511886414140463)\n\n\n\n\n\n\n\n\n\n\n# learn.fit_one_cycle(5, 3e-3)",
    "crumbs": [
      "example",
      "Ringtrial"
    ]
  },
  {
    "objectID": "example/ringtrial.html#evaluation",
    "href": "example/ringtrial.html#evaluation",
    "title": "Ringtrial",
    "section": "Evaluation",
    "text": "Evaluation\n\n# Convert predictions and targets to numpy arrays\ndef assess_model(val_preds, val_targets):\n    val_preds = val_preds.numpy().flatten()\n    val_targets = val_targets.numpy()\n\n    # Create a DataFrame with the results\n    results_df = pd.DataFrame({\n        'Predicted': val_preds,\n        'Actual': val_targets\n    })\n\n    # Display the first few rows of the results\n    print(results_df.head())\n\n    # Calculate and print the R2 score\n    from sklearn.metrics import r2_score\n    r2 = r2_score(val_targets, val_preds)\n    print(f\"R2 Score on validation set: {r2:.4f}\")\n\n\ndls.train.n\n\n69\n\n\n\nval_preds, val_targets = learn.get_preds(dl=dls.train)\nassess_model(val_preds, val_targets)\n\n\n\n\n\n\n\n\n   Predicted    Actual\n0   0.046272  0.210804\n1   0.528189  0.976900\n2   0.465372  0.469860\n3   0.258100  0.338556\n4   0.112802  0.147696\nR2 Score on validation set: 0.7392\n\n\n\nval_preds, val_targets = learn.get_preds(dl=dls.train)\nr2 = r2_score(val_targets, val_preds); r2\n\n\nr2 = r2_score(val_targets, val_preds); r2\n\n0.7391959435205914\n\n\n\nscores = []\nfor n in range(1, 20):\n    val_preds, val_targets = learn.tta(dl=dls.train, n=n)\n    scores.append(r2_score(val_targets, val_preds))\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\nx = list(range(1, 20))\nplt.plot(x, scores)\n\n\n\n\n\n\n\n\n\n# EXAMPLE of TTA on single item\n# from fastai.vision.all import *\n\n# # Define your TTA transforms\n# tta_tfms = [\n#     RandomResizedCrop(224, min_scale=0.5),\n#     Flip(),\n#     Rotate(degrees=(-15, 15)),\n#     Brightness(max_lighting=0.2),\n#     Contrast(max_lighting=0.2)\n# ]\n\n# # Create a pipeline of TTA transformations\n# tta_pipeline = Pipeline(tta_tfms)\n\n# # Load your model\n# learn = load_learner('path/to/your/model.pkl')\n\n# # Define the input data (e.g., an image)\n# input_data = PILImage.create('path/to/your/image.jpg')\n\n# # Apply TTA transforms to the input data and make predictions\n# predictions = []\n# for _ in range(5):  # Apply 5 different augmentations\n#     augmented_data = tta_pipeline(input_data)\n#     prediction = learn.predict(augmented_data)\n#     predictions.append(prediction)\n\n# # Average the predictions\n# average_prediction = sum(predictions) / len(predictions)\n\n# print(average_prediction)\n\n\n# Assuming you have a new CSV file for your test data\n# test_source = '../../_data/ossl-tfm/ossl-tfm-test.csv'\n# test_df = pd.read_csv(test_source)\n\n# # Create a new DataLoader for the test data\n# test_dl = learn.dls.test_dl(test_df)\n\n# # Get predictions on the test set\n# test_preds, test_targets = learn.get_preds(dl=test_dl)\n\n# # Now you can use test_preds and test_targets for further analysis\n\n\nassess_model(val_preds, val_targets)\n\n   Predicted    Actual\n0   0.312483  0.000000\n1   0.126990  0.184960\n2   0.365726  0.194201\n3   0.239089  0.262364\n4   0.402980  0.355799\nR2 Score on validation set: 0.8325\n\n\n\nassess_model(val_preds_tta, val_targets_tta)\n\n   Predicted    Actual\n0   0.246857  0.000000\n1   0.148590  0.184960\n2   0.371643  0.194201\n3   0.226535  0.262364\n4   0.407333  0.355799\nR2 Score on validation set: 0.8378\n\n\n\nval_preds_np = val_preds\nval_targets_np = val_targets\n\n# Apply the transformation: exp(y) - 1\nval_preds_transformed = np.exp(val_preds_np) - 1\nval_targets_transformed = np.exp(val_targets_np) - 1\n\n# Create a DataFrame with the results\nresults_df = pd.DataFrame({\n    'Predicted': val_preds_transformed,\n    'Actual': val_targets_transformed\n})\n\n# Display the first few rows of the results\nprint(results_df.head())\n\n# Calculate and print the R2 score\nfrom sklearn.metrics import r2_score\nr2 = r2_score(val_targets_transformed, val_preds_transformed)\nprint(f\"R2 Score on validation set (after transformation): {r2:.4f}\")\n\n# Calculate and print the MAPE, handling zero values\ndef mean_absolute_percentage_error(y_true, y_pred):\n    non_zero = (y_true != 0)\n    return np.mean(np.abs((y_true[non_zero] - y_pred[non_zero]) / y_true[non_zero])) * 100\n\nmape = mean_absolute_percentage_error(val_targets_transformed, val_preds_transformed)\nprint(f\"Mean Absolute Percentage Error (MAPE) on validation set: {mape:.2f}%\")\n\n# Calculate and print the MAE as an alternative metric\nfrom sklearn.metrics import mean_absolute_error\nmae = mean_absolute_error(val_targets_transformed, val_preds_transformed)\nprint(f\"Mean Absolute Error (MAE) on validation set: {mae:.4f}\")\n\n   Predicted   Actual\n0   0.366814  0.00000\n1   0.135405  0.20317\n2   0.441560  0.21434\n3   0.270092  0.30000\n4   0.496277  0.42732\nR2 Score on validation set (after transformation): 0.6936\nMean Absolute Percentage Error (MAPE) on validation set: 50.72%\nMean Absolute Error (MAE) on validation set: 0.1956\n\n\n\nplt.figure(figsize=(6, 6))\n\n# Use logarithmic bins for the colormap\nh = plt.hexbin(val_targets, val_preds, gridsize=65, \n               bins='log', cmap='Spectral_r', mincnt=1,\n               alpha=0.9)\n\n# Get the actual min and max counts from the hexbin data\ncounts = h.get_array()\nmin_count = counts[counts &gt; 0].min()  # Minimum non-zero count\nmax_count = counts.max()\n\n# Create a logarithmic colorbar\ncb = plt.colorbar(h, label='Count in bin', shrink=0.73)\ntick_locations = np.logspace(np.log10(min_count), np.log10(max_count), 5)\ncb.set_ticks(tick_locations)\ncb.set_ticklabels([f'{int(x)}' for x in tick_locations])\n\n# Add the diagonal line\nmin_val = min(val_targets.min(), val_preds.min())\nmax_val = max(val_targets.max(), val_preds.max())\nplt.plot([min_val, max_val], [min_val, max_val], 'k--', lw=1)\n\n# Set labels and title\nplt.xlabel('Actual Values')\nplt.ylabel('Predicted Values')\nplt.title('Predicted vs Actual Values (Hexbin with Log Scale)')\n\n# Add grid lines\nplt.grid(True, linestyle='--', alpha=0.65)\n\n# Set the same limits for both axes\nplt.xlim(min_val, max_val)\nplt.ylim(min_val, max_val)\n\n# Make the plot square\nplt.gca().set_aspect('equal', adjustable='box')\n\nplt.tight_layout()\nplt.show()\n\n# Print the range of counts in the hexbins\nprint(f\"Min non-zero count in hexbins: {min_count}\")\nprint(f\"Max count in hexbins: {max_count}\")\n\n\n\n\n\n\n\n\nMin non-zero count in hexbins: 1.0\nMax count in hexbins: 157.0\n\n\n\npath_model = Path('./models')\nlearn.export(path_model / '0.pkl')",
    "crumbs": [
      "example",
      "Ringtrial"
    ]
  },
  {
    "objectID": "example/ringtrial.html#inference",
    "href": "example/ringtrial.html#inference",
    "title": "Ringtrial",
    "section": "Inference",
    "text": "Inference\n\nossl_source = Path('../../_data/ossl-tfm/img')\nlearn.predict(ossl_source / '0a0a0c647671fd3030cc13ba5432eb88.png')\n\n\n\n\n\n\n\n\n((0.5229991674423218,), tensor([0.5230]), tensor([0.5230]))\n\n\n\ndf[df['fname'] == '0a0a0c647671fd3030cc13ba5432eb88.png']\n\n\n\n\n\n\n\n\nfname\nkex\n\n\n\n\n28867\n0a0a0c647671fd3030cc13ba5432eb88.png\n0.525379\n\n\n\n\n\n\n\n\nnp.exp(3) - 1\n\n19.085536923187668",
    "crumbs": [
      "example",
      "Ringtrial"
    ]
  },
  {
    "objectID": "example/ringtrial.html#experiments",
    "href": "example/ringtrial.html#experiments",
    "title": "Ringtrial",
    "section": "Experiments:",
    "text": "Experiments:\nColor scale: viridis | Discretization: percentiles = [i for i in range(60, 100)]\n\n\n\n\n\n\n\n\n\n\n\n\n\nModel\nImage Size\nLearning Rate\nEpochs\nR2 Score\nTime per Epoch\nFinetuning\nwith axis ticks\n\n\n\n\nResNet-18\n100\n1e-3\n10\n0.648\n05:12\nNo\nYes\n\n\nResNet-18\n224\n2e-3\n10\n0.69\n07:30\nNo\nYes\n\n\nResNet-18\n750 (original size)\n1e-3\n10\n0.71\n36:00\nNo\nYes\n\n\nResNet-18\n224\n2e-3\n20\n0.704\n07:30\nNo\nYes\n\n\nResNet-18\n224\n2e-3\n10\n0.71\n07:00\nNo\nNo\n\n\n\nDiscretization: percentiles = [i for i in range(20, 100)]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nModel\nImage Size\nLearning Rate\nEpochs\nR2 Score\nTime per Epoch\nFinetuning\nwith axis ticks\ncolour scale\n\n\n\n\nResNet-18\n224\n2e-3\n10\n0.7\n05:12\nNo\nNo\nviridis\n\n\nResNet-18\n224\n3e-3\n10\n0.71\n05:12\nNo\nNo\njet\n\n\n\nFrom now on with axis ticks is always No.\nDiscretization: esimated on 10000 cwt power percentiles [20, 30, 40, 50, 60, 70, 80, 90, 95, 97, 99]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nModel\nImage Size\nLearning Rate\nEpochs\nR2 Score\nTime per Epoch\nFinetuning\nremark\ncolour scale\n\n\n\n\nResNet-18\n224\n2e-3\n10\n0.71\n05:12\nNo\nNone\njet\n\n\nResNet-18\n224\n2e-3\n10\n0.685\n05:12\nNo\ny range added\njet\n\n\n\nFrom now on random splitter with 10% validation and random seed 41.\nDiscretization: esimated on 10000 cwt power percentiles [20, 30, 40, 50, 60, 70, 80, 90, 95, 97, 99]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nModel\nImage Size\nLearning Rate\nEpochs\nR2 Score\nTime per Epoch\nFinetuning\nremark\ncolour scale\n\n\n\n\nResNet-18\n224\n2e-3\n10\n0.7\n05:12\nNo\nPre-train & normalize: True\njet\n\n\nResNet-18\n224\n2e-3\n10\n0.796\n08:12\nNo\nNo Pre-train\njet\n\n\nResNet-18\n224\n3e-3\n10\n0.7\n05:12\nNo\nPre-train & normalize: False\njet\n\n\nResNet-18 (id=0)\n224\n2e-3\n20\n0.829\n08:12\nNo\nNo Pre-train (try 18 epochs)\njet",
    "crumbs": [
      "example",
      "Ringtrial"
    ]
  },
  {
    "objectID": "example/history_runpod/fastai-bw-augment-12-10-2024.html",
    "href": "example/history_runpod/fastai-bw-augment-12-10-2024.html",
    "title": "Fastai BW data augmentation",
    "section": "",
    "text": "# setting up pod and pip install uhina\n# accessing a pod terminal\n\n# 1. To get access to the pod ip adress: runpodctl get pod -a\n# 2. ssh into the pod: ssh root@&lt;ip-address&gt; -p 58871 -i ~/.ssh/id_ed25519\n\n\n# runpodctl send uhina \n\n# git clone https://github.com/franckalbinet/uhina.git\n# pip install uhina\n# runpodctl send im-bw \n# runpodctl send ossl-tfm.csv",
    "crumbs": [
      "example",
      "history_runpod",
      "Fastai BW data augmentation"
    ]
  },
  {
    "objectID": "example/history_runpod/fastai-bw-augment-12-10-2024.html#runpod-setup",
    "href": "example/history_runpod/fastai-bw-augment-12-10-2024.html#runpod-setup",
    "title": "Fastai BW data augmentation",
    "section": "",
    "text": "# setting up pod and pip install uhina\n# accessing a pod terminal\n\n# 1. To get access to the pod ip adress: runpodctl get pod -a\n# 2. ssh into the pod: ssh root@&lt;ip-address&gt; -p 58871 -i ~/.ssh/id_ed25519\n\n\n# runpodctl send uhina \n\n# git clone https://github.com/franckalbinet/uhina.git\n# pip install uhina\n# runpodctl send im-bw \n# runpodctl send ossl-tfm.csv",
    "crumbs": [
      "example",
      "history_runpod",
      "Fastai BW data augmentation"
    ]
  },
  {
    "objectID": "example/history_runpod/fastai-bw-augment-12-10-2024.html#loading-data",
    "href": "example/history_runpod/fastai-bw-augment-12-10-2024.html#loading-data",
    "title": "Fastai BW data augmentation",
    "section": "Loading data",
    "text": "Loading data\n\nimport pandas as pd\nfrom pathlib import Path\nimport fastcore.all as fc\n\nfrom fastai.data.all import *\nfrom fastai.vision.all import *\nfrom multiprocessing import cpu_count\nfrom uhina.augment import Quantize\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\n\nossl_source = '../../_data/ossl-tfm/im-targets-lut.csv'\ndf = pd.read_csv(ossl_source); df.head()\n\n\n\n\n\n\n\n\nfname\nkex\n\n\n\n\n0\n3998362dd2659e2252cd7f38b43c9b1f.png\n0.182895\n\n\n1\n2bab4dbbac073b8648475ad50d40eb95.png\n0.082741\n\n\n2\n29213d2193232be8867d85dec463ec00.png\n0.089915\n\n\n3\n8b1ee9146c026faee20a40df86736864.png\n0.135030\n\n\n4\n6e8e9d1105e7da7055555cb5d310df5f.png\n0.270421\n\n\n\n\n\n\n\n\ndf['kex'].min(), df['kex'].max()\n\n(0.0, 3.6521352871126975)\n\n\n\nfrom sklearn.model_selection import train_test_split\ndf_train, df_valid = train_test_split(df, test_size=0.1, random_state=41)\nidx_train, idx_valid = df_train.index, df_valid.index\nlen(idx_train), len(idx_valid)\n\n(51906, 5768)\n\n\n\nclass OrderedQuantize(Quantize):\n    order = 0  # Apply first\n\nclass OrderedRatioResize(RatioResize):\n    order = 1  # Apply second\n\ndef splitter(items): return [idx_train, idx_valid]\n    \nossl = DataBlock(\n    blocks=(ImageBlock, RegressionBlock),\n    get_x=ColReader(0, pref='../../_data/ossl-tfm/im/'),\n    get_y=ColReader(1),\n    splitter=splitter,\n    item_tfms=[OrderedQuantize(n_valid=len(idx_valid))],\n    batch_tfms=[\n        OrderedRatioResize(224),\n        Normalize.from_stats(*imagenet_stats)\n    ]\n)\n\n\n#def splitter(items): return [idx_train, idx_valid]\n\n#ossl = DataBlock(blocks=(ImageBlock, RegressionBlock),\n#                get_x=ColReader(0, pref='../../_data/ossl-tfm/im/'),\n#                get_y=ColReader(1),\n#                # batch_tfms=Normalize.from_stats(*imagenet_stats),\n#                batch_tfms=[RatioResize(224)],\n#                item_tfms=[Quantize(n_valid=len(idx_valid))],\n#                # splitter=RandomSplitter(valid_pct=0.1, seed=41)\n#                splitter=splitter\n#    batch_tfms=aug_transforms()\n#)\n\n\n# ossl.summary(df)\n\n\ndls = ossl.dataloaders(df)\n\n\ndls.show_batch(nrows=6, ncols=2, figsize=(12, 13))\n\n\n\n\n\n\n\n\n\nlearn = vision_learner(dls, resnet18, pretrained=True, metrics=R2Score()).to_fp16()\n\n\nlearn.freeze()\n\n\nlearn.lr_find()\n\n\n\n\n\n\n\n\nSuggestedLRs(valley=0.0010000000474974513)\n\n\n\n\n\n\n\n\n\n\n#learn.summary()\n\n\n\n\n\n\n\n\nSequential (Input shape: 64 x 3 x 221 x 669)\n============================================================================\nLayer (type)         Output Shape         Param #    Trainable \n============================================================================\n                     64 x 64 x 111 x 335 \nConv2d                                    9408       True      \nBatchNorm2d                               128        True      \nReLU                                                           \n____________________________________________________________________________\n                     64 x 64 x 56 x 168  \nMaxPool2d                                                      \nConv2d                                    36864      True      \nBatchNorm2d                               128        True      \nReLU                                                           \nConv2d                                    36864      True      \nBatchNorm2d                               128        True      \nConv2d                                    36864      True      \nBatchNorm2d                               128        True      \nReLU                                                           \nConv2d                                    36864      True      \nBatchNorm2d                               128        True      \n____________________________________________________________________________\n                     64 x 128 x 28 x 84  \nConv2d                                    73728      True      \nBatchNorm2d                               256        True      \nReLU                                                           \nConv2d                                    147456     True      \nBatchNorm2d                               256        True      \nConv2d                                    8192       True      \nBatchNorm2d                               256        True      \nConv2d                                    147456     True      \nBatchNorm2d                               256        True      \nReLU                                                           \nConv2d                                    147456     True      \nBatchNorm2d                               256        True      \n____________________________________________________________________________\n                     64 x 256 x 14 x 42  \nConv2d                                    294912     True      \nBatchNorm2d                               512        True      \nReLU                                                           \nConv2d                                    589824     True      \nBatchNorm2d                               512        True      \nConv2d                                    32768      True      \nBatchNorm2d                               512        True      \nConv2d                                    589824     True      \nBatchNorm2d                               512        True      \nReLU                                                           \nConv2d                                    589824     True      \nBatchNorm2d                               512        True      \n____________________________________________________________________________\n                     64 x 512 x 7 x 21   \nConv2d                                    1179648    True      \nBatchNorm2d                               1024       True      \nReLU                                                           \nConv2d                                    2359296    True      \nBatchNorm2d                               1024       True      \nConv2d                                    131072     True      \nBatchNorm2d                               1024       True      \nConv2d                                    2359296    True      \nBatchNorm2d                               1024       True      \nReLU                                                           \nConv2d                                    2359296    True      \nBatchNorm2d                               1024       True      \n____________________________________________________________________________\n                     64 x 512 x 1 x 1    \nAdaptiveAvgPool2d                                              \nAdaptiveMaxPool2d                                              \n____________________________________________________________________________\n                     64 x 1024           \nFlatten                                                        \nBatchNorm1d                               2048       True      \nDropout                                                        \n____________________________________________________________________________\n                     64 x 512            \nLinear                                    524288     True      \nReLU                                                           \nBatchNorm1d                               1024       True      \nDropout                                                        \n____________________________________________________________________________\n                     64 x 1              \nLinear                                    512        True      \n____________________________________________________________________________\n\nTotal params: 11,704,384\nTotal trainable params: 11,704,384\nTotal non-trainable params: 0\n\nOptimizer used: &lt;function Adam&gt;\nLoss function: FlattenedLoss of MSELoss()\n\nModel unfrozen\n\nCallbacks:\n  - TrainEvalCallback\n  - CastToTensor\n  - MixedPrecision\n  - Recorder\n  - ProgressCallback\n\n\n\nlearn.fit_one_cycle(30, 1.5e-3)\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nr2_score\ntime\n\n\n\n\n0\n1.644630\n0.300183\n-1.107600\n03:27\n\n\n1\n0.330966\n0.122813\n0.137722\n03:24\n\n\n2\n0.111735\n0.096092\n0.325332\n03:24\n\n\n3\n0.090042\n0.080140\n0.437336\n03:23\n\n\n4\n0.086476\n0.076293\n0.464347\n03:24\n\n\n5\n0.079303\n0.067029\n0.529383\n03:26\n\n\n6\n0.079823\n0.077337\n0.457015\n03:21\n\n\n7\n0.071064\n0.063280\n0.555711\n03:26\n\n\n8\n0.063395\n0.049661\n0.651327\n03:25\n\n\n9\n0.064540\n0.050022\n0.648795\n03:20\n\n\n10\n0.056607\n0.048462\n0.659747\n03:22\n\n\n11\n0.053760\n0.053292\n0.625835\n03:23\n\n\n12\n0.056411\n0.048289\n0.660963\n03:20\n\n\n13\n0.049446\n0.046147\n0.676001\n03:26\n\n\n14\n0.047927\n0.041901\n0.705815\n03:26\n\n\n15\n0.046742\n0.044546\n0.687241\n03:28\n\n\n16\n0.049120\n0.041590\n0.707998\n03:18\n\n\n17\n0.043476\n0.039859\n0.720151\n03:27\n\n\n18\n0.046412\n0.038752\n0.727923\n03:22\n\n\n19\n0.044368\n0.040569\n0.715167\n03:18\n\n\n20\n0.040819\n0.037822\n0.734452\n03:24\n\n\n21\n0.043126\n0.036971\n0.740424\n03:22\n\n\n22\n0.042248\n0.036392\n0.744487\n03:16\n\n\n23\n0.041793\n0.036009\n0.747177\n03:22\n\n\n24\n0.039837\n0.035846\n0.748324\n03:22\n\n\n25\n0.039785\n0.035595\n0.750088\n03:27\n\n\n26\n0.040293\n0.035616\n0.749942\n03:29\n\n\n27\n0.037746\n0.035546\n0.750431\n03:25\n\n\n28\n0.038235\n0.036200\n0.745835\n03:21\n\n\n29\n0.038197\n0.035067\n0.753795\n03:25\n\n\n\n\n\n\nlearn.unfreeze()\n\n\nlearn.lr_find()\n\n\n\n\n\n\n\n\nSuggestedLRs(valley=1.2022644114040304e-05)\n\n\n\n\n\n\n\n\n\n\nlearn.fit_one_cycle(10, slice(1e-5, 1e-4))\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nr2_score\ntime\n\n\n\n\n0\n0.041027\n0.036716\n0.742214\n03:24\n\n\n1\n0.043233\n0.038476\n0.729859\n03:25\n\n\n2\n0.040227\n0.036917\n0.740801\n03:27\n\n\n3\n0.037694\n0.032176\n0.774093\n03:34\n\n\n4\n0.033340\n0.032090\n0.774694\n03:20\n\n\n5\n0.029570\n0.030667\n0.784687\n03:22\n\n\n6\n0.027940\n0.028028\n0.803215\n03:24\n\n\n7\n0.028264\n0.027417\n0.807507\n03:23\n\n\n8\n0.025013\n0.026760\n0.812116\n03:17\n\n\n9\n0.024846\n0.026566\n0.813480\n03:22",
    "crumbs": [
      "example",
      "history_runpod",
      "Fastai BW data augmentation"
    ]
  },
  {
    "objectID": "example/history_runpod/fastai-bw-augment-12-10-2024.html#evaluation",
    "href": "example/history_runpod/fastai-bw-augment-12-10-2024.html#evaluation",
    "title": "Fastai BW data augmentation",
    "section": "Evaluation",
    "text": "Evaluation\n\nval_preds, val_targets = learn.get_preds(dl=dls.valid)\n\n\n\n\n\n\n\n\n\nr2_score(val_preds, val_targets)\n\n0.7777369823359973\n\n\n\nval_preds_tta, val_targets_tta = learn.tta(dl=dls.valid, n=10)\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\nfrom sklearn.metrics import r2_score\nr2_score(val_preds_tta, val_targets_tta)\n\n0.7900635997635996\n\n\n\n# EXAMPLE of TTA on single item\n# from fastai.vision.all import *\n\n# # Define your TTA transforms\n# tta_tfms = [\n#     RandomResizedCrop(224, min_scale=0.5),\n#     Flip(),\n#     Rotate(degrees=(-15, 15)),\n#     Brightness(max_lighting=0.2),\n#     Contrast(max_lighting=0.2)\n# ]\n\n# # Create a pipeline of TTA transformations\n# tta_pipeline = Pipeline(tta_tfms)\n\n# # Load your model\n# learn = load_learner('path/to/your/model.pkl')\n\n# # Define the input data (e.g., an image)\n# input_data = PILImage.create('path/to/your/image.jpg')\n\n# # Apply TTA transforms to the input data and make predictions\n# predictions = []\n# for _ in range(5):  # Apply 5 different augmentations\n#     augmented_data = tta_pipeline(input_data)\n#     prediction = learn.predict(augmented_data)\n#     predictions.append(prediction)\n\n# # Average the predictions\n# average_prediction = sum(predictions) / len(predictions)\n\n# print(average_prediction)\n\n\n# Assuming you have a new CSV file for your test data\n# test_source = '../../_data/ossl-tfm/ossl-tfm-test.csv'\n# test_df = pd.read_csv(test_source)\n\n# # Create a new DataLoader for the test data\n# test_dl = learn.dls.test_dl(test_df)\n\n# # Get predictions on the test set\n# test_preds, test_targets = learn.get_preds(dl=test_dl)\n\n# # Now you can use test_preds and test_targets for further analysis\n\n\n# Convert predictions and targets to numpy arrays\ndef assess_model(val_preds, val_targets):\n    val_preds = val_preds.numpy().flatten()\n    val_targets = val_targets.numpy()\n\n    # Create a DataFrame with the results\n    results_df = pd.DataFrame({\n        'Predicted': val_preds,\n        'Actual': val_targets\n    })\n\n    # Display the first few rows of the results\n    print(results_df.head())\n\n    # Calculate and print the R2 score\n    from sklearn.metrics import r2_score\n    r2 = r2_score(val_targets, val_preds)\n    print(f\"R2 Score on validation set: {r2:.4f}\")\n\n\nassess_model(val_preds, val_targets)\n\n   Predicted    Actual\n0   0.312483  0.000000\n1   0.126990  0.184960\n2   0.365726  0.194201\n3   0.239089  0.262364\n4   0.402980  0.355799\nR2 Score on validation set: 0.8325\n\n\n\nassess_model(val_preds_tta, val_targets_tta)\n\n   Predicted    Actual\n0   0.246857  0.000000\n1   0.148590  0.184960\n2   0.371643  0.194201\n3   0.226535  0.262364\n4   0.407333  0.355799\nR2 Score on validation set: 0.8378\n\n\n\nval_preds_np = val_preds\nval_targets_np = val_targets\n\n# Apply the transformation: exp(y) - 1\nval_preds_transformed = np.exp(val_preds_np) - 1\nval_targets_transformed = np.exp(val_targets_np) - 1\n\n# Create a DataFrame with the results\nresults_df = pd.DataFrame({\n    'Predicted': val_preds_transformed,\n    'Actual': val_targets_transformed\n})\n\n# Display the first few rows of the results\nprint(results_df.head())\n\n# Calculate and print the R2 score\nfrom sklearn.metrics import r2_score\nr2 = r2_score(val_targets_transformed, val_preds_transformed)\nprint(f\"R2 Score on validation set (after transformation): {r2:.4f}\")\n\n# Calculate and print the MAPE, handling zero values\ndef mean_absolute_percentage_error(y_true, y_pred):\n    non_zero = (y_true != 0)\n    return np.mean(np.abs((y_true[non_zero] - y_pred[non_zero]) / y_true[non_zero])) * 100\n\nmape = mean_absolute_percentage_error(val_targets_transformed, val_preds_transformed)\nprint(f\"Mean Absolute Percentage Error (MAPE) on validation set: {mape:.2f}%\")\n\n# Calculate and print the MAE as an alternative metric\nfrom sklearn.metrics import mean_absolute_error\nmae = mean_absolute_error(val_targets_transformed, val_preds_transformed)\nprint(f\"Mean Absolute Error (MAE) on validation set: {mae:.4f}\")\n\n   Predicted   Actual\n0   0.366814  0.00000\n1   0.135405  0.20317\n2   0.441560  0.21434\n3   0.270092  0.30000\n4   0.496277  0.42732\nR2 Score on validation set (after transformation): 0.6936\nMean Absolute Percentage Error (MAPE) on validation set: 50.72%\nMean Absolute Error (MAE) on validation set: 0.1956\n\n\n\nplt.figure(figsize=(6, 6))\n\n# Use logarithmic bins for the colormap\nh = plt.hexbin(val_targets, val_preds, gridsize=65, \n               bins='log', cmap='Spectral_r', mincnt=1,\n               alpha=0.9)\n\n# Get the actual min and max counts from the hexbin data\ncounts = h.get_array()\nmin_count = counts[counts &gt; 0].min()  # Minimum non-zero count\nmax_count = counts.max()\n\n# Create a logarithmic colorbar\ncb = plt.colorbar(h, label='Count in bin', shrink=0.73)\ntick_locations = np.logspace(np.log10(min_count), np.log10(max_count), 5)\ncb.set_ticks(tick_locations)\ncb.set_ticklabels([f'{int(x)}' for x in tick_locations])\n\n# Add the diagonal line\nmin_val = min(val_targets.min(), val_preds.min())\nmax_val = max(val_targets.max(), val_preds.max())\nplt.plot([min_val, max_val], [min_val, max_val], 'k--', lw=1)\n\n# Set labels and title\nplt.xlabel('Actual Values')\nplt.ylabel('Predicted Values')\nplt.title('Predicted vs Actual Values (Hexbin with Log Scale)')\n\n# Add grid lines\nplt.grid(True, linestyle='--', alpha=0.65)\n\n# Set the same limits for both axes\nplt.xlim(min_val, max_val)\nplt.ylim(min_val, max_val)\n\n# Make the plot square\nplt.gca().set_aspect('equal', adjustable='box')\n\nplt.tight_layout()\nplt.show()\n\n# Print the range of counts in the hexbins\nprint(f\"Min non-zero count in hexbins: {min_count}\")\nprint(f\"Max count in hexbins: {max_count}\")\n\n\n\n\n\n\n\n\nMin non-zero count in hexbins: 1.0\nMax count in hexbins: 157.0\n\n\n\npath_model = Path('./models')\nlearn.export(path_model / 'frozen-epoch-30-lr-1.5e-3-then-unfrozen-epoch-10-lr-1-e-4-12102024.pkl')",
    "crumbs": [
      "example",
      "history_runpod",
      "Fastai BW data augmentation"
    ]
  },
  {
    "objectID": "example/history_runpod/fastai-bw-augment-12-10-2024.html#inference",
    "href": "example/history_runpod/fastai-bw-augment-12-10-2024.html#inference",
    "title": "Fastai BW data augmentation",
    "section": "Inference",
    "text": "Inference\n\nossl_source = Path('../../_data/ossl-tfm/img')\nlearn.predict(ossl_source / '0a0a0c647671fd3030cc13ba5432eb88.png')\n\n\n\n\n\n\n\n\n((0.5229991674423218,), tensor([0.5230]), tensor([0.5230]))\n\n\n\ndf[df['fname'] == '0a0a0c647671fd3030cc13ba5432eb88.png']\n\n\n\n\n\n\n\n\nfname\nkex\n\n\n\n\n28867\n0a0a0c647671fd3030cc13ba5432eb88.png\n0.525379\n\n\n\n\n\n\n\n\nnp.exp(3) - 1\n\n19.085536923187668",
    "crumbs": [
      "example",
      "history_runpod",
      "Fastai BW data augmentation"
    ]
  },
  {
    "objectID": "example/history_runpod/fastai-bw-augment-12-10-2024.html#experiments",
    "href": "example/history_runpod/fastai-bw-augment-12-10-2024.html#experiments",
    "title": "Fastai BW data augmentation",
    "section": "Experiments:",
    "text": "Experiments:\nColor scale: viridis | Discretization: percentiles = [i for i in range(60, 100)]\n\n\n\n\n\n\n\n\n\n\n\n\n\nModel\nImage Size\nLearning Rate\nEpochs\nR2 Score\nTime per Epoch\nFinetuning\nwith axis ticks\n\n\n\n\nResNet-18\n100\n1e-3\n10\n0.648\n05:12\nNo\nYes\n\n\nResNet-18\n224\n2e-3\n10\n0.69\n07:30\nNo\nYes\n\n\nResNet-18\n750 (original size)\n1e-3\n10\n0.71\n36:00\nNo\nYes\n\n\nResNet-18\n224\n2e-3\n20\n0.704\n07:30\nNo\nYes\n\n\nResNet-18\n224\n2e-3\n10\n0.71\n07:00\nNo\nNo\n\n\n\nDiscretization: percentiles = [i for i in range(20, 100)]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nModel\nImage Size\nLearning Rate\nEpochs\nR2 Score\nTime per Epoch\nFinetuning\nwith axis ticks\ncolour scale\n\n\n\n\nResNet-18\n224\n2e-3\n10\n0.7\n05:12\nNo\nNo\nviridis\n\n\nResNet-18\n224\n3e-3\n10\n0.71\n05:12\nNo\nNo\njet\n\n\n\nFrom now on with axis ticks is always No.\nDiscretization: esimated on 10000 cwt power percentiles [20, 30, 40, 50, 60, 70, 80, 90, 95, 97, 99]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nModel\nImage Size\nLearning Rate\nEpochs\nR2 Score\nTime per Epoch\nFinetuning\nremark\ncolour scale\n\n\n\n\nResNet-18\n224\n2e-3\n10\n0.71\n05:12\nNo\nNone\njet\n\n\nResNet-18\n224\n2e-3\n10\n0.685\n05:12\nNo\ny range added\njet\n\n\n\nFrom now on random splitter with 10% validation and random seed 41.\nDiscretization: esimated on 10000 cwt power percentiles [20, 30, 40, 50, 60, 70, 80, 90, 95, 97, 99]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nModel\nImage Size\nLearning Rate\nEpochs\nR2 Score\nTime per Epoch\nFinetuning\nremark\ncolour scale\n\n\n\n\nResNet-18\n224\n2e-3\n10\n0.7\n05:12\nNo\nPre-train & normalize: True\njet\n\n\nResNet-18\n224\n2e-3\n10\n0.796\n08:12\nNo\nNo Pre-train\njet\n\n\nResNet-18\n224\n3e-3\n10\n0.7\n05:12\nNo\nPre-train & normalize: False\njet\n\n\nResNet-18 (id=0)\n224\n2e-3\n20\n0.829\n08:12\nNo\nNo Pre-train (try 18 epochs)\njet",
    "crumbs": [
      "example",
      "history_runpod",
      "Fastai BW data augmentation"
    ]
  },
  {
    "objectID": "example/fastai.html",
    "href": "example/fastai.html",
    "title": "Fastai example",
    "section": "",
    "text": "import pandas as pd\nfrom pathlib import Path\nimport fastcore.all as fc\n\nfrom fastai.data.all import *\nfrom fastai.vision.all import *\n\nimport warnings\nwarnings.filterwarnings('ignore')\nossl_source = '../../_data/ossl-tfm/ossl-tfm.csv'\ndf = pd.read_csv(ossl_source); df.head()\n\n\n\n\n\n\n\n\nfname\nkex\n\n\n\n\n0\n3998362dd2659e2252cd7f38b43c9b1f.png\n0.182895\n\n\n1\n2bab4dbbac073b8648475ad50d40eb95.png\n0.082741\n\n\n2\n29213d2193232be8867d85dec463ec00.png\n0.089915\n\n\n3\n8b1ee9146c026faee20a40df86736864.png\n0.135030\n\n\n4\n6e8e9d1105e7da7055555cb5d310df5f.png\n0.270421\ndf['kex'].min(), df['kex'].max()\n\n(0.0, 3.6521352871126975)\ndf.shape\n\n(57674, 2)\n# image size is 750x281\n# ossl_source = '../../_data/ossl-tfm/ossl-tfm.csv'\n# df = pd.read_csv(ossl_source); df.head()\n\n# ossl = DataBlock(blocks=(ImageBlock, RegressionBlock),\n#                 get_x=ColReader(0, pref='../../_data/ossl-tfm/img/'),\n#                 get_y=ColReader(1),\n#                 batch_tfms=Normalize.from_stats(*imagenet_stats),\n#                 item_tfms=RatioResize(224),\n#                 splitter=RandomSplitter(valid_pct=0.1, seed=41)\n                \n# dls = ossl.dataloaders(df)\n\n# learn = vision_learner(dls, resnet18, pretrained=False, metrics=R2Score())\n# learn.fit_one_cycle(20, 2e-3)\nossl = DataBlock(blocks=(ImageBlock, RegressionBlock),\n                get_x=ColReader(0, pref='../../_data/ossl-tfm/img/'),\n                get_y=ColReader(1),\n                batch_tfms=Normalize.from_stats(*imagenet_stats),\n                item_tfms=RatioResize(224),\n                splitter=RandomSplitter(valid_pct=0.1, seed=41)\n#    batch_tfms=aug_transforms()\n)\nossl.summary(df)\n\nSetting-up type transforms pipelines\nCollecting items from                                       fname       kex\n0      3998362dd2659e2252cd7f38b43c9b1f.png  0.182895\n1      2bab4dbbac073b8648475ad50d40eb95.png  0.082741\n2      29213d2193232be8867d85dec463ec00.png  0.089915\n3      8b1ee9146c026faee20a40df86736864.png  0.135030\n4      6e8e9d1105e7da7055555cb5d310df5f.png  0.270421\n...                                     ...       ...\n57669  8d1089ede5cae335779364ab6d97e0dd.png  0.366362\n57670  3700237aa002dee08e991b451003b3d7.png  0.485567\n57671  b790da349d49885c5727a2b5fd67b13d.png  1.243033\n57672  a057a7ead9eebce24d4039de7fd5e01b.png  0.381496\n57673  80bf4a0dc30f60552a38193d5c09b9cd.png  0.960841\n\n[57674 rows x 2 columns]\nFound 57674 items\n2 datasets of sizes 51907,5767\nSetting up Pipeline: ColReader -- {'cols': 0, 'pref': '../../_data/ossl-tfm/img/', 'suff': '', 'label_delim': None} -&gt; PILBase.create\nSetting up Pipeline: ColReader -- {'cols': 1, 'pref': '', 'suff': '', 'label_delim': None} -&gt; RegressionSetup -- {'c': None}\n\nBuilding one sample\n  Pipeline: ColReader -- {'cols': 0, 'pref': '../../_data/ossl-tfm/img/', 'suff': '', 'label_delim': None} -&gt; PILBase.create\n    starting from\n      fname    80b7bb4bb5d1e17262df3a12aafbbea8.png\nkex                                  0.391434\nName: 22759, dtype: object\n    applying ColReader -- {'cols': 0, 'pref': '../../_data/ossl-tfm/img/', 'suff': '', 'label_delim': None} gives\n      ../../_data/ossl-tfm/img/80b7bb4bb5d1e17262df3a12aafbbea8.png\n    applying PILBase.create gives\n      PILImage mode=RGB size=669x221\n  Pipeline: ColReader -- {'cols': 1, 'pref': '', 'suff': '', 'label_delim': None} -&gt; RegressionSetup -- {'c': None}\n    starting from\n      fname    80b7bb4bb5d1e17262df3a12aafbbea8.png\nkex                                  0.391434\nName: 22759, dtype: object\n    applying ColReader -- {'cols': 1, 'pref': '', 'suff': '', 'label_delim': None} gives\n      0.3914337946951873\n    applying RegressionSetup -- {'c': None} gives\n      tensor(0.3914)\n\nFinal sample: (PILImage mode=RGB size=669x221, tensor(0.3914))\n\n\nCollecting items from                                       fname       kex\n0      3998362dd2659e2252cd7f38b43c9b1f.png  0.182895\n1      2bab4dbbac073b8648475ad50d40eb95.png  0.082741\n2      29213d2193232be8867d85dec463ec00.png  0.089915\n3      8b1ee9146c026faee20a40df86736864.png  0.135030\n4      6e8e9d1105e7da7055555cb5d310df5f.png  0.270421\n...                                     ...       ...\n57669  8d1089ede5cae335779364ab6d97e0dd.png  0.366362\n57670  3700237aa002dee08e991b451003b3d7.png  0.485567\n57671  b790da349d49885c5727a2b5fd67b13d.png  1.243033\n57672  a057a7ead9eebce24d4039de7fd5e01b.png  0.381496\n57673  80bf4a0dc30f60552a38193d5c09b9cd.png  0.960841\n\n[57674 rows x 2 columns]\nFound 57674 items\n2 datasets of sizes 51907,5767\nSetting up Pipeline: ColReader -- {'cols': 0, 'pref': '../../_data/ossl-tfm/img/', 'suff': '', 'label_delim': None} -&gt; PILBase.create\nSetting up Pipeline: ColReader -- {'cols': 1, 'pref': '', 'suff': '', 'label_delim': None} -&gt; RegressionSetup -- {'c': None}\nSetting up after_item: Pipeline: RatioResize -- {'max_sz': 224, 'resamples': (&lt;Resampling.BILINEAR: 2&gt;, &lt;Resampling.NEAREST: 0&gt;)} -&gt; ToTensor\nSetting up before_batch: Pipeline: \nSetting up after_batch: Pipeline: IntToFloatTensor -- {'div': 255.0, 'div_mask': 1} -&gt; Normalize -- {'mean': tensor([[[[0.4850]],\n\n         [[0.4560]],\n\n         [[0.4060]]]], device='mps:0'), 'std': tensor([[[[0.2290]],\n\n         [[0.2240]],\n\n         [[0.2250]]]], device='mps:0'), 'axes': (0, 2, 3)}\n\nBuilding one batch\nApplying item_tfms to the first sample:\n  Pipeline: RatioResize -- {'max_sz': 224, 'resamples': (&lt;Resampling.BILINEAR: 2&gt;, &lt;Resampling.NEAREST: 0&gt;)} -&gt; ToTensor\n    starting from\n      (PILImage mode=RGB size=669x221, tensor(0.3914))\n    applying RatioResize -- {'max_sz': 224, 'resamples': (&lt;Resampling.BILINEAR: 2&gt;, &lt;Resampling.NEAREST: 0&gt;)} gives\n      (PILImage mode=RGB size=224x73, tensor(0.3914))\n    applying ToTensor gives\n      (TensorImage of size 3x73x224, tensor(0.3914))\n\nAdding the next 3 samples\n\nNo before_batch transform to apply\n\nCollating items in a batch\n\nApplying batch_tfms to the batch built\n  Pipeline: IntToFloatTensor -- {'div': 255.0, 'div_mask': 1} -&gt; Normalize -- {'mean': tensor([[[[0.4850]],\n\n         [[0.4560]],\n\n         [[0.4060]]]], device='mps:0'), 'std': tensor([[[[0.2290]],\n\n         [[0.2240]],\n\n         [[0.2250]]]], device='mps:0'), 'axes': (0, 2, 3)}\n    starting from\n      (TensorImage of size 4x3x73x224, tensor([0.3914, 0.1328, 0.3051, 1.0116], device='mps:0'))\n    applying IntToFloatTensor -- {'div': 255.0, 'div_mask': 1} gives\n      (TensorImage of size 4x3x73x224, tensor([0.3914, 0.1328, 0.3051, 1.0116], device='mps:0'))\n    applying Normalize -- {'mean': tensor([[[[0.4850]],\n\n         [[0.4560]],\n\n         [[0.4060]]]], device='mps:0'), 'std': tensor([[[[0.2290]],\n\n         [[0.2240]],\n\n         [[0.2250]]]], device='mps:0'), 'axes': (0, 2, 3)} gives\n      (TensorImage of size 4x3x73x224, tensor([0.3914, 0.1328, 0.3051, 1.0116], device='mps:0'))\ndls = ossl.dataloaders(df)\ndls.show_batch(nrows=5, ncols=1, figsize=(10, 15))\nlearn = vision_learner(dls, resnet18, pretrained=False, metrics=R2Score())\nlearn.lr_find()\n\n\n\n\n\n\n\n\nSuggestedLRs(valley=0.00363078061491251)\nlearn.fit_one_cycle(20, 2e-3)\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nr2_score\ntime\n\n\n\n\n0\n1.010429\n0.160208\n-0.149856\n07:33\n\n\n1\n0.101805\n0.105252\n0.244579\n07:37\n\n\n2\n0.080996\n0.092230\n0.338037\n07:45\n\n\n3\n0.061543\n0.068272\n0.509990\n07:48\n\n\n4\n0.061344\n0.045711\n0.671919\n07:57\n\n\n5\n0.055588\n0.044312\n0.681960\n08:00\n\n\n6\n0.047412\n0.038732\n0.722007\n08:06\n\n\n7\n0.042374\n0.045522\n0.673274\n08:08\n\n\n8\n0.037796\n0.034118\n0.755128\n08:07\n\n\n9\n0.030448\n0.033509\n0.759500\n08:13\n\n\n10\n0.030273\n0.034164\n0.754792\n08:07\n\n\n11\n0.025239\n0.029398\n0.788999\n08:04\n\n\n12\n0.025301\n0.028097\n0.798343\n08:02\n\n\n13\n0.022484\n0.027496\n0.802653\n08:06\n\n\n14\n0.019801\n0.025249\n0.818778\n08:07\n\n\n15\n0.016716\n0.025171\n0.819340\n08:12\n\n\n16\n0.015120\n0.024136\n0.826770\n08:10\n\n\n17\n0.012950\n0.023746\n0.829572\n07:56\n\n\n18\n0.012212\n0.024173\n0.826501\n07:47\n\n\n19\n0.012440\n0.024042\n0.827447\n07:50",
    "crumbs": [
      "example",
      "Fastai example"
    ]
  },
  {
    "objectID": "example/fastai.html#evaluation",
    "href": "example/fastai.html#evaluation",
    "title": "Fastai example",
    "section": "Evaluation",
    "text": "Evaluation\n\nval_preds, val_targets = learn.get_preds(dl=dls.valid)\n\n\n\n\n\n\n\n\n\n# Assuming you have a new CSV file for your test data\n# test_source = '../../_data/ossl-tfm/ossl-tfm-test.csv'\n# test_df = pd.read_csv(test_source)\n\n# # Create a new DataLoader for the test data\n# test_dl = learn.dls.test_dl(test_df)\n\n# # Get predictions on the test set\n# test_preds, test_targets = learn.get_preds(dl=test_dl)\n\n# # Now you can use test_preds and test_targets for further analysis\n\n\n# Convert predictions and targets to numpy arrays\n# val_preds = val_preds.numpy().flatten()\n# val_targets = val_targets.numpy()\n\n# Create a DataFrame with the results\nresults_df = pd.DataFrame({\n    'Predicted': val_preds,\n    'Actual': val_targets\n})\n\n# Display the first few rows of the results\nprint(results_df.head())\n\n# Calculate and print the R2 score\nfrom sklearn.metrics import r2_score\nr2 = r2_score(val_targets, val_preds)\nprint(f\"R2 Score on validation set: {r2:.4f}\")\n\n   Predicted    Actual\n0   0.153120  0.000000\n1   0.189220  0.184960\n2   0.325809  0.194201\n3   0.442900  0.262364\n4   0.335543  0.355799\nR2 Score on validation set: 0.8270\n\n\n\nval_preds_np = val_preds\nval_targets_np = val_targets\n\n# Apply the transformation: exp(y) - 1\nval_preds_transformed = np.exp(val_preds_np) - 1\nval_targets_transformed = np.exp(val_targets_np) - 1\n\n# Create a DataFrame with the results\nresults_df = pd.DataFrame({\n    'Predicted': val_preds_transformed,\n    'Actual': val_targets_transformed\n})\n\n# Display the first few rows of the results\nprint(results_df.head())\n\n# Calculate and print the R2 score\nfrom sklearn.metrics import r2_score\nr2 = r2_score(val_targets_transformed, val_preds_transformed)\nprint(f\"R2 Score on validation set (after transformation): {r2:.4f}\")\n\n# Calculate and print the MAPE, handling zero values\ndef mean_absolute_percentage_error(y_true, y_pred):\n    non_zero = (y_true != 0)\n    return np.mean(np.abs((y_true[non_zero] - y_pred[non_zero]) / y_true[non_zero])) * 100\n\nmape = mean_absolute_percentage_error(val_targets_transformed, val_preds_transformed)\nprint(f\"Mean Absolute Percentage Error (MAPE) on validation set: {mape:.2f}%\")\n\n# Calculate and print the MAE as an alternative metric\nfrom sklearn.metrics import mean_absolute_error\nmae = mean_absolute_error(val_targets_transformed, val_preds_transformed)\nprint(f\"Mean Absolute Error (MAE) on validation set: {mae:.4f}\")\n\n   Predicted   Actual\n0   0.165464  0.00000\n1   0.208306  0.20317\n2   0.385151  0.21434\n3   0.557217  0.30000\n4   0.398699  0.42732\nR2 Score on validation set (after transformation): 0.6978\nMean Absolute Percentage Error (MAPE) on validation set: 47.85%\nMean Absolute Error (MAE) on validation set: 0.1948\n\n\n\nplt.figure(figsize=(6, 6))\n\n# Use logarithmic bins for the colormap\nh = plt.hexbin(val_targets, val_preds, gridsize=65, \n               bins='log', cmap='Spectral_r', mincnt=1,\n               alpha=0.9)\n\n# Get the actual min and max counts from the hexbin data\ncounts = h.get_array()\nmin_count = counts[counts &gt; 0].min()  # Minimum non-zero count\nmax_count = counts.max()\n\n# Create a logarithmic colorbar\ncb = plt.colorbar(h, label='Count in bin', shrink=0.73)\ntick_locations = np.logspace(np.log10(min_count), np.log10(max_count), 5)\ncb.set_ticks(tick_locations)\ncb.set_ticklabels([f'{int(x)}' for x in tick_locations])\n\n# Add the diagonal line\nmin_val = min(val_targets.min(), val_preds.min())\nmax_val = max(val_targets.max(), val_preds.max())\nplt.plot([min_val, max_val], [min_val, max_val], 'k--', lw=1)\n\n# Set labels and title\nplt.xlabel('Actual Values')\nplt.ylabel('Predicted Values')\nplt.title('Predicted vs Actual Values (Hexbin with Log Scale)')\n\n# Add grid lines\nplt.grid(True, linestyle='--', alpha=0.65)\n\n# Set the same limits for both axes\nplt.xlim(min_val, max_val)\nplt.ylim(min_val, max_val)\n\n# Make the plot square\nplt.gca().set_aspect('equal', adjustable='box')\n\nplt.tight_layout()\nplt.show()\n\n# Print the range of counts in the hexbins\nprint(f\"Min non-zero count in hexbins: {min_count}\")\nprint(f\"Max count in hexbins: {max_count}\")\n\n\n\n\n\n\n\n\nMin non-zero count in hexbins: 1.0\nMax count in hexbins: 180.0\n\n\n\npath_model = Path('./models')\nlearn.export(path_model / '0.pkl')",
    "crumbs": [
      "example",
      "Fastai example"
    ]
  },
  {
    "objectID": "example/fastai.html#inference",
    "href": "example/fastai.html#inference",
    "title": "Fastai example",
    "section": "Inference",
    "text": "Inference\n\nossl_source = Path('../../_data/ossl-tfm/img')\nlearn.predict(ossl_source / '0a0a0c647671fd3030cc13ba5432eb88.png')\n\n\n\n\n\n\n\n\n((0.5229991674423218,), tensor([0.5230]), tensor([0.5230]))\n\n\n\ndf[df['fname'] == '0a0a0c647671fd3030cc13ba5432eb88.png']\n\n\n\n\n\n\n\n\nfname\nkex\n\n\n\n\n28867\n0a0a0c647671fd3030cc13ba5432eb88.png\n0.525379\n\n\n\n\n\n\n\n\nnp.exp(3) - 1\n\n19.085536923187668",
    "crumbs": [
      "example",
      "Fastai example"
    ]
  },
  {
    "objectID": "example/fastai.html#experiments",
    "href": "example/fastai.html#experiments",
    "title": "Fastai example",
    "section": "Experiments:",
    "text": "Experiments:\nColor scale: viridis | Discretization: percentiles = [i for i in range(60, 100)]\n\n\n\n\n\n\n\n\n\n\n\n\n\nModel\nImage Size\nLearning Rate\nEpochs\nR2 Score\nTime per Epoch\nFinetuning\nwith axis ticks\n\n\n\n\nResNet-18\n100\n1e-3\n10\n0.648\n05:12\nNo\nYes\n\n\nResNet-18\n224\n2e-3\n10\n0.69\n07:30\nNo\nYes\n\n\nResNet-18\n750 (original size)\n1e-3\n10\n0.71\n36:00\nNo\nYes\n\n\nResNet-18\n224\n2e-3\n20\n0.704\n07:30\nNo\nYes\n\n\nResNet-18\n224\n2e-3\n10\n0.71\n07:00\nNo\nNo\n\n\n\nDiscretization: percentiles = [i for i in range(20, 100)]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nModel\nImage Size\nLearning Rate\nEpochs\nR2 Score\nTime per Epoch\nFinetuning\nwith axis ticks\ncolour scale\n\n\n\n\nResNet-18\n224\n2e-3\n10\n0.7\n05:12\nNo\nNo\nviridis\n\n\nResNet-18\n224\n3e-3\n10\n0.71\n05:12\nNo\nNo\njet\n\n\n\nFrom now on with axis ticks is always No.\nDiscretization: esimated on 10000 cwt power percentiles [20, 30, 40, 50, 60, 70, 80, 90, 95, 97, 99]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nModel\nImage Size\nLearning Rate\nEpochs\nR2 Score\nTime per Epoch\nFinetuning\nremark\ncolour scale\n\n\n\n\nResNet-18\n224\n2e-3\n10\n0.71\n05:12\nNo\nNone\njet\n\n\nResNet-18\n224\n2e-3\n10\n0.685\n05:12\nNo\ny range added\njet\n\n\n\nFrom now on random splitter with 10% validation and random seed 41.\nDiscretization: esimated on 10000 cwt power percentiles [20, 30, 40, 50, 60, 70, 80, 90, 95, 97, 99]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nModel\nImage Size\nLearning Rate\nEpochs\nR2 Score\nTime per Epoch\nFinetuning\nremark\ncolour scale\n\n\n\n\nResNet-18\n224\n2e-3\n10\n0.7\n05:12\nNo\nPre-train & normalize: True\njet\n\n\nResNet-18\n224\n2e-3\n10\n0.796\n08:12\nNo\nNo Pre-train\njet\n\n\nResNet-18\n224\n3e-3\n10\n0.7\n05:12\nNo\nPre-train & normalize: False\njet\n\n\nResNet-18 (id=0)\n224\n2e-3\n20\n0.829\n08:12\nNo\nNo Pre-train (try 18 epochs)\njet",
    "crumbs": [
      "example",
      "Fastai example"
    ]
  },
  {
    "objectID": "example/ossl-vs-fk-eda.html",
    "href": "example/ossl-vs-fk-eda.html",
    "title": "OSSL vs Ringtrial",
    "section": "",
    "text": "import pandas as pd\nfrom pathlib import Path\n\nfrom sklearn.metrics import r2_score\nfrom uhina.loading import LoaderFactory, plot_spectra\nfrom uhina.preprocessing import TakeDerivative, SNV\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.decomposition import PCA, KernelPCA\nfrom sklearn.preprocessing import StandardScaler\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\npd.set_option('display.max_rows', 100)\n\nimport plotly\nimport plotly.express as px\nimport numpy as np\nfrom astartes import train_val_test_split",
    "crumbs": [
      "example",
      "OSSL vs Ringtrial"
    ]
  },
  {
    "objectID": "example/ossl-vs-fk-eda.html#loading-data",
    "href": "example/ossl-vs-fk-eda.html#loading-data",
    "title": "OSSL vs Ringtrial",
    "section": "Loading data",
    "text": "Loading data\n\nsrc = Path.home() / 'pro/data/woodwell-ringtrial/drive-download-20231013T123706Z-001'\nloader = LoaderFactory.get_loader(src, 'ringtrial')\ndata_rt = loader.load_data(analytes='potassium_cmolkg')\ndata_rt.ds = np.array([s.split('-rt')[0] for s in data_rt.sample_indices])\nprint(f'X shape: {data_rt.X.shape}')\n\nplot_spectra(data_rt, n_spectra=100, snv=True, alpha=0.2, figsize=(12, 3));\n\nX shape: (1400, 1676)\n\n\n\n\n\n\n\n\n\n\nsrc = Path.home() / '.lssm/data/ossl/ossl_all_L0_v1.2.csv.gz'\nloader = LoaderFactory.get_loader(src, 'ossl', spectra_type='mir')\ndata_ossl = loader.load_data(analytes='k.ext_usda.a725_cmolc.kg')\nprint(f'X shape: {data_ossl.X.shape}')\n\nLoading data from /Users/franckalbinet/.lssm/data/ossl/ossl_all_L0_v1.2.csv.gz ...\nX shape: (57674, 1676)\n\n\n\nplot_spectra(data_ossl, n_spectra=100, snv=True, alpha=0.2, figsize=(12, 3))\n\n(&lt;Figure size 1200x300 with 1 Axes&gt;,\n &lt;Axes: xlabel='Wavenumber ($cm^{-1}$)', ylabel='Absorbance'&gt;)\n\n\n\n\n\n\n\n\n\n\ndef pca_rt_ossl(data_rt, data_ossl):\n    # Combine the spectra from both datasets\n    X_combined = np.vstack((data_rt.X, data_ossl.X))\n    \n    # Create the pipeline\n    pipe = Pipeline([\n        ('SNV', SNV()),\n        ('Derivative', TakeDerivative()),\n        ('Scaler', StandardScaler()),  \n        ('PCA', PCA(n_components=3))\n    ])\n\n    # Fit and transform the combined data\n    X_pca_combined = pipe.fit_transform(X_combined)\n    \n    # Split the results back into rt and ossl\n    data_rt.X_pca = X_pca_combined[:data_rt.X.shape[0]]\n    data_ossl.X_pca = X_pca_combined[data_rt.X.shape[0]:]\n    \n    return data_rt, data_ossl\n\n\ndata_rt, data_ossl = pca_rt_ossl(data_rt, data_ossl)\n\n\nfrom matplotlib import pyplot as plt\nplt.scatter(data_ossl.X_pca[:, 0], data_ossl.X_pca[:, 1], s=5, alpha=0.1)\n\n\n\n\n\n\n\n\n\nn_samples = 100\nidx = np.random.choice(data_ossl.X_pca.shape[0], \n                       size=n_samples, replace=False)\n\nX_ossl_subset = data_ossl.X_pca[idx]\n\n\nlut_ossl_ds = {i: ds for i, ds in enumerate(data_ossl.dataset_labels)}\n\n\ndata_ossl.dataset_names\n\narray([0, 0, 0, ..., 3, 3, 3])\n\n\n\nnp.vectorize(lut_ossl_ds.get)(data_ossl.dataset_names)\n\narray(['GARRETT.SSL', 'GARRETT.SSL', 'GARRETT.SSL', ...,\n       'LUCAS.WOODWELL.SSL', 'LUCAS.WOODWELL.SSL', 'LUCAS.WOODWELL.SSL'],\n      dtype='&lt;U18')\n\n\n\ndata_rt.X_pca\n\narray([[-37.57209416,  10.0194439 ,   1.41901894],\n       [ 24.05922823,  10.83135662,  12.43538485],\n       [  8.09090194, -26.63507173,   7.36763935],\n       ...,\n       [  8.44862862,  -4.47373073,   2.51161567],\n       [ 15.9657049 ,   8.60238863, -19.86332133],\n       [  2.45832757,   6.53856188,   3.22457499]])\n\n\n\nmask_rt_ds = data_rt.ds == 'kssl'\n\n\ndata_ossl.X_pca\n\narray([[  2.45822505,  16.4823169 ,   9.00422903],\n       [ -2.36297831,  10.87565108,   7.6014877 ],\n       [ -4.66533181,  11.81300838,   7.77196598],\n       ...,\n       [ 33.2311886 ,  -6.53547903,   8.0031913 ],\n       [  8.18561655,  24.05135848,  14.03594385],\n       [-11.41377595,   8.67332126,  -6.78131327]])\n\n\n\ndef data_to_df(data_ossl, data_rt, \n               n_samples_ossl=100, rt_ds='kssl',\n               cols=['PC1', 'PC2', 'PC3']):\n    lut_ossl_ds = {i: ds for i, ds in enumerate(data_ossl.dataset_labels)}\n    idx = np.random.choice(data_ossl.X_pca.shape[0], size=n_samples_ossl, replace=False)\n    X_ossl_subset = data_ossl.X_pca[idx,:]\n    ds_ossl = np.vectorize(lut_ossl_ds.get)(data_ossl.dataset_names[idx])\n    \n    df_ossl = pd.DataFrame(X_ossl_subset, columns=cols)\n    df_ossl['ds'] = ds_ossl\n    # return df_ossl\n    \n    mask = data_rt.ds == rt_ds\n    \n    X_rt = data_rt.X_pca[mask]\n    df_rt = pd.DataFrame(X_rt, columns=cols)\n    df_rt['ds'] = rt_ds + '-rt'\n    # df_rt = pd.DataFrame(np.c_[X_rt, np.full(np.sum(mask), rt_ds + '-rt')], columns=cols)\n    \n    return pd.concat([df_ossl, df_rt], axis=0, ignore_index=True)\n\n\ndf = data_to_df(data_ossl, data_rt, n_samples_ossl=200)\n\n\ndef plot_scatter3d(df, size_dict=None, default_opacity=0.7):\n    \"\"\"\n    Generates a nicely formatted 3D scatter plot of the data with different symbols, colors, and sizes for each dataset.\n\n    Args:\n        df (pd.DataFrame): DataFrame containing the data with columns 'PC1', 'PC2', 'PC3', 'ds'\n        size_dict (dict, optional): Dictionary mapping dataset names to dot sizes. Defaults to None.\n        default_opacity (float, optional): Default opacity for all points. Defaults to 0.7.\n    \"\"\"\n    # Default size\n    default_size = 20\n\n    # If size_dict is not provided, initialize it with default values\n    if size_dict is None:\n        size_dict = {}\n\n    # Create dot_size column based on the ds column, using defaults if not in dict\n    df['dot_size'] = df['ds'].map(lambda x: size_dict.get(x, default_size))\n\n    fig = px.scatter_3d(\n        df,\n        x='PC1',\n        y='PC2',\n        z='PC3',\n        color='ds',\n        symbol='ds',\n        size='dot_size',\n        opacity=default_opacity,\n        hover_data=['ds'],\n        color_discrete_sequence=px.colors.qualitative.Set1,\n    )\n\n    fig.update_traces(marker=dict(line=dict(width=0)))\n\n    fig.update_layout(\n        scene=dict(\n            xaxis_title='PC1',\n            yaxis_title='PC2',\n            zaxis_title='PC3'\n        ),\n        legend_title='Dataset',\n        height=800,\n        width=1000,\n    )\n\n    fig.show()\n\n\ndata_ossl.dataset_labels\n\narray(['GARRETT.SSL', 'ICRAF.ISRIC', 'KSSL.SSL', 'LUCAS.WOODWELL.SSL'],\n      dtype=object)\n\n\n\nnp.unique(data_rt.ds)\n\narray(['agrocares', 'argonne', 'csu-il', 'eth-alpha-1', 'eth-alpha-2',\n       'eth-vertex', 'iaea-aug2022', 'kssl', 'landcare', 'lesotho', 'msu',\n       'osu', 'rothamsted', 'scion', 'ughent', 'uiuc', 'usp',\n       'uwisc-fine', 'woodwell-alpha', 'woodwell-vertex'], dtype='&lt;U15')\n\n\n\nsize_dict = {\n    'KSSL.SSL': 1,\n    'GARRETT.SSL': 3,\n    'ICRAF.ISRIC': 3,\n    'LUCAS.WOODWELL.SSL': 3,\n    \n}\n\nplot_scatter3d(\n    data_to_df(data_ossl, data_rt, n_samples_ossl=5000,  rt_ds='iaea-aug2022'), \n    size_dict=size_dict)\n\nUnable to display output for mime type(s): application/vnd.plotly.v1+json",
    "crumbs": [
      "example",
      "OSSL vs Ringtrial"
    ]
  },
  {
    "objectID": "example/fastai-bw-augment.html",
    "href": "example/fastai-bw-augment.html",
    "title": "Fastai BW data augmentation",
    "section": "",
    "text": "# setting up pod and pip install uhina\n# accessing a pod terminal\n\n# 1. To get access to the pod ip adress: runpodctl get pod -a\n# 2. ssh into the pod: ssh root@&lt;ip-address&gt; -p 58871 -i ~/.ssh/id_ed25519\n\n\n# runpodctl send uhina \n# pip install -e '.[dev]'\n\n# git clone https://github.com/franckalbinet/uhina.git\n# pip install uhina\n# runpodctl send im-bw \n# runpodctl send ossl-tfm.csv",
    "crumbs": [
      "example",
      "Fastai BW data augmentation"
    ]
  },
  {
    "objectID": "example/fastai-bw-augment.html#runpod-setup",
    "href": "example/fastai-bw-augment.html#runpod-setup",
    "title": "Fastai BW data augmentation",
    "section": "",
    "text": "# setting up pod and pip install uhina\n# accessing a pod terminal\n\n# 1. To get access to the pod ip adress: runpodctl get pod -a\n# 2. ssh into the pod: ssh root@&lt;ip-address&gt; -p 58871 -i ~/.ssh/id_ed25519\n\n\n# runpodctl send uhina \n# pip install -e '.[dev]'\n\n# git clone https://github.com/franckalbinet/uhina.git\n# pip install uhina\n# runpodctl send im-bw \n# runpodctl send ossl-tfm.csv",
    "crumbs": [
      "example",
      "Fastai BW data augmentation"
    ]
  },
  {
    "objectID": "example/fastai-bw-augment.html#loading-data",
    "href": "example/fastai-bw-augment.html#loading-data",
    "title": "Fastai BW data augmentation",
    "section": "Loading data",
    "text": "Loading data\n\nimport pandas as pd\nfrom pathlib import Path\nimport fastcore.all as fc\n\nfrom fastai.data.all import *\nfrom fastai.vision.all import *\nfrom multiprocessing import cpu_count\nfrom uhina.augment import Quantize\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\n\nossl_source = '../../_data/ossl-tfm/im-targets-lut.csv'\ndf = pd.read_csv(ossl_source); df.head()\n\n\n\n\n\n\n\n\nfname\nkex\n\n\n\n\n0\n3998362dd2659e2252cd7f38b43c9b1f.png\n0.182895\n\n\n1\n2bab4dbbac073b8648475ad50d40eb95.png\n0.082741\n\n\n2\n29213d2193232be8867d85dec463ec00.png\n0.089915\n\n\n3\n8b1ee9146c026faee20a40df86736864.png\n0.135030\n\n\n4\n6e8e9d1105e7da7055555cb5d310df5f.png\n0.270421\n\n\n\n\n\n\n\n\ndf['kex'].min(), df['kex'].max()\n\n(0.0, 3.6521352871126975)\n\n\n\n# start = np.random.uniform(1, 50); print(start)\n# end = np.random.uniform(90.1, 99.5); print(end)\n# steps = np.random.randint(5, 100); print(steps)\n# percentiles = torch.linspace(start=start, end=end, steps=steps)\n# percentiles\n\n\nfrom sklearn.model_selection import train_test_split\ndf_train, df_valid = train_test_split(df, test_size=0.1, random_state=41)\nidx_train, idx_valid = df_train.index, df_valid.index\nlen(idx_train), len(idx_valid)\n\n(51906, 5768)\n\n\n\ndef splitter(items): return [idx_train, idx_valid]\n\n\nOrderedRation\n\n\nclass OrderedQuantize(Quantize):\n    order = 0  # Apply first\n\nclass OrderedRatioResize(RatioResize):\n    order = 1  # Apply second\n\nossl = DataBlock(\n    blocks=(ImageBlock, RegressionBlock),\n    get_x=ColReader(0, pref='../../_data/ossl-tfm/im/'),\n    get_y=ColReader(1),\n    splitter=splitter,\n    item_tfms=[OrderedQuantize(n_valid=len(idx_valid))],\n    batch_tfms=[\n        OrderedRatioResize(224),\n        Normalize.from_stats(*imagenet_stats)\n    ]\n)\n\n\nossl = DataBlock(blocks=(ImageBlock, RegressionBlock),\n                get_x=ColReader(0, pref='../../_data/ossl-tfm/im/'),\n                get_y=ColReader(1),\n                # batch_tfms=Normalize.from_stats(*imagenet_stats),\n                item_tfms=[Quantize(n_valid=len(idx_valid))],\n                batch_tfms=[RatioResize(224), ],\n                # splitter=RandomSplitter(valid_pct=0.1, seed=41)\n                splitter=splitter\n#    batch_tfms=aug_transforms()\n)\n\n\n# ossl.summary(df)\n\n\ndls = ossl.dataloaders(df)\n\n\ndls.show_batch(nrows=6, ncols=2, figsize=(12, 13))\n\n\n\n\n\n\n\n\n\n# Unfrozen, 30 epochs, 1.5e-3 =&gt; r2: 0.85\n# Frozen,\n\n\nlearn = vision_learner(dls, resnet18, pretrained=False, metrics=R2Score()).to_fp16()\n\n\n# learn = load_learner ('./models/bw-data-augment-0.pkl', cpu=True)\n\n\nlearn.lr_find()\n\n\n\n\n\n\n    \n      \n      0.00% [0/1 00:00&lt;?]\n    \n    \n\n\n    \n      \n      1.73% [14/811 00:45&lt;42:44 4.8972]\n    \n    \n\n\n\n---------------------------------------------------------------------------\nKeyboardInterrupt                         Traceback (most recent call last)\nCell In[88], line 1\n----&gt; 1 learn.lr_find()\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/fastai/callback/schedule.py:295, in lr_find(self, start_lr, end_lr, num_it, stop_div, show_plot, suggest_funcs)\n    293 n_epoch = num_it//len(self.dls.train) + 1\n    294 cb=LRFinder(start_lr=start_lr, end_lr=end_lr, num_it=num_it, stop_div=stop_div)\n--&gt; 295 with self.no_logging(): self.fit(n_epoch, cbs=cb)\n    296 if suggest_funcs is not None:\n    297     lrs, losses = tensor(self.recorder.lrs[num_it//10:-5]), tensor(self.recorder.losses[num_it//10:-5])\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/fastai/learner.py:266, in Learner.fit(self, n_epoch, lr, wd, cbs, reset_opt, start_epoch)\n    264 self.opt.set_hypers(lr=self.lr if lr is None else lr)\n    265 self.n_epoch = n_epoch\n--&gt; 266 self._with_events(self._do_fit, 'fit', CancelFitException, self._end_cleanup)\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/fastai/learner.py:201, in Learner._with_events(self, f, event_type, ex, final)\n    200 def _with_events(self, f, event_type, ex, final=noop):\n--&gt; 201     try: self(f'before_{event_type}');  f()\n    202     except ex: self(f'after_cancel_{event_type}')\n    203     self(f'after_{event_type}');  final()\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/fastai/learner.py:255, in Learner._do_fit(self)\n    253 for epoch in range(self.n_epoch):\n    254     self.epoch=epoch\n--&gt; 255     self._with_events(self._do_epoch, 'epoch', CancelEpochException)\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/fastai/learner.py:201, in Learner._with_events(self, f, event_type, ex, final)\n    200 def _with_events(self, f, event_type, ex, final=noop):\n--&gt; 201     try: self(f'before_{event_type}');  f()\n    202     except ex: self(f'after_cancel_{event_type}')\n    203     self(f'after_{event_type}');  final()\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/fastai/learner.py:249, in Learner._do_epoch(self)\n    248 def _do_epoch(self):\n--&gt; 249     self._do_epoch_train()\n    250     self._do_epoch_validate()\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/fastai/learner.py:241, in Learner._do_epoch_train(self)\n    239 def _do_epoch_train(self):\n    240     self.dl = self.dls.train\n--&gt; 241     self._with_events(self.all_batches, 'train', CancelTrainException)\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/fastai/learner.py:201, in Learner._with_events(self, f, event_type, ex, final)\n    200 def _with_events(self, f, event_type, ex, final=noop):\n--&gt; 201     try: self(f'before_{event_type}');  f()\n    202     except ex: self(f'after_cancel_{event_type}')\n    203     self(f'after_{event_type}');  final()\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/fastai/learner.py:207, in Learner.all_batches(self)\n    205 def all_batches(self):\n    206     self.n_iter = len(self.dl)\n--&gt; 207     for o in enumerate(self.dl): self.one_batch(*o)\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/fastai/learner.py:237, in Learner.one_batch(self, i, b)\n    235 b = self._set_device(b)\n    236 self._split(b)\n--&gt; 237 self._with_events(self._do_one_batch, 'batch', CancelBatchException)\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/fastai/learner.py:203, in Learner._with_events(self, f, event_type, ex, final)\n    201 try: self(f'before_{event_type}');  f()\n    202 except ex: self(f'after_cancel_{event_type}')\n--&gt; 203 self(f'after_{event_type}');  final()\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/fastai/learner.py:174, in Learner.__call__(self, event_name)\n--&gt; 174 def __call__(self, event_name): L(event_name).map(self._call_one)\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/fastcore/foundation.py:159, in L.map(self, f, *args, **kwargs)\n--&gt; 159 def map(self, f, *args, **kwargs): return self._new(map_ex(self, f, *args, gen=False, **kwargs))\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/fastcore/basics.py:899, in map_ex(iterable, f, gen, *args, **kwargs)\n    897 res = map(g, iterable)\n    898 if gen: return res\n--&gt; 899 return list(res)\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/fastcore/basics.py:884, in bind.__call__(self, *args, **kwargs)\n    882     if isinstance(v,_Arg): kwargs[k] = args.pop(v.i)\n    883 fargs = [args[x.i] if isinstance(x, _Arg) else x for x in self.pargs] + args[self.maxi+1:]\n--&gt; 884 return self.func(*fargs, **kwargs)\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/fastai/learner.py:178, in Learner._call_one(self, event_name)\n    176 def _call_one(self, event_name):\n    177     if not hasattr(event, event_name): raise Exception(f'missing {event_name}')\n--&gt; 178     for cb in self.cbs.sorted('order'): cb(event_name)\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/fastai/callback/core.py:62, in Callback.__call__(self, event_name)\n     60 res = None\n     61 if self.run and _run: \n---&gt; 62     try: res = getcallable(self, event_name)()\n     63     except (CancelBatchException, CancelBackwardException, CancelEpochException, CancelFitException, CancelStepException, CancelTrainException, CancelValidException): raise\n     64     except Exception as e: raise modify_exception(e, f'Exception occured in `{self.__class__.__name__}` when calling event `{event_name}`:\\n\\t{e.args[0]}', replace=True)\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/fastai/learner.py:562, in Recorder.after_batch(self)\n    560 if len(self.yb) == 0: return\n    561 mets = self._train_mets if self.training else self._valid_mets\n--&gt; 562 for met in mets: met.accumulate(self.learn)\n    563 if not self.training: return\n    564 self.lrs.append(self.opt.hypers[-1]['lr'])\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/fastai/learner.py:511, in AvgSmoothLoss.accumulate(self, learn)\n    509 def accumulate(self, learn):\n    510     self.count += 1\n--&gt; 511     self.val = torch.lerp(to_detach(learn.loss.mean()), self.val, self.beta)\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/fastai/torch_core.py:246, in to_detach(b, cpu, gather)\n    244     if gather: x = maybe_gather(x)\n    245     return x.cpu() if cpu else x\n--&gt; 246 return apply(_inner, b, cpu=cpu, gather=gather)\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/fastai/torch_core.py:226, in apply(func, x, *args, **kwargs)\n    224 if is_listy(x): return type(x)([apply(func, o, *args, **kwargs) for o in x])\n    225 if isinstance(x,(dict,MutableMapping)): return {k: apply(func, v, *args, **kwargs) for k,v in x.items()}\n--&gt; 226 res = func(x, *args, **kwargs)\n    227 return res if x is None else retain_type(res, x)\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/fastai/torch_core.py:245, in to_detach.&lt;locals&gt;._inner(x, cpu, gather)\n    243 x = x.detach()\n    244 if gather: x = maybe_gather(x)\n--&gt; 245 return x.cpu() if cpu else x\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/fastai/torch_core.py:384, in TensorBase.__torch_function__(cls, func, types, args, kwargs)\n    382 if cls.debug and func.__name__ not in ('__str__','__repr__'): print(func, types, args, kwargs)\n    383 if _torch_handled(args, cls._opt, func): types = (torch.Tensor,)\n--&gt; 384 res = super().__torch_function__(func, types, args, ifnone(kwargs, {}))\n    385 dict_objs = _find_args(args) if args else _find_args(list(kwargs.values()))\n    386 if issubclass(type(res),TensorBase) and dict_objs: res.set_meta(dict_objs[0],as_copy=True)\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/torch/_tensor.py:1437, in Tensor.__torch_function__(cls, func, types, args, kwargs)\n   1434     return NotImplemented\n   1436 with _C.DisableTorchFunctionSubclass():\n-&gt; 1437     ret = func(*args, **kwargs)\n   1438     if func in get_default_nowrap_functions():\n   1439         return ret\n\nKeyboardInterrupt: \n\n\n\n\n# learn.fit_one_cycle(5, 3e-3)",
    "crumbs": [
      "example",
      "Fastai BW data augmentation"
    ]
  },
  {
    "objectID": "example/fastai-bw-augment.html#evaluation",
    "href": "example/fastai-bw-augment.html#evaluation",
    "title": "Fastai BW data augmentation",
    "section": "Evaluation",
    "text": "Evaluation\n\nval_preds, val_targets = learn.get_preds(dl=dls.valid)\n\n\n\n\n\n\n\n\n\nval_preds_tta, val_targets_tta = learn.tta(dl=dls.valid)\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n# EXAMPLE of TTA on single item\n# from fastai.vision.all import *\n\n# # Define your TTA transforms\n# tta_tfms = [\n#     RandomResizedCrop(224, min_scale=0.5),\n#     Flip(),\n#     Rotate(degrees=(-15, 15)),\n#     Brightness(max_lighting=0.2),\n#     Contrast(max_lighting=0.2)\n# ]\n\n# # Create a pipeline of TTA transformations\n# tta_pipeline = Pipeline(tta_tfms)\n\n# # Load your model\n# learn = load_learner('path/to/your/model.pkl')\n\n# # Define the input data (e.g., an image)\n# input_data = PILImage.create('path/to/your/image.jpg')\n\n# # Apply TTA transforms to the input data and make predictions\n# predictions = []\n# for _ in range(5):  # Apply 5 different augmentations\n#     augmented_data = tta_pipeline(input_data)\n#     prediction = learn.predict(augmented_data)\n#     predictions.append(prediction)\n\n# # Average the predictions\n# average_prediction = sum(predictions) / len(predictions)\n\n# print(average_prediction)\n\n\n# Assuming you have a new CSV file for your test data\n# test_source = '../../_data/ossl-tfm/ossl-tfm-test.csv'\n# test_df = pd.read_csv(test_source)\n\n# # Create a new DataLoader for the test data\n# test_dl = learn.dls.test_dl(test_df)\n\n# # Get predictions on the test set\n# test_preds, test_targets = learn.get_preds(dl=test_dl)\n\n# # Now you can use test_preds and test_targets for further analysis\n\n\n# Convert predictions and targets to numpy arrays\ndef assess_model(val_preds, val_targets):\n    val_preds = val_preds.numpy().flatten()\n    val_targets = val_targets.numpy()\n\n    # Create a DataFrame with the results\n    results_df = pd.DataFrame({\n        'Predicted': val_preds,\n        'Actual': val_targets\n    })\n\n    # Display the first few rows of the results\n    print(results_df.head())\n\n    # Calculate and print the R2 score\n    from sklearn.metrics import r2_score\n    r2 = r2_score(val_targets, val_preds)\n    print(f\"R2 Score on validation set: {r2:.4f}\")\n\n\nassess_model(val_preds, val_targets)\n\n   Predicted    Actual\n0   0.312483  0.000000\n1   0.126990  0.184960\n2   0.365726  0.194201\n3   0.239089  0.262364\n4   0.402980  0.355799\nR2 Score on validation set: 0.8325\n\n\n\nassess_model(val_preds_tta, val_targets_tta)\n\n   Predicted    Actual\n0   0.246857  0.000000\n1   0.148590  0.184960\n2   0.371643  0.194201\n3   0.226535  0.262364\n4   0.407333  0.355799\nR2 Score on validation set: 0.8378\n\n\n\nval_preds_np = val_preds\nval_targets_np = val_targets\n\n# Apply the transformation: exp(y) - 1\nval_preds_transformed = np.exp(val_preds_np) - 1\nval_targets_transformed = np.exp(val_targets_np) - 1\n\n# Create a DataFrame with the results\nresults_df = pd.DataFrame({\n    'Predicted': val_preds_transformed,\n    'Actual': val_targets_transformed\n})\n\n# Display the first few rows of the results\nprint(results_df.head())\n\n# Calculate and print the R2 score\nfrom sklearn.metrics import r2_score\nr2 = r2_score(val_targets_transformed, val_preds_transformed)\nprint(f\"R2 Score on validation set (after transformation): {r2:.4f}\")\n\n# Calculate and print the MAPE, handling zero values\ndef mean_absolute_percentage_error(y_true, y_pred):\n    non_zero = (y_true != 0)\n    return np.mean(np.abs((y_true[non_zero] - y_pred[non_zero]) / y_true[non_zero])) * 100\n\nmape = mean_absolute_percentage_error(val_targets_transformed, val_preds_transformed)\nprint(f\"Mean Absolute Percentage Error (MAPE) on validation set: {mape:.2f}%\")\n\n# Calculate and print the MAE as an alternative metric\nfrom sklearn.metrics import mean_absolute_error\nmae = mean_absolute_error(val_targets_transformed, val_preds_transformed)\nprint(f\"Mean Absolute Error (MAE) on validation set: {mae:.4f}\")\n\n   Predicted   Actual\n0   0.366814  0.00000\n1   0.135405  0.20317\n2   0.441560  0.21434\n3   0.270092  0.30000\n4   0.496277  0.42732\nR2 Score on validation set (after transformation): 0.6936\nMean Absolute Percentage Error (MAPE) on validation set: 50.72%\nMean Absolute Error (MAE) on validation set: 0.1956\n\n\n\nplt.figure(figsize=(6, 6))\n\n# Use logarithmic bins for the colormap\nh = plt.hexbin(val_targets, val_preds, gridsize=65, \n               bins='log', cmap='Spectral_r', mincnt=1,\n               alpha=0.9)\n\n# Get the actual min and max counts from the hexbin data\ncounts = h.get_array()\nmin_count = counts[counts &gt; 0].min()  # Minimum non-zero count\nmax_count = counts.max()\n\n# Create a logarithmic colorbar\ncb = plt.colorbar(h, label='Count in bin', shrink=0.73)\ntick_locations = np.logspace(np.log10(min_count), np.log10(max_count), 5)\ncb.set_ticks(tick_locations)\ncb.set_ticklabels([f'{int(x)}' for x in tick_locations])\n\n# Add the diagonal line\nmin_val = min(val_targets.min(), val_preds.min())\nmax_val = max(val_targets.max(), val_preds.max())\nplt.plot([min_val, max_val], [min_val, max_val], 'k--', lw=1)\n\n# Set labels and title\nplt.xlabel('Actual Values')\nplt.ylabel('Predicted Values')\nplt.title('Predicted vs Actual Values (Hexbin with Log Scale)')\n\n# Add grid lines\nplt.grid(True, linestyle='--', alpha=0.65)\n\n# Set the same limits for both axes\nplt.xlim(min_val, max_val)\nplt.ylim(min_val, max_val)\n\n# Make the plot square\nplt.gca().set_aspect('equal', adjustable='box')\n\nplt.tight_layout()\nplt.show()\n\n# Print the range of counts in the hexbins\nprint(f\"Min non-zero count in hexbins: {min_count}\")\nprint(f\"Max count in hexbins: {max_count}\")\n\n\n\n\n\n\n\n\nMin non-zero count in hexbins: 1.0\nMax count in hexbins: 157.0\n\n\n\npath_model = Path('./models')\nlearn.export(path_model / '0.pkl')",
    "crumbs": [
      "example",
      "Fastai BW data augmentation"
    ]
  },
  {
    "objectID": "example/fastai-bw-augment.html#inference",
    "href": "example/fastai-bw-augment.html#inference",
    "title": "Fastai BW data augmentation",
    "section": "Inference",
    "text": "Inference\n\nossl_source = Path('../../_data/ossl-tfm/img')\nlearn.predict(ossl_source / '0a0a0c647671fd3030cc13ba5432eb88.png')\n\n\n\n\n\n\n\n\n((0.5229991674423218,), tensor([0.5230]), tensor([0.5230]))\n\n\n\ndf[df['fname'] == '0a0a0c647671fd3030cc13ba5432eb88.png']\n\n\n\n\n\n\n\n\nfname\nkex\n\n\n\n\n28867\n0a0a0c647671fd3030cc13ba5432eb88.png\n0.525379\n\n\n\n\n\n\n\n\nnp.exp(3) - 1\n\n19.085536923187668",
    "crumbs": [
      "example",
      "Fastai BW data augmentation"
    ]
  },
  {
    "objectID": "example/fastai-bw-augment.html#experiments",
    "href": "example/fastai-bw-augment.html#experiments",
    "title": "Fastai BW data augmentation",
    "section": "Experiments:",
    "text": "Experiments:\nColor scale: viridis | Discretization: percentiles = [i for i in range(60, 100)]\n\n\n\n\n\n\n\n\n\n\n\n\n\nModel\nImage Size\nLearning Rate\nEpochs\nR2 Score\nTime per Epoch\nFinetuning\nwith axis ticks\n\n\n\n\nResNet-18\n100\n1e-3\n10\n0.648\n05:12\nNo\nYes\n\n\nResNet-18\n224\n2e-3\n10\n0.69\n07:30\nNo\nYes\n\n\nResNet-18\n750 (original size)\n1e-3\n10\n0.71\n36:00\nNo\nYes\n\n\nResNet-18\n224\n2e-3\n20\n0.704\n07:30\nNo\nYes\n\n\nResNet-18\n224\n2e-3\n10\n0.71\n07:00\nNo\nNo\n\n\n\nDiscretization: percentiles = [i for i in range(20, 100)]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nModel\nImage Size\nLearning Rate\nEpochs\nR2 Score\nTime per Epoch\nFinetuning\nwith axis ticks\ncolour scale\n\n\n\n\nResNet-18\n224\n2e-3\n10\n0.7\n05:12\nNo\nNo\nviridis\n\n\nResNet-18\n224\n3e-3\n10\n0.71\n05:12\nNo\nNo\njet\n\n\n\nFrom now on with axis ticks is always No.\nDiscretization: esimated on 10000 cwt power percentiles [20, 30, 40, 50, 60, 70, 80, 90, 95, 97, 99]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nModel\nImage Size\nLearning Rate\nEpochs\nR2 Score\nTime per Epoch\nFinetuning\nremark\ncolour scale\n\n\n\n\nResNet-18\n224\n2e-3\n10\n0.71\n05:12\nNo\nNone\njet\n\n\nResNet-18\n224\n2e-3\n10\n0.685\n05:12\nNo\ny range added\njet\n\n\n\nFrom now on random splitter with 10% validation and random seed 41.\nDiscretization: esimated on 10000 cwt power percentiles [20, 30, 40, 50, 60, 70, 80, 90, 95, 97, 99]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nModel\nImage Size\nLearning Rate\nEpochs\nR2 Score\nTime per Epoch\nFinetuning\nremark\ncolour scale\n\n\n\n\nResNet-18\n224\n2e-3\n10\n0.7\n05:12\nNo\nPre-train & normalize: True\njet\n\n\nResNet-18\n224\n2e-3\n10\n0.796\n08:12\nNo\nNo Pre-train\njet\n\n\nResNet-18\n224\n3e-3\n10\n0.7\n05:12\nNo\nPre-train & normalize: False\njet\n\n\nResNet-18 (id=0)\n224\n2e-3\n20\n0.829\n08:12\nNo\nNo Pre-train (try 18 epochs)\njet",
    "crumbs": [
      "example",
      "Fastai BW data augmentation"
    ]
  },
  {
    "objectID": "cli.html",
    "href": "cli.html",
    "title": "Command Line Interface",
    "section": "",
    "text": "source\n\nmain\n\n main (config:pathlib.Path)\n\nConvert spectra to wavelet images using configuration from a file.\n\n\n\n\nType\nDetails\n\n\n\n\nconfig\nPath\nPath to the configuration file\n\n\n\n\n\nExported source\n@call_parse\ndef main(\n    config: Path, # Path to the configuration file\n    ):\n    \"Convert spectra to wavelet images using configuration from a file.\"\n    cfg = load_config(config)\n    params = extract_params(cfg)\n    loader = get_loader(params)\n    data = loader.load_data(params['analytes'])\n    create_output_files(data, params)\n\n\n\nsource\n\n\nload_config\n\n load_config (config_path:pathlib.Path)\n\nLoad the configuration from a YAML file.\n\n\nExported source\ndef load_config(config_path: Path) -&gt; dict:\n    \"Load the configuration from a YAML file.\"\n    with open(config_path, 'r') as f:\n        return yaml.safe_load(f)\n\n\n\nsource\n\n\nextract_params\n\n extract_params (cfg:dict)\n\nExtract parameters from the configuration.\n\n\nExported source\ndef extract_params(cfg: dict) -&gt; dict:\n    \"Extract parameters from the configuration.\"\n    return {\n        'src': cfg['src'],\n        'dir_out': cfg['dir_out'],\n        'img_dir': cfg.get('img_dir', 'im'),\n        'dataset': cfg.get('dataset', 'ossl'),\n        'spectra_type': cfg.get('spectra_type', 'mir'),\n        'analytes': cfg.get('analytes', 'k.ext_usda.a725_cmolc.kg'),\n        'n_samples': cfg.get('n_samples'),\n        'batch_size': cfg.get('batch_size', 10)\n    }\n\n\n\nsource\n\n\nget_loader\n\n get_loader (params:dict)\n\nGet the loader from the parameters.\n\n\nExported source\ndef get_loader(params: dict):\n    \"Get the loader from the parameters.\"\n    loader_kwargs = {'spectra_type': params['spectra_type']} if params['dataset'] == 'ossl' else {}\n    return LoaderFactory.get_loader(params['src'], params['dataset'], **loader_kwargs)\n\n\n\nsource\n\n\ncreate_output_files\n\n create_output_files (data, params)\n\nCreate the output files.\n\n\nExported source\ndef create_output_files(data, params):\n    \"Create the output files.\"\n    print(f'Creating image target csv in {params[\"dir_out\"]} ...')\n    create_image_target_csv(data, \n                            n_samples=params['n_samples'], \n                            output_dir=Path(params['dir_out']))  \n    \n    print(f'Creating wavelet images in {Path(params[\"dir_out\"])/params[\"img_dir\"]} ...')\n    convert_to_wavelet_images(data, \n                              output_dir=Path(params['dir_out'])/params['img_dir'], \n                              n_samples=params['n_samples'],\n                              batch_size=params['batch_size'])",
    "crumbs": [
      "Command Line Interface"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Uhina",
    "section": "",
    "text": "Converts 1D infrared spectra to 2D (Continuous Wavelet Transform) representations.",
    "crumbs": [
      "Uhina"
    ]
  },
  {
    "objectID": "index.html#developer-guide",
    "href": "index.html#developer-guide",
    "title": "Uhina",
    "section": "Developer Guide",
    "text": "Developer Guide\nIf you are new to using nbdev here are some useful pointers to get you started.\n\nInstall uhina in Development mode\n# make sure uhina package is installed in development mode\n$ pip install -e .\n\n# make changes under nbs/ directory\n# ...\n\n# compile to have changes apply to uhina\n$ nbdev_prepare",
    "crumbs": [
      "Uhina"
    ]
  },
  {
    "objectID": "index.html#usage",
    "href": "index.html#usage",
    "title": "Uhina",
    "section": "Usage",
    "text": "Usage\n\nInstallation\nInstall latest from the GitHub repository:\n$ pip install git+https://github.com/franckalbinet/uhina.git\nor from pypi\n$ pip install uhina\n\n\nDocumentation\nDocumentation can be found hosted on this GitHub repository’s pages. Additionally you can find package manager specific guidelines o pypi respectively.",
    "crumbs": [
      "Uhina"
    ]
  },
  {
    "objectID": "index.html#how-to-use",
    "href": "index.html#how-to-use",
    "title": "Uhina",
    "section": "How to use",
    "text": "How to use\nusage: uh [-h] [--img_dir IMG_DIR] [--dataset DATASET] [--spectra_type SPECTRA_TYPE] [--analytes ANALYTES] [--n_samples N_SAMPLES] [--batch_size BATCH_SIZE]\n          src dir_out\n\nConvert spectra to wavelet images.\n\npositional arguments:\n  src                          Source file\n  dir_out                      Output root directory\n\noptions:\n  -h, --help                   show this help message and exit\n  --img_dir IMG_DIR            Image directory (default: img)\n  --dataset DATASET            Dataset to use (default: ossl)\n  --spectra_type SPECTRA_TYPE  Spectra type to use (default: mir)\n  --analytes ANALYTES          Analytes to use (default: k.ext_usda.a725_cmolc.kg)\n  --n_samples N_SAMPLES        Number of samples to use\n  --batch_size BATCH_SIZE      Batch size to use (default: 10)",
    "crumbs": [
      "Uhina"
    ]
  },
  {
    "objectID": "augment.html",
    "href": "augment.html",
    "title": "Data augmentation",
    "section": "",
    "text": "source\n\nQuantize\n\n Quantize (n_valid:int, **kwargs)\n\nQuantize B&W image.\n\n\n\n\nType\nDetails\n\n\n\n\nn_valid\nint\nValidation set size\n\n\n\n\n\nExported source\n@delegates()\nclass Quantize(RandTransform):\n    \"Quantize B&W image.\"\n    split_idx = None\n    def __init__(self, \n        n_valid: int, # Validation set size\n        **kwargs\n    ):\n        store_attr()\n        super().__init__(**kwargs)\n        self.valid_percentiles = [self.get_random_percentiles() for i in range(n_valid)]\n        self.valid_idx = 0\n\n    def before_call(self, \n        b, \n        split_idx:int # Index of the train/valid dataset (0: train, 1: valid)\n    ):\n        self.idx = split_idx\n        \n    def get_random_percentiles(self):\n        start = np.random.uniform(1, 50)\n        end = np.random.uniform(90.1, 99.5)\n        steps = np.random.randint(5, 100)\n        return torch.linspace(start=start, end=end, steps=steps)\n\n    def get_percentiles(self):\n        if self.idx == 1:\n            percentiles = self.valid_percentiles[self.valid_idx%self.n_valid]\n            self.valid_idx += 1\n            return percentiles\n        else:\n            return self.get_random_percentiles()\n    \n    def encodes(self, x:Image.Image):\n        im_tensor = image2tensor(x)[0, :, :]\n        percentiles = self.get_percentiles()\n        levels = torch.quantile(im_tensor.float(), percentiles / 100)\n        im_quant = torch.bucketize(im_tensor.float(), levels)\n        \n        cmap = plt.get_cmap('Spectral_r')\n        im_color = tensor(cmap(im_quant.float() / im_quant.max())[:,:,:3])\n        im_color = im_color.permute(2, 0, 1)\n        return to_image(im_color)\n\n\n\nim_path = '../_data/all-grey-255.png'\nim = PILImage.create(im_path)\n\nfig = plt.figure(figsize=(12, 7))\ngs = fig.add_gridspec(5, 3, hspace=0.01, wspace=0.05)\naxs = gs.subplots()\n\nfor ax in axs.flatten():\n    quantized_im = Quantize(n_valid=1)(im)\n    ax.imshow(quantized_im)\n    ax.axis('off')\n\nfig.suptitle('Multiple quantized versions of the same image', fontsize=12, y=0.91)\nplt.show()",
    "crumbs": [
      "Data augmentation"
    ]
  },
  {
    "objectID": "loading.html",
    "href": "loading.html",
    "title": "Loading",
    "section": "",
    "text": "source",
    "crumbs": [
      "Loading"
    ]
  },
  {
    "objectID": "loading.html#ossl-loader",
    "href": "loading.html#ossl-loader",
    "title": "Loading",
    "section": "OSSL loader",
    "text": "OSSL loader\nDescribe OSSL …\n\nsource\n\nOSSLLoader\n\n OSSLLoader (src:pathlib.Path=Path('/home/runner/.lssm/data/ossl/ossl_all_\n             L0_v1.2.csv.gz'), spectra_type:str='visnir', cfgs:dict=None)\n\nLoad OSSL data and filter it by spectra type and analytes of interest.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nsrc\nPath\n/home/runner/.lssm/data/ossl/ossl_all_L0_v1.2.csv.gz\nData source file name\n\n\nspectra_type\nstr\nvisnir\nSpectra type\n\n\ncfgs\ndict\nNone\nSpectra type configuration\n\n\n\n\n\nExported source\nclass OSSLLoader(DataLoader):\n    \"Load OSSL data and filter it by spectra type and analytes of interest.\"\n    DTYPE_DICT = {\n        'id.layer_local_c': 'object',\n        'id.location_olc_txt': 'object',\n        'id.dataset.site_ascii_txt': 'object',\n        'id.scan_local_c': 'object',\n        'layer.texture_usda_txt': 'object',\n        'pedon.taxa_usda_txt': 'object',\n        'horizon.designation_usda_txt': 'object',\n        'location.country_iso.3166_txt': 'object',\n        'surveyor.address_utf8_txt': 'object',\n        'efferv_usda.a479_class': 'object',\n        'scan.mir.date.begin_iso.8601_yyyy.mm.dd': 'object',\n        'scan.mir.date.end_iso.8601_yyyy.mm.dd': 'object',\n        'scan.mir.model.name_utf8_txt': 'object',\n        'scan.mir.model.code_any_txt': 'object',\n        'scan.mir.method.optics_any_txt': 'object',\n        'scan.mir.method.preparation_any_txt': 'object',\n        'scan.mir.license.title_ascii_txt': 'object',\n        'scan.mir.license.address_idn_url': 'object',\n        'scan.mir.doi_idf_url': 'object',\n        'scan.mir.contact.name_utf8_txt': 'object',\n        'scan.mir.contact.email_ietf_txt': 'object',\n        'scan.visnir.date.begin_iso.8601_yyyy.mm.dd': 'object',\n        'scan.visnir.date.end_iso.8601_yyyy.mm.dd': 'object',\n        'scan.visnir.model.name_utf8_txt': 'object',\n        'scan.visnir.model.code_any_txt': 'object',\n        'scan.visnir.method.optics_any_txt': 'object',\n        'scan.visnir.method.preparation_any_txt': 'object',\n        'scan.visnir.license.title_ascii_txt': 'object',\n        'scan.visnir.license.address_idn_url': 'object',\n        'scan.visnir.doi_idf_url': 'object',\n        'scan.visnir.contact.name_utf8_txt': 'object',\n        'scan.visnir.contact.email_ietf_txt': 'object'\n    }\n    def __init__(self, \n                 src: Path = Path.home() / '.lssm/data/ossl/ossl_all_L0_v1.2.csv.gz', # Data source file name\n                 spectra_type: str='visnir', # Spectra type\n                 cfgs: dict=None): # Spectra type configuration\n        self.src = src\n        self.spectra_type = spectra_type\n        self.df = None\n        self.ds_name_encoder = LabelEncoder()\n        self.cfgs = cfgs or {\n            'visnir': {'ref_col': 'scan_visnir.1500_ref', 'range': [400, 2500]},\n            'mir': {'ref_col': 'scan_mir.1500_abs', 'range': [650, 4000]}\n        }\n\n    def _get_spectra(self, \n                    spectra_type: str # Spectra type\n                    ):\n        cols_ref = [name for name in self.df.columns if f'scan_{spectra_type}.' in name]\n        X = self.df[cols_ref].values\n        X_names = self._get_wavelengths(spectra_type)\n        lower_limit, upper_limit = self.cfgs[spectra_type]['range']\n        idxs = np.where((X_names &gt;= lower_limit) & (X_names &lt;= upper_limit))[0]\n        return X[:, idxs], X_names[idxs]\n\n    def _encode_dataset_names(self):\n        return self.ds_name_encoder.fit_transform(self.df['dataset.code_ascii_txt'])\n\n    def _get_wavelengths(self, \n                            spectra_type: str # Spectra type\n                            ):\n        pattern = r\"scan_{}\\.(\\d+)_\".format(spectra_type)\n        return np.array([int(re.search(pattern, name).group(1)) for name in self.df.columns\n                            if re.search(pattern, name)])\n        \n    def load_data(self, \n                  analytes: str|list, # Analyte(s) of interest\n                  ) -&gt; tuple: # Return a tuple of the form (X, y, X_names, smp_idx, ds_name, ds_label)\n        \"Load OSSL data and filter it by spectra type and analytes of interest.\"\n        print(f'Loading data from {self.src} ...')\n        self.df = pd.read_csv(self.src, dtype=self.DTYPE_DICT,\n                              compression='infer', low_memory=True)\n\n        analytes = [analytes] if isinstance(analytes, str) else analytes\n        y_names = np.array(analytes)\n        subset = analytes + [self.cfgs[self.spectra_type]['ref_col']]\n        self.df = self.df.dropna(subset=subset, how='any')\n\n        X, X_names = self._get_spectra(self.spectra_type)\n        y = self.df[analytes].values\n        smp_indices = self.df['id.layer_uuid_txt'].values\n        ds_name = self._encode_dataset_names()\n        \n        return SpectralData(\n            X=X,\n            X_names=X_names,\n            y=y,\n            y_names=y_names,\n            sample_indices=smp_indices,\n            dataset_names=ds_name,\n            dataset_labels=self.ds_name_encoder.classes_\n        )\n\n        # return X, y, X_names, smp_idx, ds_name, self.ds_name_encoder.classes_, np.array(analytes)\n\n\nUsage example:\n\nsrc = Path.home() / '.lssm/data/ossl/ossl_all_L0_v1.2.csv.gz'\nloader = OSSLLoader(src=src, spectra_type='mir')\n\nanalytes = 'k.ext_usda.a725_cmolc.kg'\ndata = loader.load_data(analytes)\n\nprint(f'X shape: {data.X.shape}')\nprint(f'y shape: {data.y.shape}')\nprint(f'wavenumbers: {data.X_names}')\nprint(f'Analytes: {data.y_names}')\nprint(f'smp_idx: {data.sample_indices}')\nprint(f'ds_name: {data.dataset_names}')\nprint(f'ds_label: {data.dataset_labels}')\n\nLoading data from /Users/franckalbinet/.lssm/data/ossl/ossl_all_L0_v1.2.csv.gz ...\nX shape: (57674, 1676)\ny shape: (57674, 1)\nwavenumbers: [ 650  652  654 ... 3996 3998 4000]\nAnalytes: ['k.ext_usda.a725_cmolc.kg']\nsmp_idx: ['3998362dd2659e2252cd7f38b43c9b1f' '2bab4dbbac073b8648475ad50d40eb95'\n '29213d2193232be8867d85dec463ec00' ... 'b790da349d49885c5727a2b5fd67b13d'\n 'a057a7ead9eebce24d4039de7fd5e01b' '80bf4a0dc30f60552a38193d5c09b9cd']\nds_name: [0 0 0 ... 3 3 3]\nds_label: ['GARRETT.SSL' 'ICRAF.ISRIC' 'KSSL.SSL' 'LUCAS.WOODWELL.SSL']",
    "crumbs": [
      "Loading"
    ]
  },
  {
    "objectID": "loading.html#fukushima-jumpei-data",
    "href": "loading.html#fukushima-jumpei-data",
    "title": "Loading",
    "section": "Fukushima (Jumpei) data",
    "text": "Fukushima (Jumpei) data\nDescribe Jumpei’s data\n\nsource\n\nFukushimaJumpeiLoader\n\n FukushimaJumpeiLoader (src:pathlib.Path|str)\n\nLoad Fukushima (Jumpei) data.\n\n\n\n\nType\nDetails\n\n\n\n\nsrc\npathlib.Path | str\nSource directory\n\n\n\n\n\nExported source\nclass FukushimaJumpeiLoader(DataLoader):\n    \"Load Fukushima (Jumpei) data.\"\n    fname = 'Fukushimaall_Average.csv'\n    analytes = ['soil_total_Cs134',\n                'soil_total_Cs137',\n                'soil_ex_Cs137',\n                'exCs137_totalCs137',\n                'soil_water_soluble_K2O',\n                'soil_ex_K2O',\n                'TF_plant_totalCs137',\n                'TF_plant_exCs137',\n                'soil_pH',\n                'soil_C',\n                'soil_N',\n                'soil_CN_ratio',\n                'soil_CEC',\n                'soil_MgO',\n                'soil_CaO',\n                'soil_P_absorption_coefficient',\n                'avaiable_Pi',\n                'course_sand',\n                'fine_sand',\n                'silt',\n                'clay']\n    \n    def __init__(self, \n                 src: Path|str, # Source directory\n                 ): \n        self.src = src if isinstance(src, Path) else Path(src)\n        self.ds_name_encoder = LabelEncoder()\n        \n    def load_mir(self, df):\n        wn_cols = [col for col in df.columns if col.isdigit()]\n        return df[wn_cols].values, np.array([int(col) for col in wn_cols])\n    \n    def load_wetchem(self):\n        fname = self.src / self.fname_wetchem\n        return pd.read_csv(fname)\n    \n    def separate_spectra_and_others(self, df_merged: pd.DataFrame) -&gt; tuple:\n        \"Separate the merged dataframe into spectral data and metadata.\"\n        spectral_cols = [col for col in df_merged.columns if col.isdigit()]\n        metadata_cols = [col for col in df_merged.columns if not col.isdigit()]\n        df_spectra = df_merged[spectral_cols]\n        df_others = df_merged[metadata_cols]\n        return df_spectra, df_others\n        \n    def make_idx(self, df: pd.DataFrame) -&gt; pd.DataFrame:\n        \"Make a unique index for the samples.\"\n        return (df.iloc[:, :3].astype(str).apply('-'.join, axis=1))\n    \n    def _encode_dataset_names(self, df: pd.DataFrame):\n        return self.ds_name_encoder.fit_transform(df)\n\n    def load_data(self,\n                  analytes: str|list=None, # Analytes of interest\n                  ) -&gt; tuple:\n        \"Load Ringtrial data and return SpectralData.\"\n        df = pd.read_csv(self.src / self.fname, low_memory=False)\n        X, X_names = self.load_mir(df)\n    \n        if analytes is None: analytes = self.analytes\n    \n        # y = df[analytes].values\n        y = df[analytes].apply(pd.to_numeric, errors='coerce').values\n        y_names = np.array(analytes)\n        smp_indices = self.make_idx(df).values\n        ds_name = self._encode_dataset_names(pd.Series(['fukushima-jumpei'] * len(df), index=df.index))\n        \n        return SpectralData(\n            X=X,\n            X_names=X_names,\n            y=y,\n            y_names=y_names,\n            sample_indices=smp_indices,\n            dataset_names=ds_name,\n            dataset_labels=self.ds_name_encoder.classes_\n        )\n\n\n\nsrc = Path.home() / 'pro/data/fk-jumpei'\nloader = FukushimaJumpeiLoader(src)\ndata = loader.load_data()\n\nprint(f'X shape: {data.X.shape}')\nprint(f'y shape: {data.y.shape}')\nprint(f'wavenumbers: {data.X_names}')\nprint(f'Analytes: {data.y_names}')\nprint(f'smp_idx: {data.sample_indices}')\nprint(f'ds_name: {data.dataset_names}')\nprint(f'ds_label: {data.dataset_labels}')\n\nplot_spectra(data, n_spectra=100, snv=True, alpha=0.2, figsize=(12, 3));\n\nX shape: (635, 1675)\ny shape: (635, 21)\nwavenumbers: [ 650  652  654 ... 3996 3998 4000]\nAnalytes: ['soil_total_Cs134' 'soil_total_Cs137' 'soil_ex_Cs137'\n 'exCs137_totalCs137' 'soil_water_soluble_K2O' 'soil_ex_K2O'\n 'TF_plant_totalCs137' 'TF_plant_exCs137' 'soil_pH' 'soil_C' 'soil_N'\n 'soil_CN_ratio' 'soil_CEC' 'soil_MgO' 'soil_CaO'\n 'soil_P_absorption_coefficient' 'avaiable_Pi' 'course_sand' 'fine_sand'\n 'silt' 'clay']\nsmp_idx: ['20-2013-paddy_rice' '28-2014-paddy_rice' '33-2014-paddy_rice'\n '35-2014-paddy_rice' '36-2014-paddy_rice' '38-2014-paddy_rice'\n '40-2014-paddy_rice' '41-2014-paddy_rice' '44-2014-paddy_rice'\n '49-2014-paddy_rice' '51-2015-paddy_rice' '53-2015-paddy_rice'\n '58-2015-paddy_rice' '64-2015-paddy_rice' '66-2015-paddy_rice'\n '68-2015-paddy_rice' '69-2015-paddy_rice' '72-2015-paddy_rice'\n '73-2015-paddy_rice' '74-2015-paddy_rice' '75-2015-paddy_rice'\n '78-2015-paddy_rice' '80-2016-paddy_rice' '81-2016-paddy_rice'\n '85-2016-paddy_rice' '93-2016-paddy_rice' '94-2016-paddy_rice'\n '95-2016-paddy_rice' '98-2016-paddy_rice' '100-2017-paddy_rice'\n '101-2017-paddy_rice' '102-2017-paddy_rice' '103-2017-paddy_rice'\n '104-2017-paddy_rice' '105-2013-paddy_rice' '106-2013-paddy_rice'\n '108-2013-paddy_rice' '109-2013-paddy_rice' '110-2013-paddy_rice'\n '111-2013-paddy_rice' '112-2013-paddy_rice' '113-2013-paddy_rice'\n '114-2013-paddy_rice' '115-2013-paddy_rice' '116-2013-paddy_rice'\n '117-2013-paddy_rice' '118-2013-paddy_rice' '119-2013-paddy_rice'\n '120-2014-paddy_rice' '121-2014-paddy_rice' '122-2014-paddy_rice'\n '125-2014-paddy_rice' '128-2014-paddy_rice' '129-2014-paddy_rice'\n '130-2014-paddy_rice' '131-2014-paddy_rice' '133-2015-paddy_rice'\n '135-2015-paddy_rice' '137-2015-paddy_rice' '140-2015-paddy_rice'\n '142-2015-paddy_rice' '144-2015-paddy_rice' '145-2015-paddy_rice'\n '146-2015-paddy_rice' '147-2015-paddy_rice' '148-2015-paddy_rice'\n '149-2015-paddy_rice' '150-2015-paddy_rice' '152-2015-paddy_rice'\n '154-2015-paddy_rice' '157-2016-paddy_rice' '158-2016-paddy_rice'\n '159-2016-paddy_rice' '160-2016-paddy_rice' '161-2016-paddy_rice'\n '163-2016-paddy_rice' '164-2016-paddy_rice' '166-2016-paddy_rice'\n '167-2016-paddy_rice' '168-2016-paddy_rice' '169-2016-paddy_rice'\n '170-2016-paddy_rice' '175-2017-paddy_rice' '176-2017-paddy_rice'\n '177-2017-paddy_rice' '178-2017-paddy_rice' '181-2017-paddy_rice'\n '182-2017-paddy_rice' '190-2017-paddy_rice' '193-2017-paddy_rice'\n '195-2017-paddy_rice' '196-2017-paddy_rice' '197-2017-paddy_rice'\n '198-2017-paddy_rice' '199-2017-paddy_rice' '200-2017-paddy_rice'\n '201-2017-paddy_rice' '203-2017-paddy_rice' '204-2017-paddy_rice'\n '205-2017-paddy_rice' '206-2017-paddy_rice' '207-2017-paddy_rice'\n '208-2017-paddy_rice' '212-2017-paddy_rice' '213-2017-paddy_rice'\n '214-2017-paddy_rice' '215-2017-paddy_rice' '216-2017-paddy_rice'\n '217-2017-paddy_rice' '218-2017-paddy_rice' '219-2017-paddy_rice'\n '220-2017-paddy_rice' '221-2017-paddy_rice' '222-2017-paddy_rice'\n '223-2017-paddy_rice' '224-2017-paddy_rice' '225-2017-paddy_rice'\n '226-2017-paddy_rice' '227-2017-paddy_rice' '228-2017-paddy_rice'\n '229-2017-paddy_rice' '230-2017-paddy_rice' '231-2017-paddy_rice'\n '232-2017-paddy_rice' '233-2017-paddy_rice' '235-2017-paddy_rice'\n '236-2017-paddy_rice' '237-2017-paddy_rice' '238-2017-paddy_rice'\n '239-2017-paddy_rice' '241-2017-paddy_rice' '242-2017-paddy_rice'\n '244-2017-paddy_rice' '245-2017-paddy_rice' '246-2017-paddy_rice'\n '247-2017-paddy_rice' '248-2017-paddy_rice' '250-2017-paddy_rice'\n '251-2017-paddy_rice' '252-2017-paddy_rice' '253-2017-paddy_rice'\n '254-2017-paddy_rice' '255-2017-paddy_rice' '256-2017-paddy_rice'\n '258-2017-paddy_rice' '259-2017-paddy_rice' '260-2017-paddy_rice'\n '261-2017-paddy_rice' '262-2018-paddy_rice' '263-2018-paddy_rice'\n '264-2018-paddy_rice' '265-2018-paddy_rice' '266-2018-paddy_rice'\n '267-2018-paddy_rice' '268-2018-paddy_rice' '269-2018-paddy_rice'\n '271-2018-paddy_rice' '272-2018-paddy_rice' '273-2018-paddy_rice'\n '274-2018-paddy_rice' '275-2018-paddy_rice' '276-2018-paddy_rice'\n '277-2018-paddy_rice' '278-2018-paddy_rice' '279-2018-paddy_rice'\n '289-2019-paddy_rice' '290-2019-paddy_rice' '291-2019-paddy_rice'\n '292-2019-paddy_rice' '293-2019-paddy_rice' '294-2019-paddy_rice'\n '295-2019-paddy_rice' '296-2019-paddy_rice' '297-2019-paddy_rice'\n '298-2019-paddy_rice' '299-2019-paddy_rice' '691-2014-paddy_rice'\n '694-2014-paddy_rice' '699-2014-paddy_rice' '703-2014-paddy_rice'\n '707-2014-paddy_rice' '722-2014-soybean' '726-2014-paddy_rice'\n '729-2014-paddy_rice' '732-2014-paddy_rice' '735-2014-paddy_rice'\n '738-2014-paddy_rice' '741-2014-paddy_rice' '743-2014-paddy_rice'\n '744-2014-paddy_rice' '745-2014-paddy_rice' '747-2014-soybean'\n '749-2014-soybean' '752-2014-soybean' '755-2014-soybean'\n '758-2014-soybean' '764-2014-soybean' '769-2014-paddy_rice'\n '771-2014-soybean' '774-2014-soybean' '775-2014-buckwheat'\n '798-2014-paddy_rice' '802-2014-soybean' '805-2014-soybean'\n '808-2014-soybean' '811-2014-soybean' '813-2014-soybean'\n '816-2014-soybean' '819-2014-soybean' '822-2014-soybean'\n '825-2014-buckwheat' '827-2014-soybean' '829-2014-soybean'\n '831-2014-soybean' '836-2014-paddy_rice' '840-2014-paddy_rice'\n '844-2014-paddy_rice' '859-2014-paddy_rice' '861-2014-soybean'\n '867-2014-soybean' '869-2014-soybean' '872-2014-soybean'\n '874-2014-soybean' '884-2014-paddy_rice' '888-2014-paddy_rice'\n '905-2014-paddy_rice' '908-2014-paddy_rice' '912-2014-paddy_rice'\n '915-2014-soybean' '919-2014-soybean' '921-2014-paddy_rice'\n '923-2014-paddy_rice' '925-2014-soybean' '927-2014-soybean'\n '928-2014-soybean' '930-2014-buckwheat' '934-2014-paddy_rice'\n '946-2014-paddy_rice' '951-2014-paddy_rice' '959-2014-paddy_rice'\n '961-2014-paddy_rice' '964-2014-paddy_rice' '966-2014-paddy_rice'\n '968-2014-paddy_rice' '970-2014-paddy_rice' '972-2014-paddy_rice'\n '973-2014-soybean' '974-2014-paddy_rice' '976-2014-paddy_rice'\n '983-2014-paddy_rice' '989-2014-paddy_rice' '1019-2014-paddy_rice'\n '1022-2014-paddy_rice' '1024-2014-paddy_rice' '1026-2014-paddy_rice'\n '1031-2014-soybean' '1034-2014-paddy_rice' '1037-2014-paddy_rice'\n '1041-2014-soybean' '1044-2014-buckwheat' '1046-2014-buckwheat'\n '1048-2014-paddy_rice' '1050-2014-buckwheat' '1052-2014-buckwheat'\n '1055-2014-paddy_rice' '1059-2014-buckwheat' '1062-2014-paddy_rice'\n '1070-2014-paddy_rice' '1088-2014-paddy_rice' '1093-2014-soybean'\n '1099-2014-buckwheat' '1104-2014-paddy_rice' '1106-2014-paddy_rice'\n '1108-2014-buckwheat' '1111-2014-soybean' '1114-2014-paddy_rice'\n '1115-2014-buckwheat' '1117-2014-buckwheat' '1123-2014-paddy_rice'\n '1134-2014-buckwheat' '1139-2014-paddy_rice' '1143-2014-buckwheat'\n '1147-2014-paddy_rice' '1152-2014-buckwheat' '1156-2014-buckwheat'\n '1164-2014-soybean' '1165-2014-soybean' '1167-2014-soybean'\n '1169-2014-buckwheat' '1182-2014-paddy_rice' '1188-2014-paddy_rice'\n '1195-2014-paddy_rice' '1198-2014-buckwheat' '1201-2014-buckwheat'\n '1204-2014-soybean' '1213-2014-buckwheat' '1217-2014-paddy_rice'\n '1220-2014-buckwheat' '1224-2014-paddy_rice' '1230-2014-buckwheat'\n '1234-2014-buckwheat' '1241-2014-paddy_rice' '1244-2014-buckwheat'\n '1247-2014-buckwheat' '1249-2014-soybean' '1254-2014-paddy_rice'\n '1260-2014-buckwheat' '1268-2014-paddy_rice' '1273-2014-buckwheat'\n '1275-2014-paddy_rice' '1296-2014-paddy_rice' '1300-2014-paddy_rice'\n '1305-2014-soybean' '1307-2014-paddy_rice' '1310-2014-soybean'\n '1339-2014-paddy_rice' '1341-2014-paddy_rice' '1343-2014-paddy_rice'\n '1347-2014-paddy_rice' '1350-2014-paddy_rice' '1351-2014-paddy_rice'\n '1352-2014-paddy_rice' '1354-2014-paddy_rice' '1356-2014-paddy_rice'\n '1357-2014-paddy_rice' '1361-2014-paddy_rice' '1362-2014-paddy_rice'\n '1364-2014-paddy_rice' '1365-2014-paddy_rice' '1367-2014-paddy_rice'\n '1368-2014-paddy_rice' '1369-2014-paddy_rice' '1370-2014-paddy_rice'\n '1371-2014-paddy_rice' '1372-2014-paddy_rice' '1374-2014-paddy_rice'\n '1375-2014-paddy_rice' '1376-2014-paddy_rice' '1416-2014-paddy_rice'\n '1428-2014-paddy_rice' '1431-2014-paddy_rice' '1433-2014-buckwheat'\n '1435-2014-buckwheat' '1440-2014-paddy_rice' '1445-2014-paddy_rice'\n '1448-2014-paddy_rice' '1454-2014-buckwheat' '1457-2014-paddy_rice'\n '1460-2014-buckwheat' '1465-2014-paddy_rice' '1468-2014-buckwheat'\n '1471-2014-paddy_rice' '1473-2014-paddy_rice' '1474-2014-paddy_rice'\n '1475-2014-paddy_rice' '1477-2014-paddy_rice' '1479-2014-paddy_rice'\n '1481-2014-paddy_rice' '1484-2014-soybean' '1485-2014-soybean'\n '1486-2014-buckwheat' '1488-2014-buckwheat' '1490-2014-paddy_rice'\n '1492-2014-paddy_rice' '1494-2014-paddy_rice' '1496-2014-paddy_rice'\n '1498-2014-paddy_rice' '1500-2014-paddy_rice' '1503-2014-soybean'\n '1505-2014-soybean' '1507-2014-buckwheat' '1508-2014-buckwheat'\n '1510-2014-paddy_rice' '1511-2014-paddy_rice' '1512-2014-paddy_rice'\n '1984-2018-paddy_rice' '1985-2018-paddy_rice' '1986-2018-paddy_rice'\n '1987-2018-soil' '1988-2018-paddy_rice' '1989-2018-soil'\n '1990-2018-paddy_rice' '1991-2018-paddy_rice' '1992-2018-soybean'\n '1993-2018-paddy_rice' '1994-2018-soil' '1995-2018-paddy_rice'\n '1996-2018-buckwheat' '1997-2018-paddy_rice' '1998-2018-paddy_rice'\n '1999-2018-paddy_rice' '2000-2018-paddy_rice' '2001-2018-soybean'\n '2002-2018-soybean' '2003-2018-soil' '2004-2018-soil' '2005-2018-soybean'\n '2006-2018-paddy_rice' '2007-2018-soybean' '2008-2018-soybean'\n '2009-2018-soybean' '2010-2018-soil' '2011-2018-soil' '2012-2018-soybean'\n '2013-2018-soybean' '2014-2018-soybean' '2015-2018-soil'\n '2016-2018-soybean' '2017-2018-soil' '2018-2018-paddy_rice'\n '2019-2018-paddy_rice' '2020-2018-soybean' '2021-2018-paddy_rice'\n '2022-2018-soybean' '2023-2018-buckwheat' '2024-2018-paddy_rice'\n '2025-2018-buckwheat' '2026-2018-paddy_rice' '2027-2018-soil'\n '2028-2018-paddy_rice' '2029-2018-paddy_rice' '2030-2018-buckwheat'\n '2031-2018-soybean' '2032-2018-paddy_rice' '2033-2018-buckwheat'\n '2034-2018-paddy_rice' '2035-2018-buckwheat' '2036-2018-buckwheat'\n '2037-2018-paddy_rice' '2038-2018-buckwheat' '2039-2018-buckwheat'\n '2040-2018-buckwheat' '2041-2018-paddy_rice' '2042-2018-buckwheat'\n '2043-2018-soil' '2044-2018-paddy_rice' '2045-2018-buckwheat'\n '2046-2018-soybean' '2047-2018-soil' '2048-2018-paddy_rice'\n '2049-2018-buckwheat' '2050-2018-paddy_rice' '2051-2018-paddy_rice'\n '2052-2018-soybean' '2053-2018-soil' '2054-2018-buckwheat'\n '2055-2018-buckwheat' '2056-2018-paddy_rice' '2057-2018-buckwheat'\n '2058-2018-soil' '2059-2018-paddy_rice' '2060-2018-soil'\n '2061-2018-buckwheat' '2062-2018-paddy_rice' '2063-2018-soil'\n '2064-2018-soil' '2065-2018-paddy_rice' '2066-2018-paddy_rice'\n '2067-2018-buckwheat' '2068-2018-soil' '2069-2018-paddy_rice'\n '2070-2018-buckwheat' '2071-2018-paddy_rice' '2072-2018-paddy_rice'\n '2073-2018-paddy_rice' '2074-2018-paddy_rice' '2075-2018-paddy_rice'\n '2076-2018-paddy_rice' '2077-2018-paddy_rice' '2078-2018-paddy_rice'\n '2079-2018-soil' '2080-2018-soil' '2081-2018-soil' '2082-2018-paddy_rice'\n '2083-2018-paddy_rice' '2084-2018-paddy_rice' '2085-2018-soil'\n '2086-2018-paddy_rice' '2087-2018-soil' '2088-2018-soil' '2089-2018-soil'\n '2090-2018-paddy_rice' '2091-2018-paddy_rice' '2092-2018-soil'\n '2093-2018-soil' '2094-2018-soil' '2095-2018-soil' '2096-2018-soil'\n '2097-2018-soil' '2099-2018-paddy_rice' '2100-2018-paddy_rice'\n '2101-2018-soybean' '2102-2018-soybean' '2103-2018-paddy_rice'\n '2104-2018-paddy_rice' '2105-2018-paddy_rice' '2106-2018-paddy_rice'\n '2107-2018-paddy_rice' '2108-2018-paddy_rice' '2109-2018-paddy_rice'\n '2110-2018-paddy_rice' '2111-2018-paddy_rice' '2112-2018-paddy_rice'\n '2113-2018-paddy_rice' '2114-2018-paddy_rice' '2115-2018-paddy_rice'\n '2116-2018-paddy_rice' '2117-2018-soil' '2118-2018-paddy_rice'\n '2119-2018-paddy_rice' '2120-2018-paddy_rice' '2121-2018-soil'\n '2122-2018-paddy_rice' '2123-2018-paddy_rice' '2124-2018-soybean'\n '2125-2018-paddy_rice' '2126-2018-soil' '2127-2018-paddy_rice'\n '2128-2018-paddy_rice' '2129-2018-paddy_rice' '2130-2018-paddy_rice'\n '2131-2018-paddy_rice' '2132-2018-paddy_rice' '2133-2018-soil'\n '2134-2018-soil' '2135-2018-soil' '2136-2018-paddy_rice'\n '2137-2018-paddy_rice' '2138-2018-paddy_rice' '2139-2018-paddy_rice'\n '2140-2018-paddy_rice' '2141-2018-paddy_rice' '2142-2018-paddy_rice'\n '2143-2018-paddy_rice' '2144-2018-paddy_rice' '2145-2018-paddy_rice'\n '2146-2018-paddy_rice' '2147-2018-paddy_rice' '2148-2018-paddy_rice'\n '2149-2018-paddy_rice' '2150-2018-paddy_rice' '2151-2018-paddy_rice'\n '2152-2018-soil' '2153-2018-paddy_rice' '2154-2018-paddy_rice'\n '2155-2018-paddy_rice' '2156-2018-paddy_rice' '2157-2018-soil'\n '2158-2018-soybean' '2159-2018-paddy_rice' '2160-2018-paddy_rice'\n '2161-2018-buckwheat' '2162-2018-paddy_rice' '2163-2018-paddy_rice'\n '2164-2018-soybean' '2165-2018-paddy_rice' '2166-2018-paddy_rice'\n '2167-2018-paddy_rice' '2168-2018-buckwheat' '2169-2018-soybean'\n '2170-2018-soybean' '2171-2018-soybean' '2172-2018-soybean'\n '2173-2018-maize' '2174-2018-paddy_rice' '2175-2018-buckwheat'\n '2176-2018-paddy_rice' '2177-2018-soil' '2178-2018-paddy_rice'\n '2179-2018-paddy_rice' '2180-2018-soybean' '2181-2018-paddy_rice'\n '2182-2018-paddy_rice' '2183-2018-paddy_rice' '2184-2018-soil'\n '2368-2020-paddy_rice' '2369-2020-paddy_rice' '2374-2020-soil_only'\n '2376-2020-soybean' '2389-2020-paddy_rice' '2390-2020-soil_only'\n '2391-2020-paddy_rice' '2392-2020-soybean' '2394-2020-soil_only'\n '2395-2020-paddy_rice' '2396-2020-soil_only' '2397-2020-soil_only'\n '2398-2020-soybean' '2399-2020-soybean' '2400-2020-soil_only'\n '2401-2020-soil_only' '2402-2020-paddy_rice' '2403-2020-soybean'\n '2404-2020-soybean' '2405-2020-soybean' '2406-2020-soil_only'\n '2407-2020-soil_only' '2408-2020-soil_only' '2409-2020-paddy_rice'\n '2410-2020-paddy_rice' '2413-2020-buckwheat' '2414-2020-paddy_rice'\n '2415-2020-buckwheat' '2416-2020-paddy_rice' '2417-2020-soybean'\n '2419-2020-paddy_rice' '2421-2020-soil_only' '2422-2020-paddy_rice'\n '2423-2020-buckwheat' '2424-2020-buckwheat' '2425-2020-soil_only'\n '2426-2020-paddy_rice' '2427-2020-buckwheat' '2428-2020-soil_only'\n '2429-2020-paddy_rice' '2430-2020-buckwheat' '2431-2020-paddy_rice'\n '2432-2020-paddy_rice' '2433-2020-buckwheat' '2434-2020-paddy_rice'\n '2435-2020-paddy_rice' '2436-2020-soybean' '2437-2020-soil_only'\n '2438-2020-buckwheat' '2439-2020-paddy_rice' '2440-2020-buckwheat'\n '2442-2020-soil_only' '2443-2020-soil_only' '2444-2020-paddy_rice'\n '2445-2020-buckwheat' '2446-2020-paddy_rice' '2447-2020-soil_only'\n '2448-2020-paddy_rice' '2517-2020-paddy_rice' '2532-2020-buckwheat']\nds_name: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0]\nds_label: ['fukushima-jumpei']",
    "crumbs": [
      "Loading"
    ]
  },
  {
    "objectID": "loading.html#ringtrial-data",
    "href": "loading.html#ringtrial-data",
    "title": "Loading",
    "section": "Ringtrial data",
    "text": "Ringtrial data\nDescribe Ringtrial …\n\nsource\n\nRingtrialLoader\n\n RingtrialLoader\n                  (src:pathlib.Path|str=Path('/home/runner/pro/data/woodwe\n                  ll-ringtrial/drive-download-20231013T123706Z-001'))\n\nLoad Ringtrial data.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nsrc\npathlib.Path | str\n/home/runner/pro/data/woodwell-ringtrial/drive-download-20231013T123706Z-001\nSource directory\n\n\n\n\n\nExported source\nsrc_dir_rt = Path.home() / 'pro/data/woodwell-ringtrial/drive-download-20231013T123706Z-001'\n\n\n\n\nExported source\nclass RingtrialLoader(DataLoader):\n    \"Load Ringtrial data.\"\n    fname_mir = 'RT_STD_allMIRspectra_raw.csv'\n    fname_wetchem = 'RT_wetchem_soildata.csv'\n    def __init__(self, \n                 src: Path|str = src_dir_rt, # Source directory\n                #  target: str = 'soil_ex_K2O', # Target analyte\n                 ): # Spectra type configuration\n        self.src = src if isinstance(src, Path) else Path(src)\n        self.ds_name_encoder = LabelEncoder()\n        \n    def load_mir(self):\n        fname = self.src / self.fname_mir\n        return pd.read_csv(fname)\n    \n    def load_wetchem(self):\n        fname = self.src / self.fname_wetchem\n        return pd.read_csv(fname)\n    \n    def separate_spectra_and_others(self, df_merged: pd.DataFrame) -&gt; tuple:\n        \"Separate the merged dataframe into spectral data and metadata.\"\n        spectral_cols = [col for col in df_merged.columns if col.isdigit()]\n        metadata_cols = [col for col in df_merged.columns if not col.isdigit()]\n        df_spectra = df_merged[spectral_cols]\n        df_others = df_merged[metadata_cols]\n        return df_spectra, df_others\n        \n    def make_idx(self, df: pd.DataFrame) -&gt; pd.DataFrame:\n        \"Make a unique index for the samples.\"\n        return (df['organization'] + '-' + df['sample_id']).str.lower().str.replace('_', '-')\n    \n    def _encode_dataset_names(self, df: pd.DataFrame):\n        return self.ds_name_encoder.fit_transform(df)\n\n    def load_data(self,\n                  analytes: str|list='potassium_cmolkg', # Analytes of interest\n                  ) -&gt; tuple:\n        \"Load Ringtrial data and return (X, y, X_names, smp_idx, ds_name, ds_label).\"\n        df_merged = pd.merge(self.load_mir(), \n                            self.load_wetchem().rename(columns={'\\tsample_id': 'sample_id'}),\n                            on='sample_id', how='inner')\n        \n        df_spectra, df_others = self.separate_spectra_and_others(df_merged)\n        \n        X = df_spectra.values\n        analytes = [analytes] if isinstance(analytes, str) else analytes\n        y = df_others[analytes].values\n        y_names = np.array(analytes)\n        X_names = df_spectra.columns.astype(int).values\n        smp_indices = self.make_idx(df_others).values\n        ds_name = self._encode_dataset_names(df_others['organization'])\n        \n        return SpectralData(\n            X=X,\n            X_names=X_names,\n            y=y,\n            y_names=y_names,\n            sample_indices=smp_indices,\n            dataset_names=ds_name,\n            dataset_labels=self.ds_name_encoder.classes_\n        )\n\n\n\nsrc = Path.home() / 'pro/data/woodwell-ringtrial/drive-download-20231013T123706Z-001'\n\nloader = RingtrialLoader(src)\ndata = RingtrialLoader().load_data()\n\nprint(f'X shape: {data.X.shape}')\nprint(f'y shape: {data.y.shape}')\nprint(f'wavenumbers: {data.X_names}')\nprint(f'Analytes: {data.y_names}')\nprint(f'smp_idx: {data.sample_indices}')\nprint(f'ds_name: {data.dataset_names}')\nprint(f'ds_label: {data.dataset_labels}')\n\nplot_spectra(data, n_spectra=100, snv=True, alpha=0.3, figsize=(12, 3));\n\nX shape: (1400, 1676)\ny shape: (1400, 1)\nwavenumbers: [ 650  652  654 ... 3996 3998 4000]\nAnalytes: ['potassium_cmolkg']\nsmp_idx: ['agrocares-rt-01' 'agrocares-rt-02' 'agrocares-rt-03' ...\n 'woodwell-vertex-rt-68' 'woodwell-vertex-rt-69' 'woodwell-vertex-rt-70']\nds_name: [ 0  0  0 ... 19 19 19]\nds_label: ['Agrocares' 'Argonne' 'CSU_IL' 'ETH_alpha_1' 'ETH_alpha_2' 'ETH_vertex'\n 'IAEA_aug2022' 'KSSL' 'LandCare' 'Lesotho' 'MSU' 'OSU' 'Rothamsted'\n 'Scion' 'UGhent' 'UIUC' 'USP' 'UWisc_fine' 'Woodwell_alpha'\n 'Woodwell_vertex']",
    "crumbs": [
      "Loading"
    ]
  },
  {
    "objectID": "loading.html#loader-factory",
    "href": "loading.html#loader-factory",
    "title": "Loading",
    "section": "Loader factory",
    "text": "Loader factory\nThis is a factory class to get the appropriate loader for a given dataset.\n\nsource\n\nLoaderFactory\n\n LoaderFactory ()\n\nInitialize self. See help(type(self)) for accurate signature.\n\n\nExported source\nclass LoaderFactory:\n    @staticmethod\n    def get_loader(src: Path, dataset: str, **kwargs) -&gt; DataLoader:\n        if dataset == 'ossl':\n            return OSSLLoader(src, **kwargs)\n        elif dataset == 'ringtrial':\n            return RingtrialLoader(src)\n        elif dataset == 'fk-jumpei':\n            return FukushimaJumpeiLoader(src)\n        else:\n            raise ValueError(f\"Dataset {dataset} not supported yet ...\")\n\n\n\nsrc = Path.home() / 'pro/data/woodwell-ringtrial/drive-download-20231013T123706Z-001'\nloader = LoaderFactory.get_loader(src, 'ringtrial')\ndata = loader.load_data(analytes='potassium_cmolkg')\nprint(f'X shape: {data.X.shape}')\n\nX shape: (1400, 1676)\n\n\n\nsrc = Path.home() / '.lssm/data/ossl/ossl_all_L0_v1.2.csv.gz'\nloader = LoaderFactory.get_loader(src, 'ossl', spectra_type='mir')\ndata = loader.load_data(analytes='k.ext_usda.a725_cmolc.kg')\nprint(f'X shape: {data.X.shape}')\n\nLoading data from /Users/franckalbinet/.lssm/data/ossl/ossl_all_L0_v1.2.csv.gz ...\nX shape: (57674, 1676)\n\n\n\nsrc = Path.home() / 'pro/data/fk-jumpei'\nloader = LoaderFactory.get_loader(src, 'fk-jumpei')\ndata = loader.load_data()\nprint(f'X shape: {data.X.shape}')\n\nX shape: (635, 1675)",
    "crumbs": [
      "Loading"
    ]
  },
  {
    "objectID": "preprocessing.html",
    "href": "preprocessing.html",
    "title": "Preprocessing",
    "section": "",
    "text": "from uhina.loading import OSSLLoader\nfrom sklearn.pipeline import Pipeline\nfrom matplotlib import pyplot as plt\nimport fastcore.all as fc\n\n\nsource\n\nSNV\n\n SNV ()\n\nCreates scikit-learn SNV custom transformer\n\nsource\n\n\nTakeDerivative\n\n TakeDerivative (window_length=11, polyorder=1, deriv=1)\n\n*Creates scikit-learn derivation custom transformer\nArgs: window_length: int, optional Specify savgol filter smoothing window length\npolyorder: int, optional\n    Specify order of the polynom used to interpolate derived signal\n\nderiv: int, optional\n    Specify derivation degree\nReturns: scikit-learn custom transformer*\nUsage example:\n\nX, y, wavenumbers, smp_idx, ds_name, ds_label = fc.load_pickle('./files/spectrum-and-all.pkl')\n\n#| eval: false\npipe = Pipeline([\n    ('SNV', SNV()),\n    ('Derivative', TakeDerivative())\n])\n\n# Preprocess spectra\nX_trans = pipe.fit_transform(X)\n\n# Plot first preprocessed spectrum\nfig, ax = plt.subplots(figsize=(12, 2))\nax.plot(wavenumbers, X_trans[0, :], lw=1)\nax.set_xlabel('Wavenumber ($cm^{-1}$)')\nax.set_ylabel('Absorbance')\nax.set_title('Preprocessed Soil MIR Spectrum: SNV and 1st Derivative')\nax.grid(True)\nax.invert_xaxis()",
    "crumbs": [
      "Preprocessing"
    ]
  },
  {
    "objectID": "wavelets.html",
    "href": "wavelets.html",
    "title": "Continuous Wavelet Transform",
    "section": "",
    "text": "TEST_DATASET = 'fk-jumpei'\n\nif TEST_DATASET == 'ringtrial':\n    src = Path.home() / 'pro/data/woodwell-ringtrial/drive-download-20231013T123706Z-001'\n    loader = LoaderFactory.get_loader(src, 'ringtrial')\n    data = loader.load_data(analytes='potassium_cmolkg')\n    \nelif TEST_DATASET == 'ossl':\n    src = Path.home() / '.lssm/data/ossl/ossl_all_L0_v1.2.csv.gz'\n    loader = LoaderFactory.get_loader(src, 'ossl', \n                                      spectra_type='mir', \n                                      cfgs={'mir': {'ref_col': 'scan_mir.1500_abs', 'range': [650, 4000]}})\n    data = loader.load_data(analytes='k.ext_usda.a725_cmolc.kg')\n\nelif TEST_DATASET == 'fk-jumpei':\n    src = Path.home() / 'pro/data/fk-jumpei'\n    loader = LoaderFactory.get_loader(src, 'fk-jumpei')\n    data = loader.load_data()\nelse: \n    raise ValueError(f\"Dataset {TEST_DATASET} not found.\")\n\nprint(f'X shape: {data.X.shape}')\nprint(f'y shape: {data.y.shape}')\nprint(f'smp_idx shape: {data.sample_indices.shape}')\nprint(f'y_names: {data.y_names}')\nprint(f'X_names: {data.X_names}')\n\nX shape: (635, 1675)\ny shape: (635, 21)\nsmp_idx shape: (635,)\ny_names: ['soil_total_Cs134' 'soil_total_Cs137' 'soil_ex_Cs137'\n 'exCs137_totalCs137' 'soil_water_soluble_K2O' 'soil_ex_K2O'\n 'TF_plant_totalCs137' 'TF_plant_exCs137' 'soil_pH' 'soil_C' 'soil_N'\n 'soil_CN_ratio' 'soil_CEC' 'soil_MgO' 'soil_CaO'\n 'soil_P_absorption_coefficient' 'avaiable_Pi' 'course_sand' 'fine_sand'\n 'silt' 'clay']\nX_names: [ 650  652  654 ... 3996 3998 4000]\n\n\n\nsource\n\nCWT\n\n CWT (data, dt=2, mother=&lt;pycwt.mothers.Morlet object at 0x7ff573abad40&gt;)\n\nInitialize self. See help(type(self)) for accurate signature.\n\n\nExported source\nclass CWT: \n    def __init__(self, data, dt=2, mother=pycwt.Morlet(6)):\n        fc.store_attr()\n        self.normalize()\n        self.init_params()\n        \n    def init_params(self):\n        self.N = self.data.size\n        self.s0 = 2 * self.dt  # Starting scale, in this case 2 * 0.25 years = 6 months  \n        self.dj = 1 / 12  # Twelve sub-octaves per octaves\n        self.J = 7 / self.dj  # Seven powers of two with dj sub-octaves\n            \n    def normalize(self):\n        self.std = self.data.std()  # Standard deviation\n        self.var = self.std ** 2  # Variance\n        self.data /= self.std  # Normalized dataset\n    \n    def get_wavelet(self):\n        cwt_results = cwt(self.data, self.dt, self.dj, self.s0, self.J, self.mother)\n        (self.wave, self.scales, self.freqs, self.coi, self.fft, self.fftfreqs) = cwt_results\n    \n    def get_powers(self):    \n        self.power = (np.abs(self.wave)) ** 2\n    \n    def get_period(self): \n        self.period = 1 / self.freqs\n    \n    def __call__(self):\n        self.get_wavelet()\n        self.get_powers()\n        self.get_period()\n        return self\n\n\n\nsource\n\n\nplot_cwt\n\n plot_cwt (cwt, wavenumbers, dt=2, figprops={'figsize': (6, 2), 'dpi':\n           144}, tight=True, fontsize=8, title='',\n           cmap=&lt;matplotlib.colors.LinearSegmentedColormap object at\n           0x7ff579760d30&gt;, save_path=None, show_plot=True,\n           show_coi:bool=False)\n\nPlot the continuous wavelet transform.\n\n\nExported source\ndef plot_cwt(cwt, wavenumbers,\n             dt=2, \n             figprops=dict(figsize=(6, 2), dpi=144), tight=True, \n             fontsize=8, title='', cmap=plt.cm.grey, save_path=None, \n             show_plot=True, show_coi:bool=False):\n    \"Plot the continuous wavelet transform.\"\n    fig, ax = plt.subplots(**figprops)\n    # if levels is None:\n    #     levels = [np.percentile(cwt.power, p) for p in [10, 20, 30, 40, 50, 75, 90, 95, 99, 99.5]]\n        \n    # log2_levels = np.log2(levels)\n    # contourf = ax.contourf(wavenumbers, np.log2(cwt.period), np.log2(cwt.power), \n    #                        log2_levels, extend='both', cmap=cmap)\n    # extent = [wavenumbers.min(), wavenumbers.max(), 0, max(cwt.period)]\n\n    im = ax.imshow(np.log2(cwt.power), aspect='auto', cmap=cmap,\n                   extent=[wavenumbers.min(), wavenumbers.max(), \n                           np.log2(cwt.period.max()), np.log2(cwt.period.min())],\n                   interpolation='nearest')\n    \n    # if show_coi:\n    #     ax.fill(np.concatenate([wavenumbers, wavenumbers[-1:] + dt, wavenumbers[-1:] + dt,\n    #                            wavenumbers[:1] - dt, wavenumbers[:1] - dt]),\n    #             np.concatenate([np.log2(cwt.coi), [1e-9], np.log2(cwt.period[-1:]),\n    #                            np.log2(cwt.period[-1:]), [1e-9]]),\n    #             'black', alpha=0.5 if not save_path else 1, \n    #             hatch='x'\n    #         )\n\n    ax.set_xlim(wavenumbers.min(), wavenumbers.max())\n    ax.set_ylim(np.log2(cwt.period.min()), np.log2(cwt.period.max()))\n    # ax.set_ylim(8, np.log2(cwt.period.max()))\n\n    if not save_path: \n        ax.set_title(title, fontsize=fontsize)\n        ax.set_ylabel('Period (wavenumbers)', fontsize=fontsize)\n        if not tight: ax.set_xlabel('Wavenumber', fontsize=fontsize)  # Added x-axis label\n\n    Yticks = 2 ** np.arange(np.ceil(np.log2(cwt.period.min())),\n                               np.ceil(np.log2(cwt.period.max())))\n    Yticks = Yticks.astype(int)\n\n    ax.set_yticks(np.log2(Yticks))\n    ax.set_yticklabels(Yticks, fontsize=fontsize-2)\n    \n    # Set major and minor ticks for x-axis\n    ax.xaxis.set_major_locator(plt.MultipleLocator(500))\n    ax.xaxis.set_minor_locator(plt.MultipleLocator(100))\n    \n    # Customize tick parameters\n    ax.tick_params(axis='x', which='major', labelsize=fontsize-2)\n    ax.tick_params(axis='x', which='minor', bottom=True)\n    \n    if not save_path:\n        # Add grid for both major and minor ticks\n        ax.grid(which='major', linestyle='-', linewidth='0.5', color='white', alpha=0.5)\n        ax.grid(which='minor', linestyle=':', linewidth='0.5', color='white', alpha=0.5)\n    \n        # Create a new colorbar with correct logarithmic scaling\n        # cbar = plt.colorbar(contourf, ax=ax, ticks=log2_levels)\n        # cbar = plt.colorbar(im, ax=ax, ticks=log2_levels)\n        # cbar.ax.set_yticklabels([f'{2**x:.1e}' for x in log2_levels])\n        # cbar.ax.tick_params(labelsize=fontsize-2)\n        # cbar.set_label('Power', fontsize=fontsize)\n    \n    if save_path:\n        ax.axis('off')\n        \n        # plt.savefig(save_path, bbox_inches='tight', pad_inches=0)\n        buf = io.BytesIO()\n        fig.savefig(buf, format='png', dpi=figprops['dpi'], bbox_inches='tight', pad_inches=0)\n        buf.seek(0)\n        img = Image.open(buf).convert('L')  # Convert to black and white\n        img.save(save_path)\n        buf.close()\n    \n    if show_plot:\n        plt.tight_layout()\n        plt.show()\n    else:\n        plt.close(fig)  # Close the figure without displaying it\n\n\n\nfrom dataclasses import astuple\nX, X_names, y, y_names, smp_idx, ds_name, ds_label = astuple(data)\n\n\npipe = Pipeline([\n    ('SNV', SNV()),\n    ('Derivative', TakeDerivative())\n])\n\nX_trans = pipe.fit_transform(data.X)\n\n\nsource\n\n\nOnlinePercentileEstimator\n\n OnlinePercentileEstimator (percentiles)\n\nInitialize self. See help(type(self)) for accurate signature.\n\n\nExported source\n# Outdated\nimport numpy as np\n\nclass OnlinePercentileEstimator:\n    def __init__(self, percentiles):\n        self.percentiles = percentiles\n        self.values = []\n\n    def update(self, array):\n        self.values.extend(array.flatten())\n\n    def calculate_percentiles(self):\n        self.values = np.array(self.values)\n        return np.percentile(self.values, self.percentiles)\n\n\nExample usage:\n\narray_list = [np.random.rand(85, 1700) for _ in range(10)]  # Replace with your actual arrays\npercentiles = [10, 50, 90]\n\nestimator = OnlinePercentileEstimator(percentiles)\n\nfor array in array_list:\n    estimator.update(array)\n\nresults = estimator.calculate_percentiles()\nprint(results)\n\n[0.10028646 0.50010463 0.8998105 ]\n\n\n\nsource\n\n\nOnlinePercentileEstimator\n\n OnlinePercentileEstimator (percentiles, n_samples=1000)\n\nEstimate the percentiles of the power of the wavelet transform of the spectra.\n\n\nExported source\n# Outdated\nclass OnlinePercentileEstimator:\n    \"Estimate the percentiles of the power of the wavelet transform of the spectra.\"\n    def __init__(self, percentiles, n_samples=1000):\n        self.percentiles = percentiles\n        self.n_samples = n_samples\n        self.values = np.empty((n_samples, len(percentiles)))\n        self.current_index = 0\n        self.is_full = False\n\n    def update(self, array):\n        array_flat = array.flatten()\n        percentiles_values = np.percentile(array_flat, self.percentiles)\n        n = len(percentiles_values)\n        if self.current_index + 1 &gt; self.n_samples:\n            self.is_full = True\n            self.current_index = 0  # Overwrite from the beginning if buffer is full\n        self.values[self.current_index, :] = percentiles_values\n        self.current_index += 1\n\n    def calculate_percentiles(self):\n        if self.is_full:\n            combined_values = self.values\n        else:\n            combined_values = self.values[:self.current_index, :]\n        return np.percentile(combined_values.flatten(), self.percentiles, axis=0)\n\n\n\nsource\n\n\nestimate_percentiles\n\n estimate_percentiles (X_trans, n_samples=100, percentiles=[10, 20, 30,\n                       40, 50, 60, 70, 80, 90, 95, 99])\n\nEstimate the percentiles of the power of the wavelet transform of the spectra.\n\n\nExported source\n# Outdated\ndef estimate_percentiles(X_trans, \n                         n_samples=100, \n                         percentiles=[10, 20, 30, 40, 50, 60, 70, 80, 90, 95, 99]):\n    \"Estimate the percentiles of the power of the wavelet transform of the spectra.\"\n    random_indices = np.random.choice(X_trans.shape[0], n_samples, replace=False)\n    estimator = OnlinePercentileEstimator(percentiles)\n    for i in tqdm(random_indices):\n        estimator.update(CWT(X_trans[i, :])().power)\n        \n    return estimator.calculate_percentiles()\n\n\n\n# Outdated\npercentiles_result = estimate_percentiles(X_trans, \n                                          n_samples=100,\n                                          percentiles=[20, 30, 40, 50, 60, 70, 80, 90, 95, 97, 99])\npercentiles_result\n\n100%|██████████| 100/100 [00:00&lt;00:00, 181.47it/s]\n\n\narray([5.14356882e-03, 5.09074173e-02, 3.50768754e-01, 2.04215562e+00,\n       8.17666232e+00, 2.48272509e+01, 4.12440530e+01, 5.88435369e+01,\n       7.26961617e+01, 7.69870270e+01, 8.88923508e+01])\n\n\n\nplot_cwt(CWT(X_trans[1, :])(), wavenumbers=data.X_names, \n         cmap=plt.cm.grey, save_path='../_data/test-1.png')\n\n\n\n\n\n\n\n\n\nplot_cwt(CWT(X_trans[0, :])(), wavenumbers=data.X_names, cmap=plt.cm.Spectral_r)\n\n\n\n\n\n\n\n\n\nsource\n\n\nestimate_conversion_time\n\n estimate_conversion_time (seconds=1000, samples=1000)\n\nEstimate the time to convert all spectra to images.\n\n\nExported source\ndef estimate_conversion_time(seconds=1000, samples=1000):\n    \"Estimate the time to convert all spectra to images.\"\n    return seconds * (samples / 1000) / 60\n\n\n\nsource\n\n\ncreate_image_target_csv\n\n create_image_target_csv (data:uhina.loading.SpectralData,\n                          n_samples:int=None,\n                          output_dir:str='../_data/ossl-tfm/',\n                          fname:str='im-targets-lut.csv')\n\nCreate a CSV file with the image names and the target values.\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ndata\nSpectralData\n\nSpectra dataclass\n\n\nn_samples\nint\nNone\nnumber of samples to process\n\n\noutput_dir\nstr\n../_data/ossl-tfm/\npath to save the CSV file\n\n\nfname\nstr\nim-targets-lut.csv\n\n\n\nReturns\nNone\n\n\n\n\n\n\n\nExported source\ndef create_image_target_csv(data: SpectralData, # Spectra dataclass\n                            n_samples: int = None, # number of samples to process\n                            output_dir: str = '../_data/ossl-tfm/', # path to save the CSV file\n                            fname: str = 'im-targets-lut.csv'\n                            ) -&gt; None: \n    \"Create a CSV file with the image names and the target values.\"\n    n_samples = len(data.sample_indices) if n_samples is None else n_samples\n    items = {\n        'fname': [f'{id}.png' for id in data.sample_indices[:n_samples]],\n    }\n    \n    for i, y_name in enumerate(data.y_names):\n        items[y_name] = [data.y[j, i].item() for j in range(n_samples)]\n    \n    df = pd.DataFrame(items)\n    df.to_csv(Path(output_dir) / fname, index=False)\n\n\n\ndst_dir = Path('../_data/fk-jumpei-tfm')\ncreate_image_target_csv(data, n_samples=None, output_dir=dst_dir)  \npd.read_csv(dst_dir / 'im-targets-lut.csv').head()\n\n635\n\n\n\n\n\n\n\n\n\nfname\nsoil_total_Cs134\nsoil_total_Cs137\nsoil_ex_Cs137\nexCs137_totalCs137\nsoil_water_soluble_K2O\nsoil_ex_K2O\nTF_plant_totalCs137\nTF_plant_exCs137\nsoil_pH\n...\nsoil_CN_ratio\nsoil_CEC\nsoil_MgO\nsoil_CaO\nsoil_P_absorption_coefficient\navaiable_Pi\ncourse_sand\nfine_sand\nsilt\nclay\n\n\n\n\n0\n20-2013-paddy_rice.png\nNaN\n610.0\n70.6\n0.116\nNaN\n17.6\nNaN\nNaN\n6.0\n...\n12.0\n29.5\n64.1\n339.0\n1700.0\nNaN\n17.1\n34.1\n25.6\n23.2\n\n\n1\n28-2014-paddy_rice.png\nNaN\n273.5\n27.8\n0.102\nNaN\n62.1\nNaN\nNaN\n5.0\n...\n12.0\n19.6\n30.3\n217.0\n660.0\n12.2\nNaN\nNaN\nNaN\nNaN\n\n\n2\n33-2014-paddy_rice.png\nNaN\n28.1\n3.6\n0.127\nNaN\n22.3\nNaN\nNaN\n6.0\n...\n12.0\n13.8\n38.1\n96.1\n640.0\n6.8\nNaN\nNaN\nNaN\nNaN\n\n\n3\n35-2014-paddy_rice.png\nNaN\n897.8\n71.4\n0.080\nNaN\n33.6\nNaN\nNaN\n5.0\n...\n12.0\n15.4\n16.2\n119.0\n640.0\n34.2\nNaN\nNaN\nNaN\nNaN\n\n\n4\n36-2014-paddy_rice.png\nNaN\n964.3\n90.6\n0.094\nNaN\n57.0\nNaN\nNaN\n5.0\n...\n12.0\n17.7\n19.9\n151.0\n610.0\n40.0\nNaN\nNaN\nNaN\nNaN\n\n\n\n\n5 rows × 22 columns\n\n\n\n\nsource\n\n\ncreate_output_directory\n\n create_output_directory (output_dir)\n\nCreate the output directory if it does not exist.\n\n\nExported source\ndef create_output_directory(output_dir):\n    \"Create the output directory if it does not exist.\"\n    os.makedirs(output_dir, exist_ok=True)\n\n\n\nsource\n\n\nprocess_single_sample\n\n process_single_sample (args)\n\nProcess a single sample and save the wavelet image to the output directory.\n\n\nExported source\ndef process_single_sample(args):\n    \"Process a single sample and save the wavelet image to the output directory.\"\n    i, id, X_trans_i, wavenumbers, output_dir, cwt_kwargs, plot_kwargs = args\n    fname_img = f'{output_dir}/{id}.png'\n    cwt_result = CWT(X_trans_i, **cwt_kwargs)()\n    plot_cwt(cwt_result, wavenumbers=wavenumbers, \n             save_path=fname_img, show_plot=False, **plot_kwargs)\n\n\n\nsource\n\n\nbatch_indices\n\n batch_indices (n_samples:int, batch_size:int)\n\nGenerate batch indices for processing.\n\n\nExported source\ndef batch_indices(n_samples: int, batch_size: int) -&gt; range:\n    \"Generate batch indices for processing.\"\n    for start in range(0, n_samples, batch_size):\n        end = min(start + batch_size, n_samples)\n        yield range(start, end)\n\n\n\nsource\n\n\nconvert_to_wavelet_images\n\n convert_to_wavelet_images (data:uhina.loading.SpectralData,\n                            pipeline:sklearn.pipeline.Pipeline=Pipeline(st\n                            eps=[('SNV', SNV()), ('Derivative',\n                            TakeDerivative())]),\n                            output_dir:str='../_data/im',\n                            cwt_kwargs:dict=None, plot_kwargs:dict=None,\n                            n_samples:int=None, batch_size:int=100,\n                            n_workers:int=None)\n\nProcess samples in parallel batches and save wavelet images to output directory.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ndata\nSpectralData\n\n\n\n\npipeline\nPipeline\nPipeline(steps=[(‘SNV’, SNV()), (‘Derivative’, TakeDerivative())])\nScikit-learn pipeline\n\n\noutput_dir\nstr\n../_data/im\n\n\n\ncwt_kwargs\ndict\nNone\n\n\n\nplot_kwargs\ndict\nNone\n\n\n\nn_samples\nint\nNone\n\n\n\nbatch_size\nint\n100\n\n\n\nn_workers\nint\nNone\n\n\n\nReturns\nNone\n\n\n\n\n\n\n\nExported source\ndefault_pipe = Pipeline([\n    ('SNV', SNV()),\n    ('Derivative', TakeDerivative())])\n\n\n\n\nExported source\ndef convert_to_wavelet_images(data: SpectralData,\n                              pipeline: Pipeline = default_pipe, # Scikit-learn pipeline\n                              output_dir: str = '../_data/im',\n                              cwt_kwargs: dict = None,\n                              plot_kwargs: dict = None,\n                              n_samples: int = None,\n                              batch_size: int = 100,\n                              n_workers: int = None,\n                              ) -&gt; None:\n    \"Process samples in parallel batches and save wavelet images to output directory.\"\n    create_output_directory(output_dir)\n    \n    cwt_kwargs = cwt_kwargs or {}\n    plot_kwargs = plot_kwargs or {}\n\n    n_samples = len(data.sample_indices) if n_samples is None else min(n_samples, len(data.sample_indices))\n    n_workers = n_workers or max(1, cpu_count() - 1)  # Use all cores except one by default\n    \n    X_trans = pipeline.fit_transform(data.X)\n    \n    with tqdm(total=n_samples, desc=\"Processing samples\") as pbar:\n        for batch in batch_indices(n_samples, batch_size):\n            args = [(i, data.sample_indices[i], X_trans[i, :], data.X_names, output_dir, cwt_kwargs, plot_kwargs) for i in batch]\n            with Pool(n_workers) as pool:\n                pool.map(process_single_sample, args)\n            \n            pbar.update(len(batch))\n    \n    return None\n\n\n\nconvert_to_wavelet_images(data, \n                          output_dir='../_data/fk-jumpei-tfm/im', \n                          n_samples=200, \n                          batch_size=10)\n\nProcessing samples:   0%|          | 0/200 [00:00&lt;?, ?it/s]Processing samples: 100%|██████████| 200/200 [00:10&lt;00:00, 18.49it/s]",
    "crumbs": [
      "Continuous Wavelet Transform"
    ]
  },
  {
    "objectID": "example/ringtrial-classic.html",
    "href": "example/ringtrial-classic.html",
    "title": "Ringtrial classic",
    "section": "",
    "text": "import pandas as pd\nfrom pathlib import Path\n\nfrom sklearn.metrics import r2_score\nfrom uhina.loading import LoaderFactory, plot_spectra\nfrom uhina.preprocessing import TakeDerivative, SNV\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.decomposition import PCA, KernelPCA\nfrom sklearn.preprocessing import StandardScaler\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\npd.set_option('display.max_rows', 100)\n\nimport plotly\nimport plotly.express as px\nimport numpy as np\nfrom astartes import train_val_test_split",
    "crumbs": [
      "example",
      "Ringtrial classic"
    ]
  },
  {
    "objectID": "example/ringtrial-classic.html#loading-data",
    "href": "example/ringtrial-classic.html#loading-data",
    "title": "Ringtrial classic",
    "section": "Loading data",
    "text": "Loading data\n\nsrc = Path.home() / 'pro/data/woodwell-ringtrial/drive-download-20231013T123706Z-001'\nloader = LoaderFactory.get_loader(src, 'ringtrial')\ndata = loader.load_data(analytes='potassium_cmolkg')\nprint(f'X shape: {data.X.shape}')\n\nplot_spectra(data, n_spectra=100, snv=True, alpha=0.2, figsize=(12, 3))\n\nX shape: (1400, 1676)\n\n\n(&lt;Figure size 1200x300 with 1 Axes&gt;,\n &lt;Axes: xlabel='Wavenumber ($cm^{-1}$)', ylabel='Absorbance'&gt;)\n\n\n\n\n\n\n\n\n\n\n[d for d in dir(data) if '__' not in d]\n\n['X',\n 'X_names',\n 'dataset_labels',\n 'dataset_names',\n 'sample_indices',\n 'y',\n 'y_names']\n\n\n\nprint(f'y_names: {data.y_names}')\n\ny_names: ['potassium_cmolkg']\n\n\n\nmask = ~np.isnan(data.y).ravel()\n\n\ndata.X = data.X[mask, :]\ndata.y = data.y[mask]\ndata.sample_indices = data.sample_indices[mask]\n\n\nnp.unique(np.array([idx.split('-rt')[0] for idx in data.sample_indices]))\n## EDA\n\narray(['agrocares', 'argonne', 'csu-il', 'eth-alpha-1', 'eth-alpha-2',\n       'eth-vertex', 'iaea-aug2022', 'kssl', 'landcare', 'lesotho', 'msu',\n       'osu', 'rothamsted', 'scion', 'ughent', 'uiuc', 'usp',\n       'uwisc-fine', 'woodwell-alpha', 'woodwell-vertex'], dtype='&lt;U15')\n\n\n\ndata.sample_indices\n\narray(['agrocares-rt-01', 'agrocares-rt-02', 'agrocares-rt-03', ...,\n       'woodwell-vertex-rt-68', 'woodwell-vertex-rt-69',\n       'woodwell-vertex-rt-70'], dtype=object)\n\n\n\nds = 'kssl'\nmask_ds = np.char.find(data.sample_indices.astype(str), ds) != -1\n\n\ndata.X = data.X[mask_ds, :]\ndata.y = data.y[mask_ds]\ndata.sample_indices = data.sample_indices[mask_ds]",
    "crumbs": [
      "example",
      "Ringtrial classic"
    ]
  },
  {
    "objectID": "example/ringtrial-classic.html#eda",
    "href": "example/ringtrial-classic.html#eda",
    "title": "Ringtrial classic",
    "section": "EDA",
    "text": "EDA\nVisualize in PCA space: - PCA - Robust PCA - Kernel PCA\n\npipe = Pipeline([\n    ('SNV', SNV()),\n    ('Derivative', TakeDerivative()),\n    ('Scaler', StandardScaler()),  \n    ('PCA', PCA(n_components=3))\n    ])\n\npca = PCA(n_components=3)\ndata.X_pca = pipe.fit_transform(data.X)\n\npipe = Pipeline([\n    # ('SNV', SNV()),\n    ('Derivative', TakeDerivative())\n    # ('Scaler', StandardScaler())\n    ])\n\ndata.X_transformed = pipe.fit_transform(data.X)\n\n\nplot_spectra(data, var='X_transformed', n_spectra=100, snv=True, alpha=0.2, figsize=(12, 3));\n\n\n\n\n\n\n\n\n\ndata.y = np.log1p(data.y)\n\n\ndef data_to_df(data, x_names=['PC1', 'PC2', 'PC3']):\n    df_x = pd.DataFrame(data.X_pca, columns=x_names)\n\n    # Create a DataFrame from data.y with column names from data.y_names\n    df_y = pd.DataFrame(data.y, columns=data.y_names)\n\n    # Concatenate the two DataFrames\n    return pd.concat([df_x, df_y], axis=1)\n\n\ndata_to_df(data).head()\n\n\n\n\n\n\n\n\nPC1\nPC2\nPC3\npotassium_cmolkg\n\n\n\n\n0\n39.053896\n5.976212\n-38.723251\n0.238276\n\n\n1\n-6.612691\n33.863092\n0.546687\n0.209848\n\n\n2\n11.784152\n-7.816915\n31.112676\n0.255487\n\n\n3\n2.177276\n9.013502\n-11.529199\n0.404965\n\n\n4\n2.192674\n9.798410\n-12.638061\n0.469860\n\n\n\n\n\n\n\n\ndef scatter3d(df, idxs=None, target_name='soil_ex_K2O', dot_size=15, color_by_split=False):\n    \"\"\"Generates a nicely formatted 3D scatter plot of the data\n    optionally showing train/validation/test splits.\n\n    Args:\n        df (pd.DataFrame): DataFrame containing the data\n        idxs (tuple of np.array, optional): train, validation, and\n            test indexes. Defaults to None.\n        dot_size (int, optional): Base size for dots. Defaults to 15.\n        color_by_split (bool, optional): If True, color by split instead of soil_ex_K2O. Defaults to False.\n    \"\"\"\n    df = df.copy()\n    df['size'] = dot_size\n    min_val, max_val = df[target_name].min(), df[target_name].max()\n    plot_args = dict(\n        data_frame=df,\n        x=\"PC1\",\n        y=\"PC2\",\n        z=\"PC3\",\n        opacity=1,\n        height=800,\n        width=800,\n        size='size',\n        size_max=dot_size\n    )\n\n    if idxs:\n        total_samples = len(df)\n        size_array = [dot_size] * total_samples\n        name_array = ['Unsplit'] * total_samples\n        \n        # Calculate relative sizes based on the number of splits\n        split_sizes = [len(split) for split in idxs]\n        max_split_size = max(split_sizes)\n        relative_sizes = [dot_size * (1 + 2 * (size / max_split_size)) for size in split_sizes]\n        \n        split_names = [\"Training\", \"Validation\", \"Testing\"][:len(idxs)]\n        \n        for split, split_size, split_name in zip(idxs, relative_sizes, split_names):\n            for idx in split:\n                size_array[idx] = split_size\n                name_array[idx] = split_name\n        \n        # pass these through to plotly call\n        plot_args[\"symbol\"] = \"Split\"\n        plot_args[\"size\"] = \"MarkerSize\"\n        df[\"MarkerSize\"] = np.array(size_array)\n        df[\"Split\"] = np.array(name_array)\n\n        if color_by_split:\n            plot_args[\"color\"] = \"Split\"\n            plot_args[\"color_discrete_map\"] = {\"Training\": \"#1b9e77\", \"Validation\": \"#d95f02\", \"Testing\": \"#7570b3\", \"Unsplit\": \"gray\"}\n        else:\n            plot_args[\"color\"] = target_name\n            plot_args[\"range_color\"] = [min_val, max_val]\n    else:\n        plot_args[\"color\"] = target_name\n        plot_args[\"range_color\"] = [min_val, max_val]\n\n    # actual call to plotly\n    fig = px.scatter_3d(**plot_args)\n\n    # add a legend for different split types\n    if idxs:\n        fig.update_layout(\n            legend=dict(orientation=\"h\", yanchor=\"bottom\", y=1.02, xanchor=\"right\", x=1)\n        )\n        fig.update_traces(marker=dict(line=dict(width=0)))\n\n        # make the markers consistent between plots\n        symbols = {\"Training\": \"circle\", \"Validation\": \"diamond\", \"Testing\": \"square\", \"Unsplit\": \"circle\"}\n        for i, d in enumerate(fig.data):\n            if d.name in symbols:\n                fig.data[i].marker.symbol = symbols[d.name]\n\n    # customize the colors\n    fig.update_layout(\n        dict(\n            plot_bgcolor=\"rgba(0, 0, 0, 0)\",\n            paper_bgcolor=\"rgba(0, 0, 0, 0)\",\n        )\n    )\n    axis_args = dict(\n        backgroundcolor=\"rgba(0, 0, 0,0)\",\n        gridcolor=\"grey\",\n        showbackground=True,\n        zerolinecolor=\"grey\",\n    )\n    fig.update_layout(scene=dict(xaxis=axis_args, yaxis=axis_args, zaxis=axis_args))\n\n    # render the plot\n    fig.show()\n\n\nscatter3d(data_to_df(data), target_name='potassium_cmolkg', dot_size=20)\n\nUnable to display output for mime type(s): application/vnd.plotly.v1+json",
    "crumbs": [
      "example",
      "Ringtrial classic"
    ]
  },
  {
    "objectID": "example/ringtrial-classic.html#trainvalidtest-splits",
    "href": "example/ringtrial-classic.html#trainvalidtest-splits",
    "title": "Ringtrial classic",
    "section": "Train/Valid/Test splits",
    "text": "Train/Valid/Test splits\nInspired from: https://jacksonburns.github.io/use-rse-23-astartes/split_comparisons.html\n\nInterpolative\n\nRandom split\n\n(\n    random_X_train,\n    random_X_val,\n    random_X_test,\n    random_y_train,\n    random_y_val,\n    random_y_test,\n    random_idxs_train,\n    random_idxs_val,\n    random_idxs_test,\n) = train_val_test_split(\n    data.X_transformed,\n    data.y,\n    sampler=\"random\",\n    train_size=0.5,\n    val_size=0.25,\n    test_size=0.25,\n    return_indices=True,\n    random_state=40\n)\n\n\nscatter3d(\n    data_to_df(data), \n    idxs=(random_idxs_train, random_idxs_val, random_idxs_test),\n    target_name='potassium_cmolkg',\n    color_by_split=True,\n    dot_size=20)\n\nUnable to display output for mime type(s): application/vnd.plotly.v1+json\n\n\n\n\nKennard-Stone\n\n(\n    ks_X_train,\n    ks_X_val,\n    ks_X_test,\n    ks_y_train,\n    ks_y_val,\n    ks_y_test,\n    ks_idxs_train,\n    ks_idxs_val,\n    ks_idxs_test,\n) = train_val_test_split(\n    data.X_transformed,\n    data.y,\n    sampler=\"kennard_stone\",\n    train_size=0.5,\n    val_size=0.25,\n    test_size=0.25,\n    return_indices=True,\n)\n\n\nscatter3d(\n    data_to_df(data), \n    target_name='potassium_cmolkg',\n    idxs=(ks_idxs_train, ks_idxs_val, ks_idxs_test),\n    color_by_split=True,\n    dot_size=20)\n\nUnable to display output for mime type(s): application/vnd.plotly.v1+json\n\n\n\n\nSPXY\n\ndata.y.shape\n\n(69, 1)\n\n\n\ndata.X_transformed.shape\n\n(69, 1676)\n\n\n\n(\n    spxy_X_train,\n    spxy_X_val,\n    spxy_X_test,\n    spxy_y_train,\n    spxy_y_val,\n    spxy_y_test,\n    spxy_idxs_train,\n    spxy_idxs_val,\n    spxy_idxs_test,\n) = train_val_test_split(\n    data.X_transformed,\n    data.y.ravel(),\n    sampler=\"spxy\",\n    train_size=0.5,\n    val_size=0.25,\n    test_size=0.25,\n    return_indices=True,\n)\n\n\nscatter3d(\n    data_to_df(data), \n     target_name='potassium_cmolkg',\n    idxs=(spxy_idxs_train, spxy_idxs_val, spxy_idxs_test),\n    color_by_split=True,\n    dot_size=13)\n\nUnable to display output for mime type(s): application/vnd.plotly.v1+json\n\n\n\n\n\nExtrapolative\n\nKMeans\n\n(\n    kmeans_X_train,\n    kmeans_X_val,\n    kmeans_X_test,\n    kmeans_y_train,\n    kmeans_y_val,\n    kmeans_y_test,\n    kmeans_clusters_train,\n    kmeans_clusters_val,\n    kmeans_clusters_test,\n    kmeans_idxs_train,\n    kmeans_idxs_val,\n    kmeans_idxs_test,\n) = train_val_test_split(\n    data.X_transformed,\n    data.y[:, 5],\n    sampler=\"kmeans\",\n    train_size=0.5,\n    val_size=0.25,\n    test_size=0.25,\n    return_indices=True,\n    hopts=dict(n_clusters=6),\n)\n\n\nscatter3d(\n    data_to_df(data), \n    idxs=(kmeans_idxs_train, kmeans_idxs_val, kmeans_idxs_test),\n    color_by_split=True,\n    dot_size=13)\n\nUnable to display output for mime type(s): application/vnd.plotly.v1+json\n\n\n\n\nSphere exclusion\n\n(\n    spex_X_train,\n    spex_X_val,\n    spex_X_test,\n    spex_y_train,\n    spex_y_val,\n    spex_y_test,\n    spex_clusters_train,\n    spex_clusters_val,\n    spex_clusters_test,\n    spex_idxs_train,\n    spex_idxs_val,\n    spex_idxs_test,\n) = train_val_test_split(\n    data.X_transformed,\n    data.y[:, 5],\n    sampler=\"sphere_exclusion\",\n    train_size=0.5,\n    val_size=0.25,\n    test_size=0.25,\n    return_indices=True,\n    hopts=dict(\n        # normalized between zero and one\n        distance_cutoff=0.1,\n    ),\n)\n\n\nscatter3d(\n    data_to_df(data), \n    idxs=(spex_idxs_train, spex_idxs_val, spex_idxs_test),\n    color_by_split=True,\n    dot_size=13)\n\nUnable to display output for mime type(s): application/vnd.plotly.v1+json\n\n\n\n\nDBSCAN\n\n# (\n#     dbscan_X_train,\n#     dbscan_X_val,\n#     dbscan_X_test,\n#     dbscan_y_train,\n#     dbscan_y_val,\n#     dbscan_y_test,\n#     dbscan_clusters_train,\n#     dbscan_clusters_val,\n#     dbscan_clusters_test,\n#     dbscan_idxs_train,\n#     dbscan_idxs_val,\n#     dbscan_idxs_test,\n# ) = train_val_test_split(\n#     data.X_transformed,\n#     data.y[:, 5],\n#     sampler=\"dbscan\",\n#     train_size=0.5,\n#     val_size=0.25,\n#     test_size=0.25,\n#     return_indices=True,\n#     hopts=dict(\n#         eps=100,\n#     ),\n# )",
    "crumbs": [
      "example",
      "Ringtrial classic"
    ]
  },
  {
    "objectID": "example/ringtrial-classic.html#training",
    "href": "example/ringtrial-classic.html#training",
    "title": "Ringtrial classic",
    "section": "Training",
    "text": "Training\n\ndef get_split_data(split_type):\n    split_names = ['X_train', 'X_val', 'X_test', 'y_train', 'y_val', 'y_test', 'idxs_train', 'idxs_val', 'idxs_test']\n    return {name: globals().get(f\"{split_type}_{name}\") for name in split_names}\n\nsplit_types = ['random', 'ks', 'spxy', 'kmeans', 'spex']\n\ndef get_data_for_split(split_type):\n    if split_type not in split_types:\n        raise ValueError(f\"Invalid split type. Choose from: {', '.join(split_types)}\")\n    \n    split_data = get_split_data(split_type)\n    \n    return (\n        split_data['X_train'], split_data['X_val'], split_data['X_test'],\n        split_data['y_train'], split_data['y_val'], split_data['y_test'],\n        split_data['idxs_train'], split_data['idxs_val'], split_data['idxs_test']\n    )\n\n\nsplit_type = 'ks'  # or any other split type\n\n(\n    X_train, \n    X_val, \n    X_test, \n    y_train, \n    y_val, \n    y_test, \n    idxs_train, \n    idxs_val, \n    idxs_test\n) = get_data_for_split(split_type)\n\n\nfrom sklearn.cross_decomposition import PLSRegression\nfrom tqdm.auto import tqdm\n\nscores = []\nn_max = 30\nfor n in tqdm(range(1,n_max)):\n    pls = PLSRegression(n_components=n)\n    pls.fit(X_train, y_train)\n    y_val_predicted = pls.predict(X_val)\n    scores.append(r2_score(y_val, y_val_predicted))\n\nfrom matplotlib import pyplot as plt\nplt.plot(range(1, n_max), scores)\nn_best = np.argmax(np.array(scores)) + 1\nprint(f'Best score: {scores[n_best]} at n={n_best}')\n# plt.ylim(0, 1)\n\n100%|██████████| 29/29 [00:00&lt;00:00, 99.32it/s] \n\n\nBest score: 0.45715906114471405 at n=2\n\n\n\n\n\n\n\n\n\n\n# ON TEST SET\npls = PLSRegression(n_components=n_best)\npls.fit(X_train, y_train)\ny_test_predicted = pls.predict(X_test)\nr2_score(y_test, y_test_predicted)\n\n0.6783592767273139\n\n\n\nsrc = '../../_data/fk-jumpei-tfm/im-targets-lut.csv'\ndf = pd.read_csv(src)\nprint(f'{df.shape[0]} samples')\ndf.head()\n\n635 samples\n\n\n\n\n\n\n\n\n\nfname\nsoil_total_Cs134\nsoil_total_Cs137\nsoil_ex_Cs137\nexCs137_totalCs137\nsoil_water_soluble_K2O\nsoil_ex_K2O\nTF_plant_totalCs137\nTF_plant_exCs137\nsoil_pH\n...\nsoil_CN_ratio\nsoil_CEC\nsoil_MgO\nsoil_CaO\nsoil_P_absorption_coefficient\navaiable_Pi\ncourse_sand\nfine_sand\nsilt\nclay\n\n\n\n\n0\n20-2013-paddy_rice.png\nNaN\n610.0\n70.6\n0.116\nNaN\n17.6\nNaN\nNaN\n6.0\n...\n12.0\n29.5\n64.1\n339.0\n1700.0\nNaN\n17.1\n34.1\n25.6\n23.2\n\n\n1\n28-2014-paddy_rice.png\nNaN\n273.5\n27.8\n0.102\nNaN\n62.1\nNaN\nNaN\n5.0\n...\n12.0\n19.6\n30.3\n217.0\n660.0\n12.2\nNaN\nNaN\nNaN\nNaN\n\n\n2\n33-2014-paddy_rice.png\nNaN\n28.1\n3.6\n0.127\nNaN\n22.3\nNaN\nNaN\n6.0\n...\n12.0\n13.8\n38.1\n96.1\n640.0\n6.8\nNaN\nNaN\nNaN\nNaN\n\n\n3\n35-2014-paddy_rice.png\nNaN\n897.8\n71.4\n0.080\nNaN\n33.6\nNaN\nNaN\n5.0\n...\n12.0\n15.4\n16.2\n119.0\n640.0\n34.2\nNaN\nNaN\nNaN\nNaN\n\n\n4\n36-2014-paddy_rice.png\nNaN\n964.3\n90.6\n0.094\nNaN\n57.0\nNaN\nNaN\n5.0\n...\n12.0\n17.7\n19.9\n151.0\n610.0\n40.0\nNaN\nNaN\nNaN\nNaN\n\n\n\n\n5 rows × 22 columns\n\n\n\n\ndef mg_100g_to_cmol_kg(x, log_tfm=False, atom_weight=39.1):\n    x_mg_kg = x * 10 \n    x_mg_kg_K = 0.83 * x_mg_kg\n    x_cmol_kg_K = x_mg_kg_K / (atom_weight*10)\n    return np.log1p(x_cmol_kg_K) if log_tfm else x_cmol_kg_K\n\n\nmg_100g_to_cmol_kg(df['soil_ex_K2O'], log_tfm=True).hist()\n\n\n\n\n\n\n\n\n\nprint('Before:', df.shape)\ndf.dropna(inplace=True, subset=['soil_ex_K2O'])\nprint('After:', df.shape)\n\nBefore: (635, 22)\nAfter: (634, 22)\n\n\n\ndf['soil_ex_K2O'] = df['soil_ex_K2O'].apply(lambda x: mg_100g_to_cmol_kg(x, log_tfm=True))\n df.soil_ex_K2O.hist()\n\n\n\n\n\n\n\n\n\nfor i, col in enumerate(df.columns):\n    print(f'{i}: {col}')\n\n0: fname\n1: soil_total_Cs134\n2: soil_total_Cs137\n3: soil_ex_Cs137\n4: exCs137_totalCs137\n5: soil_water_soluble_K2O\n6: soil_ex_K2O\n7: TF_plant_totalCs137\n8: TF_plant_exCs137\n9: soil_pH\n10: soil_C\n11: soil_N\n12: soil_CN_ratio\n13: soil_CEC\n14: soil_MgO\n15: soil_CaO\n16: soil_P_absorption_coefficient\n17: avaiable_Pi\n18: course_sand\n19: fine_sand\n20: silt\n21: clay",
    "crumbs": [
      "example",
      "Ringtrial classic"
    ]
  },
  {
    "objectID": "example/ringtrial-classic.html#fine-tuning",
    "href": "example/ringtrial-classic.html#fine-tuning",
    "title": "Ringtrial classic",
    "section": "Fine-tuning",
    "text": "Fine-tuning\n\nclass OrderedQuantize(Quantize):\n    order = 0  # Apply first\n\nclass OrderedRatioResize(RatioResize):\n    order = 1  # Apply second\n\n\ndef stratified_split(df, target, valid_size=0.2, test_size=0.2, num_bins=2, seed=41):\n    from sklearn.model_selection import train_test_split\n    df = df.copy()\n    df.reset_index(inplace=True, drop=True)\n    train_df, test_df = train_test_split(df, test_size=test_size, \n                                        stratify=pd.qcut(df[target], q=num_bins, labels=False), \n                                        random_state=seed)\n\n    train_df, valid_df = train_test_split(train_df, test_size=valid_size, \n                                        stratify=pd.qcut(train_df[target], q=num_bins, labels=False), \n                                        random_state=seed)\n    \n    return train_df, train_df.index, valid_df, valid_df.index, test_df, test_df.index\n\n\n# from sklearn.model_selection import StratifiedShuffleSplit\n\n# def stratified_split(df, target_col, n_bins=2, n_splits=2, test_size=0.2, random_state=42):\n#     # Create bins for the target values\n#     df_copy = df.copy()\n#     df_copy['target_bin'] = pd.cut(df_copy[target_col], bins=n_bins, labels=False)\n    \n#     # Create a StratifiedShuffleSplit object\n#     sss = StratifiedShuffleSplit(n_splits=n_splits, test_size=test_size, random_state=random_state)\n    \n#     # Get the indices for the splits\n#     splits = list(sss.split(df_copy, df_copy['target_bin']))\n    \n#     # Remove the temporary 'target_bin' column\n#     df_copy.drop('target_bin', axis=1, inplace=True)\n    \n#     return splits\n\n\ndf.head()\n\n\n\n\n\n\n\n\nfname\nsoil_total_Cs134\nsoil_total_Cs137\nsoil_ex_Cs137\nexCs137_totalCs137\nsoil_water_soluble_K2O\nsoil_ex_K2O\nTF_plant_totalCs137\nTF_plant_exCs137\nsoil_pH\n...\nsoil_CN_ratio\nsoil_CEC\nsoil_MgO\nsoil_CaO\nsoil_P_absorption_coefficient\navaiable_Pi\ncourse_sand\nfine_sand\nsilt\nclay\n\n\n\n\n0\n20-2013-paddy_rice.png\nNaN\n610.0\n70.6\n0.116\nNaN\n0.317439\nNaN\nNaN\n6.0\n...\n12.0\n29.5\n64.1\n339.0\n1700.0\nNaN\n17.1\n34.1\n25.6\n23.2\n\n\n1\n28-2014-paddy_rice.png\nNaN\n273.5\n27.8\n0.102\nNaN\n0.840806\nNaN\nNaN\n5.0\n...\n12.0\n19.6\n30.3\n217.0\n660.0\n12.2\nNaN\nNaN\nNaN\nNaN\n\n\n2\n33-2014-paddy_rice.png\nNaN\n28.1\n3.6\n0.127\nNaN\n0.387556\nNaN\nNaN\n6.0\n...\n12.0\n13.8\n38.1\n96.1\n640.0\n6.8\nNaN\nNaN\nNaN\nNaN\n\n\n3\n35-2014-paddy_rice.png\nNaN\n897.8\n71.4\n0.080\nNaN\n0.538391\nNaN\nNaN\n5.0\n...\n12.0\n15.4\n16.2\n119.0\n640.0\n34.2\nNaN\nNaN\nNaN\nNaN\n\n\n4\n36-2014-paddy_rice.png\nNaN\n964.3\n90.6\n0.094\nNaN\n0.792981\nNaN\nNaN\n5.0\n...\n12.0\n17.7\n19.9\n151.0\n610.0\n40.0\nNaN\nNaN\nNaN\nNaN\n\n\n\n\n5 rows × 22 columns\n\n\n\n\nidx = 6\ndf.columns[idx]\n\n'soil_ex_K2O'\n\n\n\ndata = stratified_split(df,  df.columns[idx], valid_size=0.2, test_size=0.2, num_bins=2)\ntrain_df, train_idx, valid_df, valid_idx, test_df, test_idx = data\n\n\n# # Usage example:\n# splits = stratified_split(df, df.columns[idx], n_bins=4, n_splits=2, random_state=41)\n\n# # For train-validation split\n# train_idx, valid_idx = splits[0]\n\n# # For train-test split (if needed)\n# train_valid_idx, test_idx = splits[1]\n\n# # Create DataFrames\n# train_df = df.iloc[train_idx]\n# valid_df = df.iloc[valid_idx]\n# test_df = df.iloc[test_idx]\n\n\nlen(train_df), len(valid_df), len(test_df)\n\n(405, 102, 127)\n\n\n\ntest_df[['fname', df.columns[idx]]]\n\n\n\n\n\n\n\n\nfname\nsoil_ex_K2O\n\n\n\n\n195\n758-2014-soybean.png\n0.973526\n\n\n77\n166-2016-paddy_rice.png\n0.571297\n\n\n224\n888-2014-paddy_rice.png\n0.329727\n\n\n580\n2391-2020-paddy_rice.png\n0.519631\n\n\n10\n51-2015-paddy_rice.png\n0.204683\n\n\n...\n...\n...\n\n\n520\n2131-2018-paddy_rice.png\n0.473116\n\n\n321\n1352-2014-paddy_rice.png\n0.739718\n\n\n226\n908-2014-paddy_rice.png\n0.202951\n\n\n137\n250-2017-paddy_rice.png\n0.095101\n\n\n378\n1988-2018-paddy_rice.png\n0.089294\n\n\n\n\n127 rows × 2 columns\n\n\n\n\ntrain_df['soil_ex_K2O'].hist()\n\n\n\n\n\n\n\n\n\nvalid_df['soil_ex_K2O'].hist()\n\n\n\n\n\n\n\n\n\ntest_df['soil_ex_K2O'].hist()\n\n\n\n\n\n\n\n\n\ndef stratified_splitter(items):\n    return [train_idx, valid_idx]\n\n\nlen(train_idx), len(valid_idx), len(test_idx)\n\n(405, 102, 127)\n\n\n\ndblock = DataBlock(\n    blocks=(ImageBlock, RegressionBlock),\n    get_x=ColReader(0, pref='../../_data/fk-jumpei-tfm/im/'),\n    get_y=ColReader(6),\n    splitter=stratified_splitter,\n    item_tfms=[OrderedQuantize(n_valid=len(valid_idx))],\n    batch_tfms=[\n        OrderedRatioResize(224),\n        Normalize.from_stats(*imagenet_stats)\n    ]\n)\n\n\n# dblock = DataBlock(blocks=(ImageBlock, RegressionBlock),\n#                    get_x=ColReader(0, pref='../../_data/fk-jumpei-tfm/im/'),\n#                    get_y=ColReader(idx),\n#                    splitter=stratified_splitter,\n#                    batch_tfms=[RatioResize(224)],\n#                    item_tfms=[Quantize(n_valid=len(valid_idx))])\n\n# # dblock.summary(df)\n\n\ndls = dblock.dataloaders(df, bs=16)\n\n\ndls.train.n, dls.valid.n\n\n(405, 102)\n\n\n\ndls.show_batch(nrows=6, ncols=2, figsize=(12, 13))\n\n\n\n\n\n\n\n\n\n# learn = load_learner('./models/650-4000-epoch-25-lr-3e-3.pkl', cpu=True)\nlearn = load_learner('./models/unfrozen-epoch-30-lr-1.5e-3-12102024.pkl', cpu=True)\n# learn = load_learner('./models/frozen-epoch-30-lr-1.5e-3-12102024.pkl', cpu=True)\n\n\nlearn.dls = dls\n\n\n# learn.summary()\n\n\nlearn.freeze()\n\n\n# learn.model[-1][-1]\n\n\n# model = learn.model\n# last_layer = model[-1][-1]\n# new_layer = nn.Linear(in_features=last_layer.in_features, \n#                       out_features=last_layer.out_features, \n#                       bias=True)\n# new_layer.weight.data = last_layer.weight.data\n# if hasattr(last_layer, 'bias') and last_layer.bias is not None:\n#     new_layer.bias.data = last_layer.bias.data\n# learn.model[-1][-1] = new_layer\n\n\n# learn.model[-1][-1]\n\n\nlearn.lr_find()\n\n\n\n\n\n\n\n\nSuggestedLRs(valley=0.0003981071640737355)\n\n\n\n\n\n\n\n\n\n\nlearn.fit_one_cycle(20, 4e-4)\n\n\n\n\n\n\n    \n      \n      30.00% [6/20 02:14&lt;05:14]\n    \n    \n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nr2_score\ntime\n\n\n\n\n0\n0.085307\n0.063526\n-0.155087\n00:21\n\n\n1\n0.073202\n0.090788\n-0.650800\n00:21\n\n\n2\n0.064845\n0.056194\n-0.021780\n00:22\n\n\n3\n0.058440\n0.168733\n-2.068068\n00:22\n\n\n4\n0.057954\n0.169698\n-2.085604\n00:22\n\n\n5\n0.058297\n0.072166\n-0.312190\n00:24\n\n\n\n\n\n    \n      \n      0.00% [0/7 00:00&lt;?]\n    \n    \n\n\n\n---------------------------------------------------------------------------\nKeyboardInterrupt                         Traceback (most recent call last)\nCell In[287], line 1\n----&gt; 1 learn.fit_one_cycle(20, 4e-4)\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/fastai/callback/schedule.py:121, in fit_one_cycle(self, n_epoch, lr_max, div, div_final, pct_start, wd, moms, cbs, reset_opt, start_epoch)\n    118 lr_max = np.array([h['lr'] for h in self.opt.hypers])\n    119 scheds = {'lr': combined_cos(pct_start, lr_max/div, lr_max, lr_max/div_final),\n    120           'mom': combined_cos(pct_start, *(self.moms if moms is None else moms))}\n--&gt; 121 self.fit(n_epoch, cbs=ParamScheduler(scheds)+L(cbs), reset_opt=reset_opt, wd=wd, start_epoch=start_epoch)\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/fastai/learner.py:266, in Learner.fit(self, n_epoch, lr, wd, cbs, reset_opt, start_epoch)\n    264 self.opt.set_hypers(lr=self.lr if lr is None else lr)\n    265 self.n_epoch = n_epoch\n--&gt; 266 self._with_events(self._do_fit, 'fit', CancelFitException, self._end_cleanup)\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/fastai/learner.py:201, in Learner._with_events(self, f, event_type, ex, final)\n    200 def _with_events(self, f, event_type, ex, final=noop):\n--&gt; 201     try: self(f'before_{event_type}');  f()\n    202     except ex: self(f'after_cancel_{event_type}')\n    203     self(f'after_{event_type}');  final()\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/fastai/learner.py:255, in Learner._do_fit(self)\n    253 for epoch in range(self.n_epoch):\n    254     self.epoch=epoch\n--&gt; 255     self._with_events(self._do_epoch, 'epoch', CancelEpochException)\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/fastai/learner.py:201, in Learner._with_events(self, f, event_type, ex, final)\n    200 def _with_events(self, f, event_type, ex, final=noop):\n--&gt; 201     try: self(f'before_{event_type}');  f()\n    202     except ex: self(f'after_cancel_{event_type}')\n    203     self(f'after_{event_type}');  final()\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/fastai/learner.py:250, in Learner._do_epoch(self)\n    248 def _do_epoch(self):\n    249     self._do_epoch_train()\n--&gt; 250     self._do_epoch_validate()\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/fastai/learner.py:246, in Learner._do_epoch_validate(self, ds_idx, dl)\n    244 if dl is None: dl = self.dls[ds_idx]\n    245 self.dl = dl\n--&gt; 246 with torch.no_grad(): self._with_events(self.all_batches, 'validate', CancelValidException)\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/fastai/learner.py:201, in Learner._with_events(self, f, event_type, ex, final)\n    200 def _with_events(self, f, event_type, ex, final=noop):\n--&gt; 201     try: self(f'before_{event_type}');  f()\n    202     except ex: self(f'after_cancel_{event_type}')\n    203     self(f'after_{event_type}');  final()\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/fastai/learner.py:207, in Learner.all_batches(self)\n    205 def all_batches(self):\n    206     self.n_iter = len(self.dl)\n--&gt; 207     for o in enumerate(self.dl): self.one_batch(*o)\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/fastai/data/load.py:129, in DataLoader.__iter__(self)\n    127 self.before_iter()\n    128 self.__idxs=self.get_idxs() # called in context of main process (not workers/subprocesses)\n--&gt; 129 for b in _loaders[self.fake_l.num_workers==0](self.fake_l):\n    130     # pin_memory causes tuples to be converted to lists, so convert them back to tuples\n    131     if self.pin_memory and type(b) == list: b = tuple(b)\n    132     if self.device is not None: b = to_device(b, self.device)\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/torch/utils/data/dataloader.py:630, in _BaseDataLoaderIter.__next__(self)\n    627 if self._sampler_iter is None:\n    628     # TODO(https://github.com/pytorch/pytorch/issues/76750)\n    629     self._reset()  # type: ignore[call-arg]\n--&gt; 630 data = self._next_data()\n    631 self._num_yielded += 1\n    632 if self._dataset_kind == _DatasetKind.Iterable and \\\n    633         self._IterableDataset_len_called is not None and \\\n    634         self._num_yielded &gt; self._IterableDataset_len_called:\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/torch/utils/data/dataloader.py:673, in _SingleProcessDataLoaderIter._next_data(self)\n    671 def _next_data(self):\n    672     index = self._next_index()  # may raise StopIteration\n--&gt; 673     data = self._dataset_fetcher.fetch(index)  # may raise StopIteration\n    674     if self._pin_memory:\n    675         data = _utils.pin_memory.pin_memory(data, self._pin_memory_device)\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py:42, in _IterableDatasetFetcher.fetch(self, possibly_batched_index)\n     40         raise StopIteration\n     41 else:\n---&gt; 42     data = next(self.dataset_iter)\n     43 return self.collate_fn(data)\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/fastai/data/load.py:140, in DataLoader.create_batches(self, samps)\n    138 if self.dataset is not None: self.it = iter(self.dataset)\n    139 res = filter(lambda o:o is not None, map(self.do_item, samps))\n--&gt; 140 yield from map(self.do_batch, self.chunkify(res))\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/fastcore/basics.py:245, in chunked(it, chunk_sz, drop_last, n_chunks)\n    243 if not isinstance(it, Iterator): it = iter(it)\n    244 while True:\n--&gt; 245     res = list(itertools.islice(it, chunk_sz))\n    246     if res and (len(res)==chunk_sz or not drop_last): yield res\n    247     if len(res)&lt;chunk_sz: return\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/fastai/data/load.py:170, in DataLoader.do_item(self, s)\n    169 def do_item(self, s):\n--&gt; 170     try: return self.after_item(self.create_item(s))\n    171     except SkipItemException: return None\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/fastcore/transform.py:210, in Pipeline.__call__(self, o)\n--&gt; 210 def __call__(self, o): return compose_tfms(o, tfms=self.fs, split_idx=self.split_idx)\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/fastcore/transform.py:160, in compose_tfms(x, tfms, is_enc, reverse, **kwargs)\n    158 for f in tfms:\n    159     if not is_enc: f = f.decode\n--&gt; 160     x = f(x, **kwargs)\n    161 return x\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/fastai/vision/augment.py:51, in RandTransform.__call__(self, b, split_idx, **kwargs)\n     45 def __call__(self, \n     46     b, \n     47     split_idx:int=None, # Index of the train/valid dataset\n     48     **kwargs\n     49 ):\n     50     self.before_call(b, split_idx=split_idx)\n---&gt; 51     return super().__call__(b, split_idx=split_idx, **kwargs) if self.do else b\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/fastcore/transform.py:83, in Transform.__call__(self, x, **kwargs)\n---&gt; 83 def __call__(self, x, **kwargs): return self._call('encodes', x, **kwargs)\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/fastcore/transform.py:93, in Transform._call(self, fn, x, split_idx, **kwargs)\n     91 def _call(self, fn, x, split_idx=None, **kwargs):\n     92     if split_idx!=self.split_idx and self.split_idx is not None: return x\n---&gt; 93     return self._do_call(getattr(self, fn), x, **kwargs)\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/fastcore/transform.py:100, in Transform._do_call(self, f, x, **kwargs)\n     98     ret = f.returns(x) if hasattr(f,'returns') else None\n     99     return retain_type(f(x, **kwargs), x, ret)\n--&gt; 100 res = tuple(self._do_call(f, x_, **kwargs) for x_ in x)\n    101 return retain_type(res, x)\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/fastcore/transform.py:100, in &lt;genexpr&gt;(.0)\n     98     ret = f.returns(x) if hasattr(f,'returns') else None\n     99     return retain_type(f(x, **kwargs), x, ret)\n--&gt; 100 res = tuple(self._do_call(f, x_, **kwargs) for x_ in x)\n    101 return retain_type(res, x)\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/fastcore/transform.py:99, in Transform._do_call(self, f, x, **kwargs)\n     97     if f is None: return x\n     98     ret = f.returns(x) if hasattr(f,'returns') else None\n---&gt; 99     return retain_type(f(x, **kwargs), x, ret)\n    100 res = tuple(self._do_call(f, x_, **kwargs) for x_ in x)\n    101 return retain_type(res, x)\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/fastcore/dispatch.py:122, in TypeDispatch.__call__(self, *args, **kwargs)\n    120 elif self.inst is not None: f = MethodType(f, self.inst)\n    121 elif self.owner is not None: f = MethodType(f, self.owner)\n--&gt; 122 return f(*args, **kwargs)\n\nFile ~/pro/dev/uhina/uhina/augment.py:50, in Quantize.encodes(self, x)\n     48 im_tensor = image2tensor(x)[0, :, :]\n     49 percentiles = self.get_percentiles()\n---&gt; 50 levels = torch.quantile(im_tensor.float(), percentiles / 100)\n     51 im_quant = torch.bucketize(im_tensor.float(), levels)\n     53 cmap = plt.get_cmap('Spectral_r')\n\nKeyboardInterrupt: \n\n\n\n\nval_preds, val_targets = learn.get_preds(dl=dls.valid)\nr2_score(val_targets, val_preds)\n\n\n\n\n\n\n\n\n0.23469541349548861\n\n\n\nlearn.unfreeze()\n\n\nlearn.lr_find()\n\n\n\n\n\n\n\n\nSuggestedLRs(valley=5.248074739938602e-05)\n\n\n\n\n\n\n\n\n\n\n# learn.fit_one_cycle(20, slice(1e-5, 1.5e-3))\nlearn.fit_one_cycle(20, 1.5e-3)\n\n\n\n\n\n\n    \n      \n      15.00% [3/20 01:05&lt;06:11]\n    \n    \n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nr2_score\ntime\n\n\n\n\n0\n0.043800\n0.053276\n0.031285\n00:22\n\n\n1\n0.046924\n0.054486\n0.009281\n00:21\n\n\n2\n0.051729\n0.184493\n-2.354623\n00:21\n\n\n\n\n\n    \n      \n      16.00% [4/25 00:03&lt;00:16 0.0514]\n    \n    \n\n\n\n---------------------------------------------------------------------------\nKeyboardInterrupt                         Traceback (most recent call last)\nCell In[183], line 2\n      1 # learn.fit_one_cycle(20, slice(1e-5, 1.5e-3))\n----&gt; 2 learn.fit_one_cycle(20, 1.5e-3)\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/fastai/callback/schedule.py:121, in fit_one_cycle(self, n_epoch, lr_max, div, div_final, pct_start, wd, moms, cbs, reset_opt, start_epoch)\n    118 lr_max = np.array([h['lr'] for h in self.opt.hypers])\n    119 scheds = {'lr': combined_cos(pct_start, lr_max/div, lr_max, lr_max/div_final),\n    120           'mom': combined_cos(pct_start, *(self.moms if moms is None else moms))}\n--&gt; 121 self.fit(n_epoch, cbs=ParamScheduler(scheds)+L(cbs), reset_opt=reset_opt, wd=wd, start_epoch=start_epoch)\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/fastai/learner.py:266, in Learner.fit(self, n_epoch, lr, wd, cbs, reset_opt, start_epoch)\n    264 self.opt.set_hypers(lr=self.lr if lr is None else lr)\n    265 self.n_epoch = n_epoch\n--&gt; 266 self._with_events(self._do_fit, 'fit', CancelFitException, self._end_cleanup)\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/fastai/learner.py:201, in Learner._with_events(self, f, event_type, ex, final)\n    200 def _with_events(self, f, event_type, ex, final=noop):\n--&gt; 201     try: self(f'before_{event_type}');  f()\n    202     except ex: self(f'after_cancel_{event_type}')\n    203     self(f'after_{event_type}');  final()\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/fastai/learner.py:255, in Learner._do_fit(self)\n    253 for epoch in range(self.n_epoch):\n    254     self.epoch=epoch\n--&gt; 255     self._with_events(self._do_epoch, 'epoch', CancelEpochException)\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/fastai/learner.py:201, in Learner._with_events(self, f, event_type, ex, final)\n    200 def _with_events(self, f, event_type, ex, final=noop):\n--&gt; 201     try: self(f'before_{event_type}');  f()\n    202     except ex: self(f'after_cancel_{event_type}')\n    203     self(f'after_{event_type}');  final()\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/fastai/learner.py:249, in Learner._do_epoch(self)\n    248 def _do_epoch(self):\n--&gt; 249     self._do_epoch_train()\n    250     self._do_epoch_validate()\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/fastai/learner.py:241, in Learner._do_epoch_train(self)\n    239 def _do_epoch_train(self):\n    240     self.dl = self.dls.train\n--&gt; 241     self._with_events(self.all_batches, 'train', CancelTrainException)\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/fastai/learner.py:201, in Learner._with_events(self, f, event_type, ex, final)\n    200 def _with_events(self, f, event_type, ex, final=noop):\n--&gt; 201     try: self(f'before_{event_type}');  f()\n    202     except ex: self(f'after_cancel_{event_type}')\n    203     self(f'after_{event_type}');  final()\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/fastai/learner.py:207, in Learner.all_batches(self)\n    205 def all_batches(self):\n    206     self.n_iter = len(self.dl)\n--&gt; 207     for o in enumerate(self.dl): self.one_batch(*o)\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/fastai/learner.py:237, in Learner.one_batch(self, i, b)\n    235 b = self._set_device(b)\n    236 self._split(b)\n--&gt; 237 self._with_events(self._do_one_batch, 'batch', CancelBatchException)\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/fastai/learner.py:203, in Learner._with_events(self, f, event_type, ex, final)\n    201 try: self(f'before_{event_type}');  f()\n    202 except ex: self(f'after_cancel_{event_type}')\n--&gt; 203 self(f'after_{event_type}');  final()\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/fastai/learner.py:174, in Learner.__call__(self, event_name)\n--&gt; 174 def __call__(self, event_name): L(event_name).map(self._call_one)\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/fastcore/foundation.py:159, in L.map(self, f, *args, **kwargs)\n--&gt; 159 def map(self, f, *args, **kwargs): return self._new(map_ex(self, f, *args, gen=False, **kwargs))\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/fastcore/basics.py:899, in map_ex(iterable, f, gen, *args, **kwargs)\n    897 res = map(g, iterable)\n    898 if gen: return res\n--&gt; 899 return list(res)\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/fastcore/basics.py:884, in bind.__call__(self, *args, **kwargs)\n    882     if isinstance(v,_Arg): kwargs[k] = args.pop(v.i)\n    883 fargs = [args[x.i] if isinstance(x, _Arg) else x for x in self.pargs] + args[self.maxi+1:]\n--&gt; 884 return self.func(*fargs, **kwargs)\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/fastai/learner.py:178, in Learner._call_one(self, event_name)\n    176 def _call_one(self, event_name):\n    177     if not hasattr(event, event_name): raise Exception(f'missing {event_name}')\n--&gt; 178     for cb in self.cbs.sorted('order'): cb(event_name)\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/fastai/callback/core.py:62, in Callback.__call__(self, event_name)\n     60 res = None\n     61 if self.run and _run: \n---&gt; 62     try: res = getcallable(self, event_name)()\n     63     except (CancelBatchException, CancelBackwardException, CancelEpochException, CancelFitException, CancelStepException, CancelTrainException, CancelValidException): raise\n     64     except Exception as e: raise modify_exception(e, f'Exception occured in `{self.__class__.__name__}` when calling event `{event_name}`:\\n\\t{e.args[0]}', replace=True)\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/fastai/learner.py:562, in Recorder.after_batch(self)\n    560 if len(self.yb) == 0: return\n    561 mets = self._train_mets if self.training else self._valid_mets\n--&gt; 562 for met in mets: met.accumulate(self.learn)\n    563 if not self.training: return\n    564 self.lrs.append(self.opt.hypers[-1]['lr'])\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/fastai/learner.py:511, in AvgSmoothLoss.accumulate(self, learn)\n    509 def accumulate(self, learn):\n    510     self.count += 1\n--&gt; 511     self.val = torch.lerp(to_detach(learn.loss.mean()), self.val, self.beta)\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/fastai/torch_core.py:246, in to_detach(b, cpu, gather)\n    244     if gather: x = maybe_gather(x)\n    245     return x.cpu() if cpu else x\n--&gt; 246 return apply(_inner, b, cpu=cpu, gather=gather)\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/fastai/torch_core.py:226, in apply(func, x, *args, **kwargs)\n    224 if is_listy(x): return type(x)([apply(func, o, *args, **kwargs) for o in x])\n    225 if isinstance(x,(dict,MutableMapping)): return {k: apply(func, v, *args, **kwargs) for k,v in x.items()}\n--&gt; 226 res = func(x, *args, **kwargs)\n    227 return res if x is None else retain_type(res, x)\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/fastai/torch_core.py:245, in to_detach.&lt;locals&gt;._inner(x, cpu, gather)\n    243 x = x.detach()\n    244 if gather: x = maybe_gather(x)\n--&gt; 245 return x.cpu() if cpu else x\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/fastai/torch_core.py:384, in TensorBase.__torch_function__(cls, func, types, args, kwargs)\n    382 if cls.debug and func.__name__ not in ('__str__','__repr__'): print(func, types, args, kwargs)\n    383 if _torch_handled(args, cls._opt, func): types = (torch.Tensor,)\n--&gt; 384 res = super().__torch_function__(func, types, args, ifnone(kwargs, {}))\n    385 dict_objs = _find_args(args) if args else _find_args(list(kwargs.values()))\n    386 if issubclass(type(res),TensorBase) and dict_objs: res.set_meta(dict_objs[0],as_copy=True)\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/torch/_tensor.py:1437, in Tensor.__torch_function__(cls, func, types, args, kwargs)\n   1434     return NotImplemented\n   1436 with _C.DisableTorchFunctionSubclass():\n-&gt; 1437     ret = func(*args, **kwargs)\n   1438     if func in get_default_nowrap_functions():\n   1439         return ret\n\nKeyboardInterrupt: \n\n\n\n\nval_preds, val_targets = learn.get_preds(dl=dls.valid)\nr2_score(val_targets, val_preds)\n\n\n\n\n\n\n\n\n0.36861295616974843\n\n\n\nEvaluate fine-tuned model\n\nlen(test_df)\n\n127\n\n\n\ndblock = DataBlock(blocks=(ImageBlock, RegressionBlock),\n                   get_x=ColReader(0, pref='../../_data/fk-jumpei-tfm/im/'),\n                   get_y=ColReader(idx),\n                   splitter=RandomSplitter(valid_pct=0, seed=41),\n                   batch_tfms=[RatioResize(224)],\n                   item_tfms=[Quantize(n_valid=len(test_df))])\n\ndls = dblock.dataloaders(test_df, bs=len(test_df))\n\n\nval_preds, val_targets = learn.get_preds(dl=dls.train)\n\n\n\n\n\n\n\n\n\nr2_score(val_targets, val_preds)\n\n-0.012676790057743803\n\n\n\nval_preds, val_targets = learn.tta(dl=dls.train, n=30)\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n---------------------------------------------------------------------------\nKeyboardInterrupt                         Traceback (most recent call last)\nCell In[120], line 1\n----&gt; 1 val_preds, val_targets = learn.tta(dl=dls.train, n=30)\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/fastai/learner.py:678, in tta(self, ds_idx, dl, n, item_tfms, batch_tfms, beta, use_max)\n    676     for i in self.progress.mbar if hasattr(self,'progress') else range(n):\n    677         self.epoch = i #To keep track of progress on mbar since the progress callback will use self.epoch\n--&gt; 678         aug_preds.append(self.get_preds(dl=dl, inner=True)[0][None])\n    679 aug_preds = torch.cat(aug_preds)\n    680 aug_preds = aug_preds.max(0)[0] if use_max else aug_preds.mean(0)\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/fastai/learner.py:310, in Learner.get_preds(self, ds_idx, dl, with_input, with_decoded, with_loss, act, inner, reorder, cbs, **kwargs)\n    308 if with_loss: ctx_mgrs.append(self.loss_not_reduced())\n    309 with ContextManagers(ctx_mgrs):\n--&gt; 310     self._do_epoch_validate(dl=dl)\n    311     if act is None: act = getcallable(self.loss_func, 'activation')\n    312     res = cb.all_tensors()\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/fastai/learner.py:246, in Learner._do_epoch_validate(self, ds_idx, dl)\n    244 if dl is None: dl = self.dls[ds_idx]\n    245 self.dl = dl\n--&gt; 246 with torch.no_grad(): self._with_events(self.all_batches, 'validate', CancelValidException)\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/fastai/learner.py:201, in Learner._with_events(self, f, event_type, ex, final)\n    200 def _with_events(self, f, event_type, ex, final=noop):\n--&gt; 201     try: self(f'before_{event_type}');  f()\n    202     except ex: self(f'after_cancel_{event_type}')\n    203     self(f'after_{event_type}');  final()\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/fastai/learner.py:207, in Learner.all_batches(self)\n    205 def all_batches(self):\n    206     self.n_iter = len(self.dl)\n--&gt; 207     for o in enumerate(self.dl): self.one_batch(*o)\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/fastai/data/load.py:129, in DataLoader.__iter__(self)\n    127 self.before_iter()\n    128 self.__idxs=self.get_idxs() # called in context of main process (not workers/subprocesses)\n--&gt; 129 for b in _loaders[self.fake_l.num_workers==0](self.fake_l):\n    130     # pin_memory causes tuples to be converted to lists, so convert them back to tuples\n    131     if self.pin_memory and type(b) == list: b = tuple(b)\n    132     if self.device is not None: b = to_device(b, self.device)\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/torch/utils/data/dataloader.py:630, in _BaseDataLoaderIter.__next__(self)\n    627 if self._sampler_iter is None:\n    628     # TODO(https://github.com/pytorch/pytorch/issues/76750)\n    629     self._reset()  # type: ignore[call-arg]\n--&gt; 630 data = self._next_data()\n    631 self._num_yielded += 1\n    632 if self._dataset_kind == _DatasetKind.Iterable and \\\n    633         self._IterableDataset_len_called is not None and \\\n    634         self._num_yielded &gt; self._IterableDataset_len_called:\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/torch/utils/data/dataloader.py:673, in _SingleProcessDataLoaderIter._next_data(self)\n    671 def _next_data(self):\n    672     index = self._next_index()  # may raise StopIteration\n--&gt; 673     data = self._dataset_fetcher.fetch(index)  # may raise StopIteration\n    674     if self._pin_memory:\n    675         data = _utils.pin_memory.pin_memory(data, self._pin_memory_device)\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py:42, in _IterableDatasetFetcher.fetch(self, possibly_batched_index)\n     40         raise StopIteration\n     41 else:\n---&gt; 42     data = next(self.dataset_iter)\n     43 return self.collate_fn(data)\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/fastai/data/load.py:140, in DataLoader.create_batches(self, samps)\n    138 if self.dataset is not None: self.it = iter(self.dataset)\n    139 res = filter(lambda o:o is not None, map(self.do_item, samps))\n--&gt; 140 yield from map(self.do_batch, self.chunkify(res))\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/fastcore/basics.py:245, in chunked(it, chunk_sz, drop_last, n_chunks)\n    243 if not isinstance(it, Iterator): it = iter(it)\n    244 while True:\n--&gt; 245     res = list(itertools.islice(it, chunk_sz))\n    246     if res and (len(res)==chunk_sz or not drop_last): yield res\n    247     if len(res)&lt;chunk_sz: return\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/fastai/data/load.py:170, in DataLoader.do_item(self, s)\n    169 def do_item(self, s):\n--&gt; 170     try: return self.after_item(self.create_item(s))\n    171     except SkipItemException: return None\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/fastcore/transform.py:210, in Pipeline.__call__(self, o)\n--&gt; 210 def __call__(self, o): return compose_tfms(o, tfms=self.fs, split_idx=self.split_idx)\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/fastcore/transform.py:160, in compose_tfms(x, tfms, is_enc, reverse, **kwargs)\n    158 for f in tfms:\n    159     if not is_enc: f = f.decode\n--&gt; 160     x = f(x, **kwargs)\n    161 return x\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/fastai/vision/augment.py:51, in RandTransform.__call__(self, b, split_idx, **kwargs)\n     45 def __call__(self, \n     46     b, \n     47     split_idx:int=None, # Index of the train/valid dataset\n     48     **kwargs\n     49 ):\n     50     self.before_call(b, split_idx=split_idx)\n---&gt; 51     return super().__call__(b, split_idx=split_idx, **kwargs) if self.do else b\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/fastcore/transform.py:83, in Transform.__call__(self, x, **kwargs)\n---&gt; 83 def __call__(self, x, **kwargs): return self._call('encodes', x, **kwargs)\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/fastcore/transform.py:93, in Transform._call(self, fn, x, split_idx, **kwargs)\n     91 def _call(self, fn, x, split_idx=None, **kwargs):\n     92     if split_idx!=self.split_idx and self.split_idx is not None: return x\n---&gt; 93     return self._do_call(getattr(self, fn), x, **kwargs)\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/fastcore/transform.py:100, in Transform._do_call(self, f, x, **kwargs)\n     98     ret = f.returns(x) if hasattr(f,'returns') else None\n     99     return retain_type(f(x, **kwargs), x, ret)\n--&gt; 100 res = tuple(self._do_call(f, x_, **kwargs) for x_ in x)\n    101 return retain_type(res, x)\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/fastcore/transform.py:100, in &lt;genexpr&gt;(.0)\n     98     ret = f.returns(x) if hasattr(f,'returns') else None\n     99     return retain_type(f(x, **kwargs), x, ret)\n--&gt; 100 res = tuple(self._do_call(f, x_, **kwargs) for x_ in x)\n    101 return retain_type(res, x)\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/fastcore/transform.py:99, in Transform._do_call(self, f, x, **kwargs)\n     97     if f is None: return x\n     98     ret = f.returns(x) if hasattr(f,'returns') else None\n---&gt; 99     return retain_type(f(x, **kwargs), x, ret)\n    100 res = tuple(self._do_call(f, x_, **kwargs) for x_ in x)\n    101 return retain_type(res, x)\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/fastcore/dispatch.py:122, in TypeDispatch.__call__(self, *args, **kwargs)\n    120 elif self.inst is not None: f = MethodType(f, self.inst)\n    121 elif self.owner is not None: f = MethodType(f, self.owner)\n--&gt; 122 return f(*args, **kwargs)\n\nFile ~/pro/dev/uhina/uhina/augment.py:51, in Quantize.encodes(self, x)\n     49 percentiles = self.get_percentiles()\n     50 levels = torch.quantile(im_tensor.float(), percentiles / 100)\n---&gt; 51 im_quant = torch.bucketize(im_tensor.float(), levels)\n     53 cmap = plt.get_cmap('Spectral_r')\n     54 im_color = tensor(cmap(im_quant.float() / im_quant.max())[:,:,:3])\n\nKeyboardInterrupt: \n\n\n\n\nnp.c_[val_preds, val_targets][:10]\n\narray([[0.6631091 , 0.7696582 ],\n       [0.45307112, 0.5359099 ],\n       [0.28646332, 0.25363058],\n       [0.891094  , 0.96547544],\n       [0.47445062, 0.54948056],\n       [1.4899724 , 1.4513922 ],\n       [0.3082603 , 0.25363058],\n       [0.41703525, 0.27481836],\n       [0.42921203, 0.4435868 ],\n       [0.77836686, 0.80633885]], dtype=float32)\n\n\n\nx, y = val_preds, val_targets\nplt.plot(x, y, '.')\n# Add the diagonal line\nmin_val = min(y.min(), x.min())\nmax_val = max(y.max(), x.max())\nplt.plot([min_val, max_val], [min_val, max_val], 'k--', lw=1)\n\n\n\n\n\n\n\n\n\nr2_score(val_targets, val_preds)\n\n0.8264008364793762\n\n\n\n\nOn single images\n\ndef predict_with_transforms(learn, img_path, n_predictions=5):\n    # Load the image\n    img = PILImage.create(img_path)\n    \n    # Create instances of the transforms\n    ratio_resize = RatioResize(224)\n    quantize = Quantize()\n    \n    predictions = []\n    for _ in range(n_predictions):\n        # Apply transforms\n        img_resized = ratio_resize(img)\n        img_quantized = quantize(img_resized)\n        \n        # Predict\n        pred, _, _ = learn.predict(img_quantized)\n        predictions.append(pred[0])\n    \n    from statistics import mode\n    # Calculate mean and standard deviation\n    mean_pred = np.mean(predictions)\n    std_pred = np.std(predictions)\n    median_pred = np.median(predictions)\n    mode_pred = mode(predictions)\n    return mean_pred, std_pred, median_pred, mode_pred, predictions\n\n\ntest_df[['fname', df.columns[idx]]]\n\n\n\n\n\n\n\n\nfname\nsoil_ex_K2O\n\n\n\n\n217\n859-2014-paddy_rice.png\n0.539629\n\n\n163\n278-2018-paddy_rice.png\n0.341865\n\n\n243\n968-2014-paddy_rice.png\n0.578465\n\n\n467\n2076-2018-paddy_rice.png\n0.338844\n\n\n513\n2123-2018-paddy_rice.png\n1.048431\n\n\n...\n...\n...\n\n\n605\n2419-2020-paddy_rice.png\n0.274818\n\n\n352\n1473-2014-paddy_rice.png\n0.407526\n\n\n0\n20-2013-paddy_rice.png\n0.317439\n\n\n355\n1477-2014-paddy_rice.png\n0.337330\n\n\n424\n2033-2018-buckwheat.png\n0.806339\n\n\n\n\n127 rows × 2 columns\n\n\n\n\nlearn.predict('/Users/franckalbinet/pro/dev/uhina/_data/fk-jumpei-tfm/im/859-2014-paddy_rice.png')\n\n\n\n\n\n\n\n\n((0.5223042368888855,), tensor([0.5223]), tensor([0.5223]))\n\n\n\ndef predict_with_tta_histogram(learn, img_path, n_tta=30):\n    # Load the image\n    img = PILImage.create(img_path)\n    \n    # Create a test DataLoader with a single image\n    test_dl = learn.dls.test_dl([img])\n    \n    # Collect predictions\n    all_preds = []\n    for _ in range(n_tta):\n        # Get prediction with TTA (n=1 for a single augmentation each time)\n        preds, _ = learn.tta(dl=test_dl, n=1)\n        all_preds.append(preds[0][0].item())  # Assuming single output\n    \n    all_preds = np.array(all_preds)\n    \n    # Calculate statistics\n    mean_pred = np.mean(all_preds)\n    std_pred = np.std(all_preds)\n    median_pred = np.median(all_preds)\n    min_pred = np.min(all_preds)\n    max_pred = np.max(all_preds)\n    \n    return mean_pred, std_pred, median_pred, min_pred, max_pred, all_preds\n\n\n# Use the function\nfname = '859-2014-paddy_rice.png'\nimg_path = Path('/Users/franckalbinet/pro/dev/uhina/_data/fk-jumpei-tfm/im/') / fname\nmean, std, median, min_pred, max_pred, all_preds = predict_with_tta_histogram(learn, img_path, n_tta=30)\n\nprint(f\"Min prediction: {min_pred:.4f}\")\nprint(f\"Max prediction: {max_pred:.4f}\")\nprint(f\"Mean prediction: {mean:.4f}\")\nprint(f\"Standard deviation: {std:.4f}\")\nprint(f\"Median prediction: {median:.4f}\")\nprint(f\"All predictions: {all_preds}\")\n\n# If you want to compare with the ground truth\nprint('Ground truth:', df[df.fname == fname][df.columns[idx]].values[0])\n\n# Plot histogram\nplt.hist(all_preds, bins=10)\nplt.title('Histogram of TTA Predictions')\nplt.xlabel('Predicted Value')\nplt.ylabel('Frequency')\nplt.show()\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\nMin prediction: 0.4531\nMax prediction: 0.5795\nMean prediction: 0.5275\nStandard deviation: 0.0282\nMedian prediction: 0.5272\nAll predictions: [0.54436386 0.55598998 0.56092638 0.57104981 0.52798319 0.57950228\n 0.50701064 0.52194297 0.51890564 0.53010362 0.50141889 0.53311121\n 0.51312613 0.53879243 0.50901508 0.51508129 0.54903734 0.51155448\n 0.53831923 0.50822324 0.52851534 0.57572448 0.51641762 0.51522946\n 0.45307761 0.52632904 0.53577548 0.56359959 0.51006508 0.46458086]\nGround truth: 0.5396292928049117\n\n\n\n\n\n\n\n\n\n\n# Canonical fine-tuning\n# from fastai.vision.all import *\n\n# # Load the pretrained model\n# learn = load_learner('./models/650-4000-epoch-25-lr-3e-3.pkl', cpu=False)\n\n# # Prepare your new data\n# path = 'path/to/your/data'\n# dls = ImageDataLoaders.from_folder(path, valid_pct=0.2, item_tfms=Resize(224), batch_tfms=aug_transforms())\n\n# # Set the new data\n# learn.dls = dls\n\n# # Fine-tune the head of the model\n# learn.freeze()\n# # alternatively: learn.freeze_to(n)\n# learn.lr_find()\n# learn.fit_one_cycle(5, 3e-3)\n\n# # Fine-tune the entire model\n# learn.unfreeze()\n# learn.lr_find()\n# learn.fit_one_cycle(5, slice(1e-5, 1e-3))\n\n\n# learn = vision_learner(dls, resnet18, pretrained=False, metrics=R2Score()).to_fp16()\n\n\n# learn.lr_find()\n\n\n# learn.lr_find()\n\n\n\n\n\n\n\n\nSuggestedLRs(valley=0.002511886414140463)\n\n\n\n\n\n\n\n\n\n\n# learn.fit_one_cycle(5, 3e-3)",
    "crumbs": [
      "example",
      "Ringtrial classic"
    ]
  },
  {
    "objectID": "example/ringtrial-classic.html#evaluation",
    "href": "example/ringtrial-classic.html#evaluation",
    "title": "Ringtrial classic",
    "section": "Evaluation",
    "text": "Evaluation\n\n# Convert predictions and targets to numpy arrays\ndef assess_model(val_preds, val_targets):\n    val_preds = val_preds.numpy().flatten()\n    val_targets = val_targets.numpy()\n\n    # Create a DataFrame with the results\n    results_df = pd.DataFrame({\n        'Predicted': val_preds,\n        'Actual': val_targets\n    })\n\n    # Display the first few rows of the results\n    print(results_df.head())\n\n    # Calculate and print the R2 score\n    from sklearn.metrics import r2_score\n    r2 = r2_score(val_targets, val_preds)\n    print(f\"R2 Score on validation set: {r2:.4f}\")\n\n\ndls.train.n\n\n69\n\n\n\nval_preds, val_targets = learn.get_preds(dl=dls.train)\nassess_model(val_preds, val_targets)\n\n\n\n\n\n\n\n\n   Predicted    Actual\n0   0.046272  0.210804\n1   0.528189  0.976900\n2   0.465372  0.469860\n3   0.258100  0.338556\n4   0.112802  0.147696\nR2 Score on validation set: 0.7392\n\n\n\nval_preds, val_targets = learn.get_preds(dl=dls.train)\nr2 = r2_score(val_targets, val_preds); r2\n\n\nr2 = r2_score(val_targets, val_preds); r2\n\n0.7391959435205914\n\n\n\nscores = []\nfor n in range(1, 20):\n    val_preds, val_targets = learn.tta(dl=dls.train, n=n)\n    scores.append(r2_score(val_targets, val_preds))\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\nx = list(range(1, 20))\nplt.plot(x, scores)\n\n\n\n\n\n\n\n\n\n# EXAMPLE of TTA on single item\n# from fastai.vision.all import *\n\n# # Define your TTA transforms\n# tta_tfms = [\n#     RandomResizedCrop(224, min_scale=0.5),\n#     Flip(),\n#     Rotate(degrees=(-15, 15)),\n#     Brightness(max_lighting=0.2),\n#     Contrast(max_lighting=0.2)\n# ]\n\n# # Create a pipeline of TTA transformations\n# tta_pipeline = Pipeline(tta_tfms)\n\n# # Load your model\n# learn = load_learner('path/to/your/model.pkl')\n\n# # Define the input data (e.g., an image)\n# input_data = PILImage.create('path/to/your/image.jpg')\n\n# # Apply TTA transforms to the input data and make predictions\n# predictions = []\n# for _ in range(5):  # Apply 5 different augmentations\n#     augmented_data = tta_pipeline(input_data)\n#     prediction = learn.predict(augmented_data)\n#     predictions.append(prediction)\n\n# # Average the predictions\n# average_prediction = sum(predictions) / len(predictions)\n\n# print(average_prediction)\n\n\n# Assuming you have a new CSV file for your test data\n# test_source = '../../_data/ossl-tfm/ossl-tfm-test.csv'\n# test_df = pd.read_csv(test_source)\n\n# # Create a new DataLoader for the test data\n# test_dl = learn.dls.test_dl(test_df)\n\n# # Get predictions on the test set\n# test_preds, test_targets = learn.get_preds(dl=test_dl)\n\n# # Now you can use test_preds and test_targets for further analysis\n\n\nassess_model(val_preds, val_targets)\n\n   Predicted    Actual\n0   0.312483  0.000000\n1   0.126990  0.184960\n2   0.365726  0.194201\n3   0.239089  0.262364\n4   0.402980  0.355799\nR2 Score on validation set: 0.8325\n\n\n\nassess_model(val_preds_tta, val_targets_tta)\n\n   Predicted    Actual\n0   0.246857  0.000000\n1   0.148590  0.184960\n2   0.371643  0.194201\n3   0.226535  0.262364\n4   0.407333  0.355799\nR2 Score on validation set: 0.8378\n\n\n\nval_preds_np = val_preds\nval_targets_np = val_targets\n\n# Apply the transformation: exp(y) - 1\nval_preds_transformed = np.exp(val_preds_np) - 1\nval_targets_transformed = np.exp(val_targets_np) - 1\n\n# Create a DataFrame with the results\nresults_df = pd.DataFrame({\n    'Predicted': val_preds_transformed,\n    'Actual': val_targets_transformed\n})\n\n# Display the first few rows of the results\nprint(results_df.head())\n\n# Calculate and print the R2 score\nfrom sklearn.metrics import r2_score\nr2 = r2_score(val_targets_transformed, val_preds_transformed)\nprint(f\"R2 Score on validation set (after transformation): {r2:.4f}\")\n\n# Calculate and print the MAPE, handling zero values\ndef mean_absolute_percentage_error(y_true, y_pred):\n    non_zero = (y_true != 0)\n    return np.mean(np.abs((y_true[non_zero] - y_pred[non_zero]) / y_true[non_zero])) * 100\n\nmape = mean_absolute_percentage_error(val_targets_transformed, val_preds_transformed)\nprint(f\"Mean Absolute Percentage Error (MAPE) on validation set: {mape:.2f}%\")\n\n# Calculate and print the MAE as an alternative metric\nfrom sklearn.metrics import mean_absolute_error\nmae = mean_absolute_error(val_targets_transformed, val_preds_transformed)\nprint(f\"Mean Absolute Error (MAE) on validation set: {mae:.4f}\")\n\n   Predicted   Actual\n0   0.366814  0.00000\n1   0.135405  0.20317\n2   0.441560  0.21434\n3   0.270092  0.30000\n4   0.496277  0.42732\nR2 Score on validation set (after transformation): 0.6936\nMean Absolute Percentage Error (MAPE) on validation set: 50.72%\nMean Absolute Error (MAE) on validation set: 0.1956\n\n\n\nplt.figure(figsize=(6, 6))\n\n# Use logarithmic bins for the colormap\nh = plt.hexbin(val_targets, val_preds, gridsize=65, \n               bins='log', cmap='Spectral_r', mincnt=1,\n               alpha=0.9)\n\n# Get the actual min and max counts from the hexbin data\ncounts = h.get_array()\nmin_count = counts[counts &gt; 0].min()  # Minimum non-zero count\nmax_count = counts.max()\n\n# Create a logarithmic colorbar\ncb = plt.colorbar(h, label='Count in bin', shrink=0.73)\ntick_locations = np.logspace(np.log10(min_count), np.log10(max_count), 5)\ncb.set_ticks(tick_locations)\ncb.set_ticklabels([f'{int(x)}' for x in tick_locations])\n\n# Add the diagonal line\nmin_val = min(val_targets.min(), val_preds.min())\nmax_val = max(val_targets.max(), val_preds.max())\nplt.plot([min_val, max_val], [min_val, max_val], 'k--', lw=1)\n\n# Set labels and title\nplt.xlabel('Actual Values')\nplt.ylabel('Predicted Values')\nplt.title('Predicted vs Actual Values (Hexbin with Log Scale)')\n\n# Add grid lines\nplt.grid(True, linestyle='--', alpha=0.65)\n\n# Set the same limits for both axes\nplt.xlim(min_val, max_val)\nplt.ylim(min_val, max_val)\n\n# Make the plot square\nplt.gca().set_aspect('equal', adjustable='box')\n\nplt.tight_layout()\nplt.show()\n\n# Print the range of counts in the hexbins\nprint(f\"Min non-zero count in hexbins: {min_count}\")\nprint(f\"Max count in hexbins: {max_count}\")\n\n\n\n\n\n\n\n\nMin non-zero count in hexbins: 1.0\nMax count in hexbins: 157.0\n\n\n\npath_model = Path('./models')\nlearn.export(path_model / '0.pkl')",
    "crumbs": [
      "example",
      "Ringtrial classic"
    ]
  },
  {
    "objectID": "example/ringtrial-classic.html#inference",
    "href": "example/ringtrial-classic.html#inference",
    "title": "Ringtrial classic",
    "section": "Inference",
    "text": "Inference\n\nossl_source = Path('../../_data/ossl-tfm/img')\nlearn.predict(ossl_source / '0a0a0c647671fd3030cc13ba5432eb88.png')\n\n\n\n\n\n\n\n\n((0.5229991674423218,), tensor([0.5230]), tensor([0.5230]))\n\n\n\ndf[df['fname'] == '0a0a0c647671fd3030cc13ba5432eb88.png']\n\n\n\n\n\n\n\n\nfname\nkex\n\n\n\n\n28867\n0a0a0c647671fd3030cc13ba5432eb88.png\n0.525379",
    "crumbs": [
      "example",
      "Ringtrial classic"
    ]
  },
  {
    "objectID": "example/ossl-vs-ringtrial-eda.html",
    "href": "example/ossl-vs-ringtrial-eda.html",
    "title": "OSSL vs Ringtrial",
    "section": "",
    "text": "import pandas as pd\nfrom pathlib import Path\n\nfrom sklearn.metrics import r2_score\nfrom uhina.loading import LoaderFactory, plot_spectra\nfrom uhina.preprocessing import TakeDerivative, SNV\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.decomposition import PCA, KernelPCA\nfrom sklearn.preprocessing import StandardScaler\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\npd.set_option('display.max_rows', 100)\n\nimport plotly\nimport plotly.express as px\nimport numpy as np\nfrom astartes import train_val_test_split",
    "crumbs": [
      "example",
      "OSSL vs Ringtrial"
    ]
  },
  {
    "objectID": "example/ossl-vs-ringtrial-eda.html#loading-data",
    "href": "example/ossl-vs-ringtrial-eda.html#loading-data",
    "title": "OSSL vs Ringtrial",
    "section": "Loading data",
    "text": "Loading data\n\nsrc = Path.home() / 'pro/data/woodwell-ringtrial/drive-download-20231013T123706Z-001'\nloader = LoaderFactory.get_loader(src, 'ringtrial')\ndata_rt = loader.load_data(analytes='potassium_cmolkg')\ndata_rt.ds = np.array([s.split('-rt')[0] for s in data_rt.sample_indices])\nprint(f'X shape: {data_rt.X.shape}')\n\nplot_spectra(data_rt, n_spectra=100, snv=True, alpha=0.2, figsize=(12, 3));\n\nX shape: (1400, 1676)\n\n\n\n\n\n\n\n\n\n\nsrc = Path.home() / '.lssm/data/ossl/ossl_all_L0_v1.2.csv.gz'\nloader = LoaderFactory.get_loader(src, 'ossl', spectra_type='mir')\ndata_ossl = loader.load_data(analytes='k.ext_usda.a725_cmolc.kg')\nprint(f'X shape: {data_ossl.X.shape}')\n\nLoading data from /Users/franckalbinet/.lssm/data/ossl/ossl_all_L0_v1.2.csv.gz ...\nX shape: (57674, 1676)\n\n\n\nplot_spectra(data_ossl, n_spectra=100, snv=True, alpha=0.2, figsize=(12, 3))\n\n(&lt;Figure size 1200x300 with 1 Axes&gt;,\n &lt;Axes: xlabel='Wavenumber ($cm^{-1}$)', ylabel='Absorbance'&gt;)\n\n\n\n\n\n\n\n\n\n\ndef pca_rt_ossl(data_rt, data_ossl):\n    # Combine the spectra from both datasets\n    X_combined = np.vstack((data_rt.X, data_ossl.X))\n    \n    # Create the pipeline\n    pipe = Pipeline([\n        ('SNV', SNV()),\n        ('Derivative', TakeDerivative()),\n        ('Scaler', StandardScaler()),  \n        ('PCA', PCA(n_components=3))\n    ])\n\n    # Fit and transform the combined data\n    X_pca_combined = pipe.fit_transform(X_combined)\n    \n    # Split the results back into rt and ossl\n    data_rt.X_pca = X_pca_combined[:data_rt.X.shape[0]]\n    data_ossl.X_pca = X_pca_combined[data_rt.X.shape[0]:]\n    \n    return data_rt, data_ossl\n\n\ndata_rt, data_ossl = pca_rt_ossl(data_rt, data_ossl)\n\n\nfrom matplotlib import pyplot as plt\nplt.scatter(data_ossl.X_pca[:, 0], data_ossl.X_pca[:, 1], s=5, alpha=0.1)\n\n\n\n\n\n\n\n\n\nn_samples = 100\nidx = np.random.choice(data_ossl.X_pca.shape[0], \n                       size=n_samples, replace=False)\n\nX_ossl_subset = data_ossl.X_pca[idx]\n\n\nlut_ossl_ds = {i: ds for i, ds in enumerate(data_ossl.dataset_labels)}\n\n\ndata_ossl.dataset_names\n\narray([0, 0, 0, ..., 3, 3, 3])\n\n\n\nnp.vectorize(lut_ossl_ds.get)(data_ossl.dataset_names)\n\narray(['GARRETT.SSL', 'GARRETT.SSL', 'GARRETT.SSL', ...,\n       'LUCAS.WOODWELL.SSL', 'LUCAS.WOODWELL.SSL', 'LUCAS.WOODWELL.SSL'],\n      dtype='&lt;U18')\n\n\n\ndata_rt.X_pca\n\narray([[-37.57209416,  10.0194439 ,   1.41901894],\n       [ 24.05922823,  10.83135662,  12.43538485],\n       [  8.09090194, -26.63507173,   7.36763935],\n       ...,\n       [  8.44862862,  -4.47373073,   2.51161567],\n       [ 15.9657049 ,   8.60238863, -19.86332133],\n       [  2.45832757,   6.53856188,   3.22457499]])\n\n\n\nmask_rt_ds = data_rt.ds == 'kssl'\n\n\ndata_ossl.X_pca\n\narray([[  2.45822505,  16.4823169 ,   9.00422903],\n       [ -2.36297831,  10.87565108,   7.6014877 ],\n       [ -4.66533181,  11.81300838,   7.77196598],\n       ...,\n       [ 33.2311886 ,  -6.53547903,   8.0031913 ],\n       [  8.18561655,  24.05135848,  14.03594385],\n       [-11.41377595,   8.67332126,  -6.78131327]])\n\n\n\ndef data_to_df(data_ossl, data_rt, \n               n_samples_ossl=100, rt_ds='kssl',\n               cols=['PC1', 'PC2', 'PC3']):\n    lut_ossl_ds = {i: ds for i, ds in enumerate(data_ossl.dataset_labels)}\n    idx = np.random.choice(data_ossl.X_pca.shape[0], size=n_samples_ossl, replace=False)\n    X_ossl_subset = data_ossl.X_pca[idx,:]\n    ds_ossl = np.vectorize(lut_ossl_ds.get)(data_ossl.dataset_names[idx])\n    \n    df_ossl = pd.DataFrame(X_ossl_subset, columns=cols)\n    df_ossl['ds'] = ds_ossl\n    # return df_ossl\n    \n    mask = data_rt.ds == rt_ds\n    \n    X_rt = data_rt.X_pca[mask]\n    df_rt = pd.DataFrame(X_rt, columns=cols)\n    df_rt['ds'] = rt_ds + '-rt'\n    # df_rt = pd.DataFrame(np.c_[X_rt, np.full(np.sum(mask), rt_ds + '-rt')], columns=cols)\n    \n    return pd.concat([df_ossl, df_rt], axis=0, ignore_index=True)\n\n\ndf = data_to_df(data_ossl, data_rt, n_samples_ossl=200)\n\n\ndef plot_scatter3d(df, size_dict=None, default_opacity=0.7):\n    \"\"\"\n    Generates a nicely formatted 3D scatter plot of the data with different symbols, colors, and sizes for each dataset.\n\n    Args:\n        df (pd.DataFrame): DataFrame containing the data with columns 'PC1', 'PC2', 'PC3', 'ds'\n        size_dict (dict, optional): Dictionary mapping dataset names to dot sizes. Defaults to None.\n        default_opacity (float, optional): Default opacity for all points. Defaults to 0.7.\n    \"\"\"\n    # Default size\n    default_size = 20\n\n    # If size_dict is not provided, initialize it with default values\n    if size_dict is None:\n        size_dict = {}\n\n    # Create dot_size column based on the ds column, using defaults if not in dict\n    df['dot_size'] = df['ds'].map(lambda x: size_dict.get(x, default_size))\n\n    fig = px.scatter_3d(\n        df,\n        x='PC1',\n        y='PC2',\n        z='PC3',\n        color='ds',\n        symbol='ds',\n        size='dot_size',\n        opacity=default_opacity,\n        hover_data=['ds'],\n        color_discrete_sequence=px.colors.qualitative.Set1,\n    )\n\n    fig.update_traces(marker=dict(line=dict(width=0)))\n\n    fig.update_layout(\n        scene=dict(\n            xaxis_title='PC1',\n            yaxis_title='PC2',\n            zaxis_title='PC3'\n        ),\n        legend_title='Dataset',\n        height=800,\n        width=1000,\n    )\n\n    fig.show()\n\n\ndata_ossl.dataset_labels\n\narray(['GARRETT.SSL', 'ICRAF.ISRIC', 'KSSL.SSL', 'LUCAS.WOODWELL.SSL'],\n      dtype=object)\n\n\n\nnp.unique(data_rt.ds)\n\narray(['agrocares', 'argonne', 'csu-il', 'eth-alpha-1', 'eth-alpha-2',\n       'eth-vertex', 'iaea-aug2022', 'kssl', 'landcare', 'lesotho', 'msu',\n       'osu', 'rothamsted', 'scion', 'ughent', 'uiuc', 'usp',\n       'uwisc-fine', 'woodwell-alpha', 'woodwell-vertex'], dtype='&lt;U15')\n\n\n\nsize_dict = {\n    'KSSL.SSL': 1,\n    'GARRETT.SSL': 3,\n    'ICRAF.ISRIC': 3,\n    'LUCAS.WOODWELL.SSL': 3,\n    \n}\n\nplot_scatter3d(\n    data_to_df(data_ossl, data_rt, n_samples_ossl=5000,  rt_ds='iaea-aug2022'), \n    size_dict=size_dict)\n\nUnable to display output for mime type(s): application/vnd.plotly.v1+json",
    "crumbs": [
      "example",
      "OSSL vs Ringtrial"
    ]
  },
  {
    "objectID": "example/fk-jumpei-transfer-learning.html",
    "href": "example/fk-jumpei-transfer-learning.html",
    "title": "Fukushima Jumpei transfer learning",
    "section": "",
    "text": "The autoreload extension is already loaded. To reload it, use:\n  %reload_ext autoreload\nimport pandas as pd\nfrom pathlib import Path\nimport fastcore.all as fc\n\nfrom fastai.data.all import *\nfrom fastai.vision.all import *\nfrom multiprocessing import cpu_count\nfrom sklearn.metrics import r2_score\nfrom uhina.augment import Quantize\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\npd.set_option('display.max_rows', 100)",
    "crumbs": [
      "example",
      "Fukushima Jumpei transfer learning"
    ]
  },
  {
    "objectID": "example/fk-jumpei-transfer-learning.html#loading-data",
    "href": "example/fk-jumpei-transfer-learning.html#loading-data",
    "title": "Fukushima Jumpei transfer learning",
    "section": "Loading data",
    "text": "Loading data\n\nsrc = '../../_data/fk-jumpei-tfm/im-targets-lut.csv'\ndf = pd.read_csv(src)\nprint(f'{df.shape[0]} samples')\ndf.head()\n\n635 samples\n\n\n\n\n\n\n\n\n\nfname\nsoil_total_Cs134\nsoil_total_Cs137\nsoil_ex_Cs137\nexCs137_totalCs137\nsoil_water_soluble_K2O\nsoil_ex_K2O\nTF_plant_totalCs137\nTF_plant_exCs137\nsoil_pH\n...\nsoil_CN_ratio\nsoil_CEC\nsoil_MgO\nsoil_CaO\nsoil_P_absorption_coefficient\navaiable_Pi\ncourse_sand\nfine_sand\nsilt\nclay\n\n\n\n\n0\n20-2013-paddy_rice.png\nNaN\n610.0\n70.6\n0.116\nNaN\n17.6\nNaN\nNaN\n6.0\n...\n12.0\n29.5\n64.1\n339.0\n1700.0\nNaN\n17.1\n34.1\n25.6\n23.2\n\n\n1\n28-2014-paddy_rice.png\nNaN\n273.5\n27.8\n0.102\nNaN\n62.1\nNaN\nNaN\n5.0\n...\n12.0\n19.6\n30.3\n217.0\n660.0\n12.2\nNaN\nNaN\nNaN\nNaN\n\n\n2\n33-2014-paddy_rice.png\nNaN\n28.1\n3.6\n0.127\nNaN\n22.3\nNaN\nNaN\n6.0\n...\n12.0\n13.8\n38.1\n96.1\n640.0\n6.8\nNaN\nNaN\nNaN\nNaN\n\n\n3\n35-2014-paddy_rice.png\nNaN\n897.8\n71.4\n0.080\nNaN\n33.6\nNaN\nNaN\n5.0\n...\n12.0\n15.4\n16.2\n119.0\n640.0\n34.2\nNaN\nNaN\nNaN\nNaN\n\n\n4\n36-2014-paddy_rice.png\nNaN\n964.3\n90.6\n0.094\nNaN\n57.0\nNaN\nNaN\n5.0\n...\n12.0\n17.7\n19.9\n151.0\n610.0\n40.0\nNaN\nNaN\nNaN\nNaN\n\n\n\n\n5 rows × 22 columns\n\n\n\n\ndef mg_100g_to_cmol_kg(x, log_tfm=False, atom_weight=39.1):\n    x_mg_kg = x * 10 \n    x_mg_kg_K = 0.83 * x_mg_kg\n    x_cmol_kg_K = x_mg_kg_K / (atom_weight*10)\n    return np.log1p(x_cmol_kg_K) if log_tfm else x_cmol_kg_K\n\n\nmg_100g_to_cmol_kg(df['soil_ex_K2O'], log_tfm=True).hist()\n\n\n\n\n\n\n\n\n\nprint('Before:', df.shape)\ndf.dropna(inplace=True, subset=['soil_ex_K2O'])\nprint('After:', df.shape)\n\nBefore: (635, 22)\nAfter: (634, 22)\n\n\n\ndf['soil_ex_K2O'] = df['soil_ex_K2O'].apply(lambda x: mg_100g_to_cmol_kg(x, log_tfm=True))\n df.soil_ex_K2O.hist()\n\n\n\n\n\n\n\n\n\nfor i, col in enumerate(df.columns):\n    print(f'{i}: {col}')\n\n0: fname\n1: soil_total_Cs134\n2: soil_total_Cs137\n3: soil_ex_Cs137\n4: exCs137_totalCs137\n5: soil_water_soluble_K2O\n6: soil_ex_K2O\n7: TF_plant_totalCs137\n8: TF_plant_exCs137\n9: soil_pH\n10: soil_C\n11: soil_N\n12: soil_CN_ratio\n13: soil_CEC\n14: soil_MgO\n15: soil_CaO\n16: soil_P_absorption_coefficient\n17: avaiable_Pi\n18: course_sand\n19: fine_sand\n20: silt\n21: clay",
    "crumbs": [
      "example",
      "Fukushima Jumpei transfer learning"
    ]
  },
  {
    "objectID": "example/fk-jumpei-transfer-learning.html#fine-tuning",
    "href": "example/fk-jumpei-transfer-learning.html#fine-tuning",
    "title": "Fukushima Jumpei transfer learning",
    "section": "Fine-tuning",
    "text": "Fine-tuning\n\nclass OrderedQuantize(Quantize):\n    order = 0  # Apply first\n\nclass OrderedRatioResize(RatioResize):\n    order = 1  # Apply second\n\n\ndef stratified_split(df, target, valid_size=0.2, test_size=0.2, num_bins=2, seed=41):\n    from sklearn.model_selection import train_test_split\n    df = df.copy()\n    df.reset_index(inplace=True, drop=True)\n    train_df, test_df = train_test_split(df, test_size=test_size, \n                                        stratify=pd.qcut(df[target], q=num_bins, labels=False), \n                                        random_state=seed)\n\n    train_df, valid_df = train_test_split(train_df, test_size=valid_size, \n                                        stratify=pd.qcut(train_df[target], q=num_bins, labels=False), \n                                        random_state=seed)\n    \n    return train_df, train_df.index, valid_df, valid_df.index, test_df, test_df.index\n\n\n# from sklearn.model_selection import StratifiedShuffleSplit\n\n# def stratified_split(df, target_col, n_bins=2, n_splits=2, test_size=0.2, random_state=42):\n#     # Create bins for the target values\n#     df_copy = df.copy()\n#     df_copy['target_bin'] = pd.cut(df_copy[target_col], bins=n_bins, labels=False)\n    \n#     # Create a StratifiedShuffleSplit object\n#     sss = StratifiedShuffleSplit(n_splits=n_splits, test_size=test_size, random_state=random_state)\n    \n#     # Get the indices for the splits\n#     splits = list(sss.split(df_copy, df_copy['target_bin']))\n    \n#     # Remove the temporary 'target_bin' column\n#     df_copy.drop('target_bin', axis=1, inplace=True)\n    \n#     return splits\n\n\ndf.head()\n\n\n\n\n\n\n\n\nfname\nsoil_total_Cs134\nsoil_total_Cs137\nsoil_ex_Cs137\nexCs137_totalCs137\nsoil_water_soluble_K2O\nsoil_ex_K2O\nTF_plant_totalCs137\nTF_plant_exCs137\nsoil_pH\n...\nsoil_CN_ratio\nsoil_CEC\nsoil_MgO\nsoil_CaO\nsoil_P_absorption_coefficient\navaiable_Pi\ncourse_sand\nfine_sand\nsilt\nclay\n\n\n\n\n0\n20-2013-paddy_rice.png\nNaN\n610.0\n70.6\n0.116\nNaN\n0.317439\nNaN\nNaN\n6.0\n...\n12.0\n29.5\n64.1\n339.0\n1700.0\nNaN\n17.1\n34.1\n25.6\n23.2\n\n\n1\n28-2014-paddy_rice.png\nNaN\n273.5\n27.8\n0.102\nNaN\n0.840806\nNaN\nNaN\n5.0\n...\n12.0\n19.6\n30.3\n217.0\n660.0\n12.2\nNaN\nNaN\nNaN\nNaN\n\n\n2\n33-2014-paddy_rice.png\nNaN\n28.1\n3.6\n0.127\nNaN\n0.387556\nNaN\nNaN\n6.0\n...\n12.0\n13.8\n38.1\n96.1\n640.0\n6.8\nNaN\nNaN\nNaN\nNaN\n\n\n3\n35-2014-paddy_rice.png\nNaN\n897.8\n71.4\n0.080\nNaN\n0.538391\nNaN\nNaN\n5.0\n...\n12.0\n15.4\n16.2\n119.0\n640.0\n34.2\nNaN\nNaN\nNaN\nNaN\n\n\n4\n36-2014-paddy_rice.png\nNaN\n964.3\n90.6\n0.094\nNaN\n0.792981\nNaN\nNaN\n5.0\n...\n12.0\n17.7\n19.9\n151.0\n610.0\n40.0\nNaN\nNaN\nNaN\nNaN\n\n\n\n\n5 rows × 22 columns\n\n\n\n\nidx = 6\ndf.columns[idx]\n\n'soil_ex_K2O'\n\n\n\ndata = stratified_split(df,  df.columns[idx], valid_size=0.2, test_size=0.2, num_bins=2)\ntrain_df, train_idx, valid_df, valid_idx, test_df, test_idx = data\n\n\n# # Usage example:\n# splits = stratified_split(df, df.columns[idx], n_bins=4, n_splits=2, random_state=41)\n\n# # For train-validation split\n# train_idx, valid_idx = splits[0]\n\n# # For train-test split (if needed)\n# train_valid_idx, test_idx = splits[1]\n\n# # Create DataFrames\n# train_df = df.iloc[train_idx]\n# valid_df = df.iloc[valid_idx]\n# test_df = df.iloc[test_idx]\n\n\nlen(train_df), len(valid_df), len(test_df)\n\n(405, 102, 127)\n\n\n\ntest_df[['fname', df.columns[idx]]]\n\n\n\n\n\n\n\n\nfname\nsoil_ex_K2O\n\n\n\n\n195\n758-2014-soybean.png\n0.973526\n\n\n77\n166-2016-paddy_rice.png\n0.571297\n\n\n224\n888-2014-paddy_rice.png\n0.329727\n\n\n580\n2391-2020-paddy_rice.png\n0.519631\n\n\n10\n51-2015-paddy_rice.png\n0.204683\n\n\n...\n...\n...\n\n\n520\n2131-2018-paddy_rice.png\n0.473116\n\n\n321\n1352-2014-paddy_rice.png\n0.739718\n\n\n226\n908-2014-paddy_rice.png\n0.202951\n\n\n137\n250-2017-paddy_rice.png\n0.095101\n\n\n378\n1988-2018-paddy_rice.png\n0.089294\n\n\n\n\n127 rows × 2 columns\n\n\n\n\ntrain_df['soil_ex_K2O'].hist()\n\n\n\n\n\n\n\n\n\nvalid_df['soil_ex_K2O'].hist()\n\n\n\n\n\n\n\n\n\ntest_df['soil_ex_K2O'].hist()\n\n\n\n\n\n\n\n\n\ndef stratified_splitter(items):\n    return [train_idx, valid_idx]\n\n\nlen(train_idx), len(valid_idx), len(test_idx)\n\n(405, 102, 127)\n\n\n\ndblock = DataBlock(\n    blocks=(ImageBlock, RegressionBlock),\n    get_x=ColReader(0, pref='../../_data/fk-jumpei-tfm/im/'),\n    get_y=ColReader(6),\n    splitter=stratified_splitter,\n    item_tfms=[OrderedQuantize(n_valid=len(valid_idx))],\n    batch_tfms=[\n        OrderedRatioResize(224),\n        Normalize.from_stats(*imagenet_stats)\n    ]\n)\n\n\n# dblock = DataBlock(blocks=(ImageBlock, RegressionBlock),\n#                    get_x=ColReader(0, pref='../../_data/fk-jumpei-tfm/im/'),\n#                    get_y=ColReader(idx),\n#                    splitter=stratified_splitter,\n#                    batch_tfms=[RatioResize(224)],\n#                    item_tfms=[Quantize(n_valid=len(valid_idx))])\n\n# # dblock.summary(df)\n\n\ndls = dblock.dataloaders(df, bs=16)\n\n\ndls.train.n, dls.valid.n\n\n(405, 102)\n\n\n\ndls.show_batch(nrows=6, ncols=2, figsize=(12, 13))\n\n\n\n\n\n\n\n\n\n# learn = load_learner('./models/650-4000-epoch-25-lr-3e-3.pkl', cpu=True)\nlearn = load_learner('./models/unfrozen-epoch-30-lr-1.5e-3-12102024.pkl', cpu=True)\n# learn = load_learner('./models/frozen-epoch-30-lr-1.5e-3-12102024.pkl', cpu=True)\n\n\nlearn.dls = dls\n\n\n# learn.summary()\n\n\nlearn.freeze()\n\n\n# learn.model[-1][-1]\n\n\n# model = learn.model\n# last_layer = model[-1][-1]\n# new_layer = nn.Linear(in_features=last_layer.in_features, \n#                       out_features=last_layer.out_features, \n#                       bias=True)\n# new_layer.weight.data = last_layer.weight.data\n# if hasattr(last_layer, 'bias') and last_layer.bias is not None:\n#     new_layer.bias.data = last_layer.bias.data\n# learn.model[-1][-1] = new_layer\n\n\n# learn.model[-1][-1]\n\n\nlearn.lr_find()\n\n\n\n\n\n\n    \n      \n      0.00% [0/5 00:00&lt;?]\n    \n    \n\n\n    \n      \n      0.00% [0/25 00:00&lt;?]\n    \n    \n\n\nSuggestedLRs(valley=0.0004786300996784121)\n\n\n\n\n\n\n\n\n\n\nlearn.fit_one_cycle(20, 1e-3)\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nr2_score\ntime\n\n\n\n\n0\n4.031535\n1.352721\n-23.596432\n00:16\n\n\n1\n3.784171\n1.538314\n-26.971052\n00:16\n\n\n2\n3.508733\n1.428865\n-24.980963\n00:16\n\n\n3\n3.396891\n1.600550\n-28.102680\n00:16\n\n\n4\n3.298875\n0.973944\n-16.709154\n00:16\n\n\n5\n3.040169\n0.889875\n-15.180531\n00:17\n\n\n6\n2.690931\n0.809856\n-13.725562\n00:17\n\n\n7\n2.377800\n0.696135\n-11.657766\n00:16\n\n\n8\n2.104720\n0.340535\n-5.191922\n00:16\n\n\n9\n1.807394\n0.360653\n-5.557731\n00:16\n\n\n10\n1.515663\n0.342427\n-5.226330\n00:16\n\n\n11\n1.358019\n0.400202\n-6.276837\n00:16\n\n\n12\n1.253106\n0.226004\n-3.109422\n00:16\n\n\n13\n1.118638\n0.233846\n-3.251998\n00:17\n\n\n14\n0.979438\n0.218567\n-2.974184\n00:17\n\n\n15\n0.913578\n0.212184\n-2.858124\n00:17\n\n\n16\n0.870852\n0.208475\n-2.790682\n00:17\n\n\n17\n0.825625\n0.205535\n-2.737223\n00:17\n\n\n18\n0.803334\n0.206433\n-2.753554\n00:17\n\n\n19\n0.792737\n0.200518\n-2.646005\n00:17\n\n\n\n\n\n\nval_preds, val_targets = learn.get_preds(dl=dls.valid)\nr2_score(val_targets, val_preds)\n\n\n\n\n\n\n\n\n0.23469541349548861\n\n\n\nlearn.unfreeze()\n\n\nlearn.lr_find()\n\n\n\n\n\n\n\n\nSuggestedLRs(valley=5.248074739938602e-05)\n\n\n\n\n\n\n\n\n\n\n# learn.fit_one_cycle(20, slice(1e-5, 1.5e-3))\nlearn.fit_one_cycle(20, 1.5e-3)\n\n\n\n\n\n\n    \n      \n      15.00% [3/20 01:05&lt;06:11]\n    \n    \n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nr2_score\ntime\n\n\n\n\n0\n0.043800\n0.053276\n0.031285\n00:22\n\n\n1\n0.046924\n0.054486\n0.009281\n00:21\n\n\n2\n0.051729\n0.184493\n-2.354623\n00:21\n\n\n\n\n\n    \n      \n      16.00% [4/25 00:03&lt;00:16 0.0514]\n    \n    \n\n\n\n---------------------------------------------------------------------------\nKeyboardInterrupt                         Traceback (most recent call last)\nCell In[183], line 2\n      1 # learn.fit_one_cycle(20, slice(1e-5, 1.5e-3))\n----&gt; 2 learn.fit_one_cycle(20, 1.5e-3)\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/fastai/callback/schedule.py:121, in fit_one_cycle(self, n_epoch, lr_max, div, div_final, pct_start, wd, moms, cbs, reset_opt, start_epoch)\n    118 lr_max = np.array([h['lr'] for h in self.opt.hypers])\n    119 scheds = {'lr': combined_cos(pct_start, lr_max/div, lr_max, lr_max/div_final),\n    120           'mom': combined_cos(pct_start, *(self.moms if moms is None else moms))}\n--&gt; 121 self.fit(n_epoch, cbs=ParamScheduler(scheds)+L(cbs), reset_opt=reset_opt, wd=wd, start_epoch=start_epoch)\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/fastai/learner.py:266, in Learner.fit(self, n_epoch, lr, wd, cbs, reset_opt, start_epoch)\n    264 self.opt.set_hypers(lr=self.lr if lr is None else lr)\n    265 self.n_epoch = n_epoch\n--&gt; 266 self._with_events(self._do_fit, 'fit', CancelFitException, self._end_cleanup)\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/fastai/learner.py:201, in Learner._with_events(self, f, event_type, ex, final)\n    200 def _with_events(self, f, event_type, ex, final=noop):\n--&gt; 201     try: self(f'before_{event_type}');  f()\n    202     except ex: self(f'after_cancel_{event_type}')\n    203     self(f'after_{event_type}');  final()\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/fastai/learner.py:255, in Learner._do_fit(self)\n    253 for epoch in range(self.n_epoch):\n    254     self.epoch=epoch\n--&gt; 255     self._with_events(self._do_epoch, 'epoch', CancelEpochException)\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/fastai/learner.py:201, in Learner._with_events(self, f, event_type, ex, final)\n    200 def _with_events(self, f, event_type, ex, final=noop):\n--&gt; 201     try: self(f'before_{event_type}');  f()\n    202     except ex: self(f'after_cancel_{event_type}')\n    203     self(f'after_{event_type}');  final()\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/fastai/learner.py:249, in Learner._do_epoch(self)\n    248 def _do_epoch(self):\n--&gt; 249     self._do_epoch_train()\n    250     self._do_epoch_validate()\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/fastai/learner.py:241, in Learner._do_epoch_train(self)\n    239 def _do_epoch_train(self):\n    240     self.dl = self.dls.train\n--&gt; 241     self._with_events(self.all_batches, 'train', CancelTrainException)\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/fastai/learner.py:201, in Learner._with_events(self, f, event_type, ex, final)\n    200 def _with_events(self, f, event_type, ex, final=noop):\n--&gt; 201     try: self(f'before_{event_type}');  f()\n    202     except ex: self(f'after_cancel_{event_type}')\n    203     self(f'after_{event_type}');  final()\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/fastai/learner.py:207, in Learner.all_batches(self)\n    205 def all_batches(self):\n    206     self.n_iter = len(self.dl)\n--&gt; 207     for o in enumerate(self.dl): self.one_batch(*o)\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/fastai/learner.py:237, in Learner.one_batch(self, i, b)\n    235 b = self._set_device(b)\n    236 self._split(b)\n--&gt; 237 self._with_events(self._do_one_batch, 'batch', CancelBatchException)\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/fastai/learner.py:203, in Learner._with_events(self, f, event_type, ex, final)\n    201 try: self(f'before_{event_type}');  f()\n    202 except ex: self(f'after_cancel_{event_type}')\n--&gt; 203 self(f'after_{event_type}');  final()\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/fastai/learner.py:174, in Learner.__call__(self, event_name)\n--&gt; 174 def __call__(self, event_name): L(event_name).map(self._call_one)\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/fastcore/foundation.py:159, in L.map(self, f, *args, **kwargs)\n--&gt; 159 def map(self, f, *args, **kwargs): return self._new(map_ex(self, f, *args, gen=False, **kwargs))\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/fastcore/basics.py:899, in map_ex(iterable, f, gen, *args, **kwargs)\n    897 res = map(g, iterable)\n    898 if gen: return res\n--&gt; 899 return list(res)\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/fastcore/basics.py:884, in bind.__call__(self, *args, **kwargs)\n    882     if isinstance(v,_Arg): kwargs[k] = args.pop(v.i)\n    883 fargs = [args[x.i] if isinstance(x, _Arg) else x for x in self.pargs] + args[self.maxi+1:]\n--&gt; 884 return self.func(*fargs, **kwargs)\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/fastai/learner.py:178, in Learner._call_one(self, event_name)\n    176 def _call_one(self, event_name):\n    177     if not hasattr(event, event_name): raise Exception(f'missing {event_name}')\n--&gt; 178     for cb in self.cbs.sorted('order'): cb(event_name)\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/fastai/callback/core.py:62, in Callback.__call__(self, event_name)\n     60 res = None\n     61 if self.run and _run: \n---&gt; 62     try: res = getcallable(self, event_name)()\n     63     except (CancelBatchException, CancelBackwardException, CancelEpochException, CancelFitException, CancelStepException, CancelTrainException, CancelValidException): raise\n     64     except Exception as e: raise modify_exception(e, f'Exception occured in `{self.__class__.__name__}` when calling event `{event_name}`:\\n\\t{e.args[0]}', replace=True)\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/fastai/learner.py:562, in Recorder.after_batch(self)\n    560 if len(self.yb) == 0: return\n    561 mets = self._train_mets if self.training else self._valid_mets\n--&gt; 562 for met in mets: met.accumulate(self.learn)\n    563 if not self.training: return\n    564 self.lrs.append(self.opt.hypers[-1]['lr'])\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/fastai/learner.py:511, in AvgSmoothLoss.accumulate(self, learn)\n    509 def accumulate(self, learn):\n    510     self.count += 1\n--&gt; 511     self.val = torch.lerp(to_detach(learn.loss.mean()), self.val, self.beta)\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/fastai/torch_core.py:246, in to_detach(b, cpu, gather)\n    244     if gather: x = maybe_gather(x)\n    245     return x.cpu() if cpu else x\n--&gt; 246 return apply(_inner, b, cpu=cpu, gather=gather)\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/fastai/torch_core.py:226, in apply(func, x, *args, **kwargs)\n    224 if is_listy(x): return type(x)([apply(func, o, *args, **kwargs) for o in x])\n    225 if isinstance(x,(dict,MutableMapping)): return {k: apply(func, v, *args, **kwargs) for k,v in x.items()}\n--&gt; 226 res = func(x, *args, **kwargs)\n    227 return res if x is None else retain_type(res, x)\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/fastai/torch_core.py:245, in to_detach.&lt;locals&gt;._inner(x, cpu, gather)\n    243 x = x.detach()\n    244 if gather: x = maybe_gather(x)\n--&gt; 245 return x.cpu() if cpu else x\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/fastai/torch_core.py:384, in TensorBase.__torch_function__(cls, func, types, args, kwargs)\n    382 if cls.debug and func.__name__ not in ('__str__','__repr__'): print(func, types, args, kwargs)\n    383 if _torch_handled(args, cls._opt, func): types = (torch.Tensor,)\n--&gt; 384 res = super().__torch_function__(func, types, args, ifnone(kwargs, {}))\n    385 dict_objs = _find_args(args) if args else _find_args(list(kwargs.values()))\n    386 if issubclass(type(res),TensorBase) and dict_objs: res.set_meta(dict_objs[0],as_copy=True)\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/torch/_tensor.py:1437, in Tensor.__torch_function__(cls, func, types, args, kwargs)\n   1434     return NotImplemented\n   1436 with _C.DisableTorchFunctionSubclass():\n-&gt; 1437     ret = func(*args, **kwargs)\n   1438     if func in get_default_nowrap_functions():\n   1439         return ret\n\nKeyboardInterrupt: \n\n\n\n\nval_preds, val_targets = learn.get_preds(dl=dls.valid)\nr2_score(val_targets, val_preds)\n\n\n\n\n\n\n\n\n0.36861295616974843\n\n\n\nEvaluate fine-tuned model\n\nlen(test_df)\n\n127\n\n\n\ndblock = DataBlock(blocks=(ImageBlock, RegressionBlock),\n                   get_x=ColReader(0, pref='../../_data/fk-jumpei-tfm/im/'),\n                   get_y=ColReader(idx),\n                   splitter=RandomSplitter(valid_pct=0, seed=41),\n                   batch_tfms=[RatioResize(224)],\n                   item_tfms=[Quantize(n_valid=len(test_df))])\n\ndls = dblock.dataloaders(test_df, bs=len(test_df))\n\n\nval_preds, val_targets = learn.get_preds(dl=dls.train)\n\n\n\n\n\n\n\n\n\nr2_score(val_targets, val_preds)\n\n-0.012676790057743803\n\n\n\nval_preds, val_targets = learn.tta(dl=dls.train, n=30)\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n---------------------------------------------------------------------------\nKeyboardInterrupt                         Traceback (most recent call last)\nCell In[120], line 1\n----&gt; 1 val_preds, val_targets = learn.tta(dl=dls.train, n=30)\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/fastai/learner.py:678, in tta(self, ds_idx, dl, n, item_tfms, batch_tfms, beta, use_max)\n    676     for i in self.progress.mbar if hasattr(self,'progress') else range(n):\n    677         self.epoch = i #To keep track of progress on mbar since the progress callback will use self.epoch\n--&gt; 678         aug_preds.append(self.get_preds(dl=dl, inner=True)[0][None])\n    679 aug_preds = torch.cat(aug_preds)\n    680 aug_preds = aug_preds.max(0)[0] if use_max else aug_preds.mean(0)\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/fastai/learner.py:310, in Learner.get_preds(self, ds_idx, dl, with_input, with_decoded, with_loss, act, inner, reorder, cbs, **kwargs)\n    308 if with_loss: ctx_mgrs.append(self.loss_not_reduced())\n    309 with ContextManagers(ctx_mgrs):\n--&gt; 310     self._do_epoch_validate(dl=dl)\n    311     if act is None: act = getcallable(self.loss_func, 'activation')\n    312     res = cb.all_tensors()\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/fastai/learner.py:246, in Learner._do_epoch_validate(self, ds_idx, dl)\n    244 if dl is None: dl = self.dls[ds_idx]\n    245 self.dl = dl\n--&gt; 246 with torch.no_grad(): self._with_events(self.all_batches, 'validate', CancelValidException)\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/fastai/learner.py:201, in Learner._with_events(self, f, event_type, ex, final)\n    200 def _with_events(self, f, event_type, ex, final=noop):\n--&gt; 201     try: self(f'before_{event_type}');  f()\n    202     except ex: self(f'after_cancel_{event_type}')\n    203     self(f'after_{event_type}');  final()\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/fastai/learner.py:207, in Learner.all_batches(self)\n    205 def all_batches(self):\n    206     self.n_iter = len(self.dl)\n--&gt; 207     for o in enumerate(self.dl): self.one_batch(*o)\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/fastai/data/load.py:129, in DataLoader.__iter__(self)\n    127 self.before_iter()\n    128 self.__idxs=self.get_idxs() # called in context of main process (not workers/subprocesses)\n--&gt; 129 for b in _loaders[self.fake_l.num_workers==0](self.fake_l):\n    130     # pin_memory causes tuples to be converted to lists, so convert them back to tuples\n    131     if self.pin_memory and type(b) == list: b = tuple(b)\n    132     if self.device is not None: b = to_device(b, self.device)\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/torch/utils/data/dataloader.py:630, in _BaseDataLoaderIter.__next__(self)\n    627 if self._sampler_iter is None:\n    628     # TODO(https://github.com/pytorch/pytorch/issues/76750)\n    629     self._reset()  # type: ignore[call-arg]\n--&gt; 630 data = self._next_data()\n    631 self._num_yielded += 1\n    632 if self._dataset_kind == _DatasetKind.Iterable and \\\n    633         self._IterableDataset_len_called is not None and \\\n    634         self._num_yielded &gt; self._IterableDataset_len_called:\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/torch/utils/data/dataloader.py:673, in _SingleProcessDataLoaderIter._next_data(self)\n    671 def _next_data(self):\n    672     index = self._next_index()  # may raise StopIteration\n--&gt; 673     data = self._dataset_fetcher.fetch(index)  # may raise StopIteration\n    674     if self._pin_memory:\n    675         data = _utils.pin_memory.pin_memory(data, self._pin_memory_device)\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py:42, in _IterableDatasetFetcher.fetch(self, possibly_batched_index)\n     40         raise StopIteration\n     41 else:\n---&gt; 42     data = next(self.dataset_iter)\n     43 return self.collate_fn(data)\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/fastai/data/load.py:140, in DataLoader.create_batches(self, samps)\n    138 if self.dataset is not None: self.it = iter(self.dataset)\n    139 res = filter(lambda o:o is not None, map(self.do_item, samps))\n--&gt; 140 yield from map(self.do_batch, self.chunkify(res))\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/fastcore/basics.py:245, in chunked(it, chunk_sz, drop_last, n_chunks)\n    243 if not isinstance(it, Iterator): it = iter(it)\n    244 while True:\n--&gt; 245     res = list(itertools.islice(it, chunk_sz))\n    246     if res and (len(res)==chunk_sz or not drop_last): yield res\n    247     if len(res)&lt;chunk_sz: return\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/fastai/data/load.py:170, in DataLoader.do_item(self, s)\n    169 def do_item(self, s):\n--&gt; 170     try: return self.after_item(self.create_item(s))\n    171     except SkipItemException: return None\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/fastcore/transform.py:210, in Pipeline.__call__(self, o)\n--&gt; 210 def __call__(self, o): return compose_tfms(o, tfms=self.fs, split_idx=self.split_idx)\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/fastcore/transform.py:160, in compose_tfms(x, tfms, is_enc, reverse, **kwargs)\n    158 for f in tfms:\n    159     if not is_enc: f = f.decode\n--&gt; 160     x = f(x, **kwargs)\n    161 return x\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/fastai/vision/augment.py:51, in RandTransform.__call__(self, b, split_idx, **kwargs)\n     45 def __call__(self, \n     46     b, \n     47     split_idx:int=None, # Index of the train/valid dataset\n     48     **kwargs\n     49 ):\n     50     self.before_call(b, split_idx=split_idx)\n---&gt; 51     return super().__call__(b, split_idx=split_idx, **kwargs) if self.do else b\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/fastcore/transform.py:83, in Transform.__call__(self, x, **kwargs)\n---&gt; 83 def __call__(self, x, **kwargs): return self._call('encodes', x, **kwargs)\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/fastcore/transform.py:93, in Transform._call(self, fn, x, split_idx, **kwargs)\n     91 def _call(self, fn, x, split_idx=None, **kwargs):\n     92     if split_idx!=self.split_idx and self.split_idx is not None: return x\n---&gt; 93     return self._do_call(getattr(self, fn), x, **kwargs)\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/fastcore/transform.py:100, in Transform._do_call(self, f, x, **kwargs)\n     98     ret = f.returns(x) if hasattr(f,'returns') else None\n     99     return retain_type(f(x, **kwargs), x, ret)\n--&gt; 100 res = tuple(self._do_call(f, x_, **kwargs) for x_ in x)\n    101 return retain_type(res, x)\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/fastcore/transform.py:100, in &lt;genexpr&gt;(.0)\n     98     ret = f.returns(x) if hasattr(f,'returns') else None\n     99     return retain_type(f(x, **kwargs), x, ret)\n--&gt; 100 res = tuple(self._do_call(f, x_, **kwargs) for x_ in x)\n    101 return retain_type(res, x)\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/fastcore/transform.py:99, in Transform._do_call(self, f, x, **kwargs)\n     97     if f is None: return x\n     98     ret = f.returns(x) if hasattr(f,'returns') else None\n---&gt; 99     return retain_type(f(x, **kwargs), x, ret)\n    100 res = tuple(self._do_call(f, x_, **kwargs) for x_ in x)\n    101 return retain_type(res, x)\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/fastcore/dispatch.py:122, in TypeDispatch.__call__(self, *args, **kwargs)\n    120 elif self.inst is not None: f = MethodType(f, self.inst)\n    121 elif self.owner is not None: f = MethodType(f, self.owner)\n--&gt; 122 return f(*args, **kwargs)\n\nFile ~/pro/dev/uhina/uhina/augment.py:51, in Quantize.encodes(self, x)\n     49 percentiles = self.get_percentiles()\n     50 levels = torch.quantile(im_tensor.float(), percentiles / 100)\n---&gt; 51 im_quant = torch.bucketize(im_tensor.float(), levels)\n     53 cmap = plt.get_cmap('Spectral_r')\n     54 im_color = tensor(cmap(im_quant.float() / im_quant.max())[:,:,:3])\n\nKeyboardInterrupt: \n\n\n\n\nnp.c_[val_preds, val_targets][:10]\n\narray([[0.6631091 , 0.7696582 ],\n       [0.45307112, 0.5359099 ],\n       [0.28646332, 0.25363058],\n       [0.891094  , 0.96547544],\n       [0.47445062, 0.54948056],\n       [1.4899724 , 1.4513922 ],\n       [0.3082603 , 0.25363058],\n       [0.41703525, 0.27481836],\n       [0.42921203, 0.4435868 ],\n       [0.77836686, 0.80633885]], dtype=float32)\n\n\n\nx, y = val_preds, val_targets\nplt.plot(x, y, '.')\n# Add the diagonal line\nmin_val = min(y.min(), x.min())\nmax_val = max(y.max(), x.max())\nplt.plot([min_val, max_val], [min_val, max_val], 'k--', lw=1)\n\n\n\n\n\n\n\n\n\nr2_score(val_targets, val_preds)\n\n0.8264008364793762\n\n\n\n\nOn single images\n\ndef predict_with_transforms(learn, img_path, n_predictions=5):\n    # Load the image\n    img = PILImage.create(img_path)\n    \n    # Create instances of the transforms\n    ratio_resize = RatioResize(224)\n    quantize = Quantize()\n    \n    predictions = []\n    for _ in range(n_predictions):\n        # Apply transforms\n        img_resized = ratio_resize(img)\n        img_quantized = quantize(img_resized)\n        \n        # Predict\n        pred, _, _ = learn.predict(img_quantized)\n        predictions.append(pred[0])\n    \n    from statistics import mode\n    # Calculate mean and standard deviation\n    mean_pred = np.mean(predictions)\n    std_pred = np.std(predictions)\n    median_pred = np.median(predictions)\n    mode_pred = mode(predictions)\n    return mean_pred, std_pred, median_pred, mode_pred, predictions\n\n\ntest_df[['fname', df.columns[idx]]]\n\n\n\n\n\n\n\n\nfname\nsoil_ex_K2O\n\n\n\n\n217\n859-2014-paddy_rice.png\n0.539629\n\n\n163\n278-2018-paddy_rice.png\n0.341865\n\n\n243\n968-2014-paddy_rice.png\n0.578465\n\n\n467\n2076-2018-paddy_rice.png\n0.338844\n\n\n513\n2123-2018-paddy_rice.png\n1.048431\n\n\n...\n...\n...\n\n\n605\n2419-2020-paddy_rice.png\n0.274818\n\n\n352\n1473-2014-paddy_rice.png\n0.407526\n\n\n0\n20-2013-paddy_rice.png\n0.317439\n\n\n355\n1477-2014-paddy_rice.png\n0.337330\n\n\n424\n2033-2018-buckwheat.png\n0.806339\n\n\n\n\n127 rows × 2 columns\n\n\n\n\nlearn.predict('/Users/franckalbinet/pro/dev/uhina/_data/fk-jumpei-tfm/im/859-2014-paddy_rice.png')\n\n\n\n\n\n\n\n\n((0.5223042368888855,), tensor([0.5223]), tensor([0.5223]))\n\n\n\ndef predict_with_tta_histogram(learn, img_path, n_tta=30):\n    # Load the image\n    img = PILImage.create(img_path)\n    \n    # Create a test DataLoader with a single image\n    test_dl = learn.dls.test_dl([img])\n    \n    # Collect predictions\n    all_preds = []\n    for _ in range(n_tta):\n        # Get prediction with TTA (n=1 for a single augmentation each time)\n        preds, _ = learn.tta(dl=test_dl, n=1)\n        all_preds.append(preds[0][0].item())  # Assuming single output\n    \n    all_preds = np.array(all_preds)\n    \n    # Calculate statistics\n    mean_pred = np.mean(all_preds)\n    std_pred = np.std(all_preds)\n    median_pred = np.median(all_preds)\n    min_pred = np.min(all_preds)\n    max_pred = np.max(all_preds)\n    \n    return mean_pred, std_pred, median_pred, min_pred, max_pred, all_preds\n\n\n# Use the function\nfname = '859-2014-paddy_rice.png'\nimg_path = Path('/Users/franckalbinet/pro/dev/uhina/_data/fk-jumpei-tfm/im/') / fname\nmean, std, median, min_pred, max_pred, all_preds = predict_with_tta_histogram(learn, img_path, n_tta=30)\n\nprint(f\"Min prediction: {min_pred:.4f}\")\nprint(f\"Max prediction: {max_pred:.4f}\")\nprint(f\"Mean prediction: {mean:.4f}\")\nprint(f\"Standard deviation: {std:.4f}\")\nprint(f\"Median prediction: {median:.4f}\")\nprint(f\"All predictions: {all_preds}\")\n\n# If you want to compare with the ground truth\nprint('Ground truth:', df[df.fname == fname][df.columns[idx]].values[0])\n\n# Plot histogram\nplt.hist(all_preds, bins=10)\nplt.title('Histogram of TTA Predictions')\nplt.xlabel('Predicted Value')\nplt.ylabel('Frequency')\nplt.show()\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\nMin prediction: 0.4531\nMax prediction: 0.5795\nMean prediction: 0.5275\nStandard deviation: 0.0282\nMedian prediction: 0.5272\nAll predictions: [0.54436386 0.55598998 0.56092638 0.57104981 0.52798319 0.57950228\n 0.50701064 0.52194297 0.51890564 0.53010362 0.50141889 0.53311121\n 0.51312613 0.53879243 0.50901508 0.51508129 0.54903734 0.51155448\n 0.53831923 0.50822324 0.52851534 0.57572448 0.51641762 0.51522946\n 0.45307761 0.52632904 0.53577548 0.56359959 0.51006508 0.46458086]\nGround truth: 0.5396292928049117\n\n\n\n\n\n\n\n\n\n\n# Canonical fine-tuning\n# from fastai.vision.all import *\n\n# # Load the pretrained model\n# learn = load_learner('./models/650-4000-epoch-25-lr-3e-3.pkl', cpu=False)\n\n# # Prepare your new data\n# path = 'path/to/your/data'\n# dls = ImageDataLoaders.from_folder(path, valid_pct=0.2, item_tfms=Resize(224), batch_tfms=aug_transforms())\n\n# # Set the new data\n# learn.dls = dls\n\n# # Fine-tune the head of the model\n# learn.freeze()\n# # alternatively: learn.freeze_to(n)\n# learn.lr_find()\n# learn.fit_one_cycle(5, 3e-3)\n\n# # Fine-tune the entire model\n# learn.unfreeze()\n# learn.lr_find()\n# learn.fit_one_cycle(5, slice(1e-5, 1e-3))\n\n\n# learn = vision_learner(dls, resnet18, pretrained=False, metrics=R2Score()).to_fp16()\n\n\n# learn.lr_find()\n\n\n# learn.lr_find()\n\n\n\n\n\n\n\n\nSuggestedLRs(valley=0.002511886414140463)\n\n\n\n\n\n\n\n\n\n\n# learn.fit_one_cycle(5, 3e-3)",
    "crumbs": [
      "example",
      "Fukushima Jumpei transfer learning"
    ]
  },
  {
    "objectID": "example/fk-jumpei-transfer-learning.html#evaluation",
    "href": "example/fk-jumpei-transfer-learning.html#evaluation",
    "title": "Fukushima Jumpei transfer learning",
    "section": "Evaluation",
    "text": "Evaluation\n\n# Convert predictions and targets to numpy arrays\ndef assess_model(val_preds, val_targets):\n    val_preds = val_preds.numpy().flatten()\n    val_targets = val_targets.numpy()\n\n    # Create a DataFrame with the results\n    results_df = pd.DataFrame({\n        'Predicted': val_preds,\n        'Actual': val_targets\n    })\n\n    # Display the first few rows of the results\n    print(results_df.head())\n\n    # Calculate and print the R2 score\n    from sklearn.metrics import r2_score\n    r2 = r2_score(val_targets, val_preds)\n    print(f\"R2 Score on validation set: {r2:.4f}\")\n\n\ndls.train.n\n\n69\n\n\n\nval_preds, val_targets = learn.get_preds(dl=dls.train)\nassess_model(val_preds, val_targets)\n\n\n\n\n\n\n\n\n   Predicted    Actual\n0   0.046272  0.210804\n1   0.528189  0.976900\n2   0.465372  0.469860\n3   0.258100  0.338556\n4   0.112802  0.147696\nR2 Score on validation set: 0.7392\n\n\n\nval_preds, val_targets = learn.get_preds(dl=dls.train)\nr2 = r2_score(val_targets, val_preds); r2\n\n\nr2 = r2_score(val_targets, val_preds); r2\n\n0.7391959435205914\n\n\n\nscores = []\nfor n in range(1, 20):\n    val_preds, val_targets = learn.tta(dl=dls.train, n=n)\n    scores.append(r2_score(val_targets, val_preds))\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\nx = list(range(1, 20))\nplt.plot(x, scores)\n\n\n\n\n\n\n\n\n\n# EXAMPLE of TTA on single item\n# from fastai.vision.all import *\n\n# # Define your TTA transforms\n# tta_tfms = [\n#     RandomResizedCrop(224, min_scale=0.5),\n#     Flip(),\n#     Rotate(degrees=(-15, 15)),\n#     Brightness(max_lighting=0.2),\n#     Contrast(max_lighting=0.2)\n# ]\n\n# # Create a pipeline of TTA transformations\n# tta_pipeline = Pipeline(tta_tfms)\n\n# # Load your model\n# learn = load_learner('path/to/your/model.pkl')\n\n# # Define the input data (e.g., an image)\n# input_data = PILImage.create('path/to/your/image.jpg')\n\n# # Apply TTA transforms to the input data and make predictions\n# predictions = []\n# for _ in range(5):  # Apply 5 different augmentations\n#     augmented_data = tta_pipeline(input_data)\n#     prediction = learn.predict(augmented_data)\n#     predictions.append(prediction)\n\n# # Average the predictions\n# average_prediction = sum(predictions) / len(predictions)\n\n# print(average_prediction)\n\n\n# Assuming you have a new CSV file for your test data\n# test_source = '../../_data/ossl-tfm/ossl-tfm-test.csv'\n# test_df = pd.read_csv(test_source)\n\n# # Create a new DataLoader for the test data\n# test_dl = learn.dls.test_dl(test_df)\n\n# # Get predictions on the test set\n# test_preds, test_targets = learn.get_preds(dl=test_dl)\n\n# # Now you can use test_preds and test_targets for further analysis\n\n\nassess_model(val_preds, val_targets)\n\n   Predicted    Actual\n0   0.312483  0.000000\n1   0.126990  0.184960\n2   0.365726  0.194201\n3   0.239089  0.262364\n4   0.402980  0.355799\nR2 Score on validation set: 0.8325\n\n\n\nassess_model(val_preds_tta, val_targets_tta)\n\n   Predicted    Actual\n0   0.246857  0.000000\n1   0.148590  0.184960\n2   0.371643  0.194201\n3   0.226535  0.262364\n4   0.407333  0.355799\nR2 Score on validation set: 0.8378\n\n\n\nval_preds_np = val_preds\nval_targets_np = val_targets\n\n# Apply the transformation: exp(y) - 1\nval_preds_transformed = np.exp(val_preds_np) - 1\nval_targets_transformed = np.exp(val_targets_np) - 1\n\n# Create a DataFrame with the results\nresults_df = pd.DataFrame({\n    'Predicted': val_preds_transformed,\n    'Actual': val_targets_transformed\n})\n\n# Display the first few rows of the results\nprint(results_df.head())\n\n# Calculate and print the R2 score\nfrom sklearn.metrics import r2_score\nr2 = r2_score(val_targets_transformed, val_preds_transformed)\nprint(f\"R2 Score on validation set (after transformation): {r2:.4f}\")\n\n# Calculate and print the MAPE, handling zero values\ndef mean_absolute_percentage_error(y_true, y_pred):\n    non_zero = (y_true != 0)\n    return np.mean(np.abs((y_true[non_zero] - y_pred[non_zero]) / y_true[non_zero])) * 100\n\nmape = mean_absolute_percentage_error(val_targets_transformed, val_preds_transformed)\nprint(f\"Mean Absolute Percentage Error (MAPE) on validation set: {mape:.2f}%\")\n\n# Calculate and print the MAE as an alternative metric\nfrom sklearn.metrics import mean_absolute_error\nmae = mean_absolute_error(val_targets_transformed, val_preds_transformed)\nprint(f\"Mean Absolute Error (MAE) on validation set: {mae:.4f}\")\n\n   Predicted   Actual\n0   0.366814  0.00000\n1   0.135405  0.20317\n2   0.441560  0.21434\n3   0.270092  0.30000\n4   0.496277  0.42732\nR2 Score on validation set (after transformation): 0.6936\nMean Absolute Percentage Error (MAPE) on validation set: 50.72%\nMean Absolute Error (MAE) on validation set: 0.1956\n\n\n\nplt.figure(figsize=(6, 6))\n\n# Use logarithmic bins for the colormap\nh = plt.hexbin(val_targets, val_preds, gridsize=65, \n               bins='log', cmap='Spectral_r', mincnt=1,\n               alpha=0.9)\n\n# Get the actual min and max counts from the hexbin data\ncounts = h.get_array()\nmin_count = counts[counts &gt; 0].min()  # Minimum non-zero count\nmax_count = counts.max()\n\n# Create a logarithmic colorbar\ncb = plt.colorbar(h, label='Count in bin', shrink=0.73)\ntick_locations = np.logspace(np.log10(min_count), np.log10(max_count), 5)\ncb.set_ticks(tick_locations)\ncb.set_ticklabels([f'{int(x)}' for x in tick_locations])\n\n# Add the diagonal line\nmin_val = min(val_targets.min(), val_preds.min())\nmax_val = max(val_targets.max(), val_preds.max())\nplt.plot([min_val, max_val], [min_val, max_val], 'k--', lw=1)\n\n# Set labels and title\nplt.xlabel('Actual Values')\nplt.ylabel('Predicted Values')\nplt.title('Predicted vs Actual Values (Hexbin with Log Scale)')\n\n# Add grid lines\nplt.grid(True, linestyle='--', alpha=0.65)\n\n# Set the same limits for both axes\nplt.xlim(min_val, max_val)\nplt.ylim(min_val, max_val)\n\n# Make the plot square\nplt.gca().set_aspect('equal', adjustable='box')\n\nplt.tight_layout()\nplt.show()\n\n# Print the range of counts in the hexbins\nprint(f\"Min non-zero count in hexbins: {min_count}\")\nprint(f\"Max count in hexbins: {max_count}\")\n\n\n\n\n\n\n\n\nMin non-zero count in hexbins: 1.0\nMax count in hexbins: 157.0\n\n\n\npath_model = Path('./models')\nlearn.export(path_model / '0.pkl')",
    "crumbs": [
      "example",
      "Fukushima Jumpei transfer learning"
    ]
  },
  {
    "objectID": "example/fk-jumpei-transfer-learning.html#inference",
    "href": "example/fk-jumpei-transfer-learning.html#inference",
    "title": "Fukushima Jumpei transfer learning",
    "section": "Inference",
    "text": "Inference\n\nossl_source = Path('../../_data/ossl-tfm/img')\nlearn.predict(ossl_source / '0a0a0c647671fd3030cc13ba5432eb88.png')\n\n\n\n\n\n\n\n\n((0.5229991674423218,), tensor([0.5230]), tensor([0.5230]))\n\n\n\ndf[df['fname'] == '0a0a0c647671fd3030cc13ba5432eb88.png']\n\n\n\n\n\n\n\n\nfname\nkex\n\n\n\n\n28867\n0a0a0c647671fd3030cc13ba5432eb88.png\n0.525379",
    "crumbs": [
      "example",
      "Fukushima Jumpei transfer learning"
    ]
  },
  {
    "objectID": "example/fk-jumpei-classic.html",
    "href": "example/fk-jumpei-classic.html",
    "title": "Fukushima Jumpei classic",
    "section": "",
    "text": "The autoreload extension is already loaded. To reload it, use:\n  %reload_ext autoreload\nimport pandas as pd\nfrom pathlib import Path\n\nfrom sklearn.metrics import r2_score\nfrom uhina.loading import LoaderFactory, plot_spectra\nfrom uhina.preprocessing import TakeDerivative, SNV\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.decomposition import PCA, KernelPCA\nfrom sklearn.preprocessing import StandardScaler\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\npd.set_option('display.max_rows', 100)\n\nimport plotly\nimport plotly.express as px\nimport numpy as np\nfrom astartes import train_val_test_split",
    "crumbs": [
      "example",
      "Fukushima Jumpei classic"
    ]
  },
  {
    "objectID": "example/fk-jumpei-classic.html#loading-data",
    "href": "example/fk-jumpei-classic.html#loading-data",
    "title": "Fukushima Jumpei classic",
    "section": "Loading data",
    "text": "Loading data\n\nsrc = Path.home() / 'pro/data/fk-jumpei'\nloader = LoaderFactory.get_loader(src, 'fk-jumpei')\ndata = loader.load_data()\nprint(f'X shape: {data.X.shape}')\n\nplot_spectra(data, n_spectra=100, snv=True, alpha=0.2, figsize=(12, 3))\n\nX shape: (635, 1675)\n\n\n(&lt;Figure size 1200x300 with 1 Axes&gt;,\n &lt;Axes: xlabel='Wavenumber ($cm^{-1}$)', ylabel='Absorbance'&gt;)\n\n\n\n\n\n\n\n\n\n\n[d for d in dir(data) if '__' not in d]\n\n['X',\n 'X_names',\n 'dataset_labels',\n 'dataset_names',\n 'sample_indices',\n 'y',\n 'y_names']\n\n\n\nprint(f'y_names: {data.y_names}')\n\ny_names: ['soil_total_Cs134' 'soil_total_Cs137' 'soil_ex_Cs137'\n 'exCs137_totalCs137' 'soil_water_soluble_K2O' 'soil_ex_K2O'\n 'TF_plant_totalCs137' 'TF_plant_exCs137' 'soil_pH' 'soil_C' 'soil_N'\n 'soil_CN_ratio' 'soil_CEC' 'soil_MgO' 'soil_CaO'\n 'soil_P_absorption_coefficient' 'avaiable_Pi' 'course_sand' 'fine_sand'\n 'silt' 'clay']\n\n\n\nmask = ~np.isnan(data.y[:, 5])\n\ndata.X = data.X[mask, :]\ndata.y = data.y[mask, :]\ndata.sample_indices = data.sample_indices[mask]",
    "crumbs": [
      "example",
      "Fukushima Jumpei classic"
    ]
  },
  {
    "objectID": "example/fk-jumpei-classic.html#eda",
    "href": "example/fk-jumpei-classic.html#eda",
    "title": "Fukushima Jumpei classic",
    "section": "EDA",
    "text": "EDA\nVisualize in PCA space: - PCA - Robust PCA - Kernel PCA\n\npipe = Pipeline([\n    # ('SNV', SNV()),\n    ('Derivative', TakeDerivative()),\n    ('Scaler', StandardScaler()),  \n    ('PCA', PCA(n_components=3))])\n\npca = PCA(n_components=3)\ndata.X_pca = pipe.fit_transform(data.X)\n\n\npipe = Pipeline([\n    # ('SNV', SNV()),\n    ('Derivative', TakeDerivative()),\n    ('Scaler', StandardScaler())\n    ])\ndata.X_transformed = pipe.fit_transform(data.X)\n\n\nplot_spectra(data, var='X_transformed', n_spectra=100, snv=True, alpha=0.2, figsize=(12, 3))\n\n(&lt;Figure size 1200x300 with 1 Axes&gt;,\n &lt;Axes: xlabel='Wavenumber ($cm^{-1}$)', ylabel='Absorbance'&gt;)\n\n\n\n\n\n\n\n\n\n\nfor i, name in enumerate(data.y_names):\n    print(i, name)\n\n0 soil_total_Cs134\n1 soil_total_Cs137\n2 soil_ex_Cs137\n3 exCs137_totalCs137\n4 soil_water_soluble_K2O\n5 soil_ex_K2O\n6 TF_plant_totalCs137\n7 TF_plant_exCs137\n8 soil_pH\n9 soil_C\n10 soil_N\n11 soil_CN_ratio\n12 soil_CEC\n13 soil_MgO\n14 soil_CaO\n15 soil_P_absorption_coefficient\n16 avaiable_Pi\n17 course_sand\n18 fine_sand\n19 silt\n20 clay\n\n\n\ndef mg_100g_to_cmol_kg(x, log_tfm=False, atom_weight=39.1):\n    x_mg_kg = x * 10 \n    x_mg_kg_K = 0.83 * x_mg_kg\n    x_cmol_kg_K = x_mg_kg_K / (atom_weight*10)\n    return np.log1p(x_cmol_kg_K) if log_tfm else x_cmol_kg_K\n\n\ndata.y[:, 5] = np.log1p(mg_100g_to_cmol_kg(data.y[:, 5]))\n\n\ndef data_to_df(data, x_names=['PC1', 'PC2', 'PC3']):\n    df_x = pd.DataFrame(data.X_pca, columns=x_names)\n\n    # Create a DataFrame from data.y with column names from data.y_names\n    df_y = pd.DataFrame(data.y, columns=data.y_names)\n\n    # Concatenate the two DataFrames\n    return pd.concat([df_x, df_y], axis=1)\n\n\ndata_to_df(data).head()\n\n\n\n\n\n\n\n\nPC1\nPC2\nPC3\nsoil_total_Cs134\nsoil_total_Cs137\nsoil_ex_Cs137\nexCs137_totalCs137\nsoil_water_soluble_K2O\nsoil_ex_K2O\nTF_plant_totalCs137\n...\nsoil_CN_ratio\nsoil_CEC\nsoil_MgO\nsoil_CaO\nsoil_P_absorption_coefficient\navaiable_Pi\ncourse_sand\nfine_sand\nsilt\nclay\n\n\n\n\n0\n-14.869968\n15.920217\n-4.068206\nNaN\n610.0\n70.6\n0.116\nNaN\n0.317439\nNaN\n...\n12.0\n29.5\n64.1\n339.0\n1700.0\nNaN\n17.1\n34.1\n25.6\n23.2\n\n\n1\n15.475605\n-15.832351\n-14.945087\nNaN\n273.5\n27.8\n0.102\nNaN\n0.840806\nNaN\n...\n12.0\n19.6\n30.3\n217.0\n660.0\n12.2\nNaN\nNaN\nNaN\nNaN\n\n\n2\n7.119297\n4.821976\n-12.138583\nNaN\n28.1\n3.6\n0.127\nNaN\n0.387556\nNaN\n...\n12.0\n13.8\n38.1\n96.1\n640.0\n6.8\nNaN\nNaN\nNaN\nNaN\n\n\n3\n5.582190\n13.646001\n-18.429360\nNaN\n897.8\n71.4\n0.080\nNaN\n0.538391\nNaN\n...\n12.0\n15.4\n16.2\n119.0\n640.0\n34.2\nNaN\nNaN\nNaN\nNaN\n\n\n4\n8.468630\n12.233581\n-19.155799\nNaN\n964.3\n90.6\n0.094\nNaN\n0.792981\nNaN\n...\n12.0\n17.7\n19.9\n151.0\n610.0\n40.0\nNaN\nNaN\nNaN\nNaN\n\n\n\n\n5 rows × 24 columns\n\n\n\n\ndef scatter3d(df, idxs=None, dot_size=15, color_by_split=False):\n    \"\"\"Generates a nicely formatted 3D scatter plot of the data\n    optionally showing train/validation/test splits.\n\n    Args:\n        df (pd.DataFrame): DataFrame containing the data\n        idxs (tuple of np.array, optional): train, validation, and\n            test indexes. Defaults to None.\n        dot_size (int, optional): Base size for dots. Defaults to 15.\n        color_by_split (bool, optional): If True, color by split instead of soil_ex_K2O. Defaults to False.\n    \"\"\"\n    df = df.copy()\n    df['size'] = dot_size\n    min_val, max_val = df['soil_ex_K2O'].min(), df['soil_ex_K2O'].max()\n    plot_args = dict(\n        data_frame=df,\n        x=\"PC1\",\n        y=\"PC2\",\n        z=\"PC3\",\n        opacity=1,\n        height=800,\n        width=800,\n        size='size',\n        size_max=dot_size\n    )\n\n    if idxs:\n        total_samples = len(df)\n        size_array = [dot_size] * total_samples\n        name_array = ['Unsplit'] * total_samples\n        \n        # Calculate relative sizes based on the number of splits\n        split_sizes = [len(split) for split in idxs]\n        max_split_size = max(split_sizes)\n        relative_sizes = [dot_size * (1 + 2 * (size / max_split_size)) for size in split_sizes]\n        \n        split_names = [\"Training\", \"Validation\", \"Testing\"][:len(idxs)]\n        \n        for split, split_size, split_name in zip(idxs, relative_sizes, split_names):\n            for idx in split:\n                size_array[idx] = split_size\n                name_array[idx] = split_name\n        \n        # pass these through to plotly call\n        plot_args[\"symbol\"] = \"Split\"\n        plot_args[\"size\"] = \"MarkerSize\"\n        df[\"MarkerSize\"] = np.array(size_array)\n        df[\"Split\"] = np.array(name_array)\n\n        if color_by_split:\n            plot_args[\"color\"] = \"Split\"\n            plot_args[\"color_discrete_map\"] = {\"Training\": \"#1b9e77\", \"Validation\": \"#d95f02\", \"Testing\": \"#7570b3\", \"Unsplit\": \"gray\"}\n        else:\n            plot_args[\"color\"] = \"soil_ex_K2O\"\n            plot_args[\"range_color\"] = [min_val, max_val]\n    else:\n        plot_args[\"color\"] = \"soil_ex_K2O\"\n        plot_args[\"range_color\"] = [min_val, max_val]\n\n    # actual call to plotly\n    fig = px.scatter_3d(**plot_args)\n\n    # add a legend for different split types\n    if idxs:\n        fig.update_layout(\n            legend=dict(orientation=\"h\", yanchor=\"bottom\", y=1.02, xanchor=\"right\", x=1)\n        )\n        fig.update_traces(marker=dict(line=dict(width=0)))\n\n        # make the markers consistent between plots\n        symbols = {\"Training\": \"circle\", \"Validation\": \"diamond\", \"Testing\": \"square\", \"Unsplit\": \"circle\"}\n        for i, d in enumerate(fig.data):\n            if d.name in symbols:\n                fig.data[i].marker.symbol = symbols[d.name]\n\n    # customize the colors\n    fig.update_layout(\n        dict(\n            plot_bgcolor=\"rgba(0, 0, 0, 0)\",\n            paper_bgcolor=\"rgba(0, 0, 0, 0)\",\n        )\n    )\n    axis_args = dict(\n        backgroundcolor=\"rgba(0, 0, 0,0)\",\n        gridcolor=\"grey\",\n        showbackground=True,\n        zerolinecolor=\"grey\",\n    )\n    fig.update_layout(scene=dict(xaxis=axis_args, yaxis=axis_args, zaxis=axis_args))\n\n    # render the plot\n    fig.show()\n\n\nscatter3d(data_to_df(data), dot_size=15)\n\nUnable to display output for mime type(s): application/vnd.plotly.v1+json",
    "crumbs": [
      "example",
      "Fukushima Jumpei classic"
    ]
  },
  {
    "objectID": "example/fk-jumpei-classic.html#trainvalidtest-splits",
    "href": "example/fk-jumpei-classic.html#trainvalidtest-splits",
    "title": "Fukushima Jumpei classic",
    "section": "Train/Valid/Test splits",
    "text": "Train/Valid/Test splits\nInspired from: https://jacksonburns.github.io/use-rse-23-astartes/split_comparisons.html\n\nInterpolative\n\nRandom split\n\n(\n    random_X_train,\n    random_X_val,\n    random_X_test,\n    random_y_train,\n    random_y_val,\n    random_y_test,\n    random_idxs_train,\n    random_idxs_val,\n    random_idxs_test,\n) = train_val_test_split(\n    data.X_transformed,\n    data.y[:, 5],\n    sampler=\"random\",\n    train_size=0.5,\n    val_size=0.25,\n    test_size=0.25,\n    return_indices=True,\n    random_state=40\n)\n\n\nscatter3d(\n    data_to_df(data), \n    idxs=(random_idxs_train, random_idxs_val, random_idxs_test),\n    color_by_split=True,\n    dot_size=13)\n\nUnable to display output for mime type(s): application/vnd.plotly.v1+json\n\n\n\n\nKennard-Stone\n\n(\n    ks_X_train,\n    ks_X_val,\n    ks_X_test,\n    ks_y_train,\n    ks_y_val,\n    ks_y_test,\n    ks_idxs_train,\n    ks_idxs_val,\n    ks_idxs_test,\n) = train_val_test_split(\n    data.X_transformed,\n    data.y[:, 5],\n    sampler=\"kennard_stone\",\n    train_size=0.5,\n    val_size=0.25,\n    test_size=0.25,\n    return_indices=True,\n)\n\n\nscatter3d(\n    data_to_df(data), \n    idxs=(ks_idxs_train, ks_idxs_val, ks_idxs_test),\n    color_by_split=True,\n    dot_size=13)\n\nUnable to display output for mime type(s): application/vnd.plotly.v1+json\n\n\n\n\nSPXY\n\n(\n    spxy_X_train,\n    spxy_X_val,\n    spxy_X_test,\n    spxy_y_train,\n    spxy_y_val,\n    spxy_y_test,\n    spxy_idxs_train,\n    spxy_idxs_val,\n    spxy_idxs_test,\n) = train_val_test_split(\n    data.X_transformed,\n    data.y[:, 5],\n    sampler=\"spxy\",\n    train_size=0.5,\n    val_size=0.25,\n    test_size=0.25,\n    return_indices=True,\n)\n\n\nscatter3d(\n    data_to_df(data), \n    idxs=(spxy_idxs_train, spxy_idxs_val, spxy_idxs_test),\n    color_by_split=True,\n    dot_size=13)\n\nUnable to display output for mime type(s): application/vnd.plotly.v1+json\n\n\n\n\n\nExtrapolative\n\nKMeans\n\n(\n    kmeans_X_train,\n    kmeans_X_val,\n    kmeans_X_test,\n    kmeans_y_train,\n    kmeans_y_val,\n    kmeans_y_test,\n    kmeans_clusters_train,\n    kmeans_clusters_val,\n    kmeans_clusters_test,\n    kmeans_idxs_train,\n    kmeans_idxs_val,\n    kmeans_idxs_test,\n) = train_val_test_split(\n    data.X_transformed,\n    data.y[:, 5],\n    sampler=\"kmeans\",\n    train_size=0.5,\n    val_size=0.25,\n    test_size=0.25,\n    return_indices=True,\n    hopts=dict(n_clusters=6),\n)\n\n\nscatter3d(\n    data_to_df(data), \n    idxs=(kmeans_idxs_train, kmeans_idxs_val, kmeans_idxs_test),\n    color_by_split=True,\n    dot_size=13)\n\nUnable to display output for mime type(s): application/vnd.plotly.v1+json\n\n\n\n\nSphere exclusion\n\n(\n    spex_X_train,\n    spex_X_val,\n    spex_X_test,\n    spex_y_train,\n    spex_y_val,\n    spex_y_test,\n    spex_clusters_train,\n    spex_clusters_val,\n    spex_clusters_test,\n    spex_idxs_train,\n    spex_idxs_val,\n    spex_idxs_test,\n) = train_val_test_split(\n    data.X_transformed,\n    data.y[:, 5],\n    sampler=\"sphere_exclusion\",\n    train_size=0.5,\n    val_size=0.25,\n    test_size=0.25,\n    return_indices=True,\n    hopts=dict(\n        # normalized between zero and one\n        distance_cutoff=0.1,\n    ),\n)\n\n\nscatter3d(\n    data_to_df(data), \n    idxs=(spex_idxs_train, spex_idxs_val, spex_idxs_test),\n    color_by_split=True,\n    dot_size=13)\n\nUnable to display output for mime type(s): application/vnd.plotly.v1+json\n\n\n\n\nDBSCAN\n\n# (\n#     dbscan_X_train,\n#     dbscan_X_val,\n#     dbscan_X_test,\n#     dbscan_y_train,\n#     dbscan_y_val,\n#     dbscan_y_test,\n#     dbscan_clusters_train,\n#     dbscan_clusters_val,\n#     dbscan_clusters_test,\n#     dbscan_idxs_train,\n#     dbscan_idxs_val,\n#     dbscan_idxs_test,\n# ) = train_val_test_split(\n#     data.X_transformed,\n#     data.y[:, 5],\n#     sampler=\"dbscan\",\n#     train_size=0.5,\n#     val_size=0.25,\n#     test_size=0.25,\n#     return_indices=True,\n#     hopts=dict(\n#         eps=100,\n#     ),\n# )",
    "crumbs": [
      "example",
      "Fukushima Jumpei classic"
    ]
  },
  {
    "objectID": "example/fk-jumpei-classic.html#training",
    "href": "example/fk-jumpei-classic.html#training",
    "title": "Fukushima Jumpei classic",
    "section": "Training",
    "text": "Training\n\ndef get_split_data(split_type):\n    split_names = ['X_train', 'X_val', 'X_test', 'y_train', 'y_val', 'y_test', 'idxs_train', 'idxs_val', 'idxs_test']\n    return {name: globals().get(f\"{split_type}_{name}\") for name in split_names}\n\nsplit_types = ['random', 'ks', 'spxy', 'kmeans', 'spex']\n\ndef get_data_for_split(split_type):\n    if split_type not in split_types:\n        raise ValueError(f\"Invalid split type. Choose from: {', '.join(split_types)}\")\n    \n    split_data = get_split_data(split_type)\n    \n    return (\n        split_data['X_train'], split_data['X_val'], split_data['X_test'],\n        split_data['y_train'], split_data['y_val'], split_data['y_test'],\n        split_data['idxs_train'], split_data['idxs_val'], split_data['idxs_test']\n    )\n\n\nsplit_type = 'ks'  # or any other split type\n\n(\n    X_train, \n    X_val, \n    X_test, \n    y_train, \n    y_val, \n    y_test, \n    idxs_train, \n    idxs_val, \n    idxs_test\n) = get_data_for_split(split_type)\n\n\nfrom sklearn.cross_decomposition import PLSRegression\nfrom tqdm.auto import tqdm\n\nscores = []\nn_max = 20\nfor n in tqdm(range(1,n_max)):\n    pls = PLSRegression(n_components=n)\n    pls.fit(X_train, y_train)\n    y_val_predicted = pls.predict(X_val)\n    scores.append(r2_score(y_val, y_val_predicted))\n\nplt.plot(range(1, n_max), scores)\nn_best = np.argmax(np.array(scores)) + 1\nprint(f'Best score: {scores[n_best]} at n={n_best}')\n# plt.ylim(0, 1)\n\n100%|██████████| 19/19 [00:00&lt;00:00, 25.93it/s]\n\n\nBest score: 0.33593208396890584 at n=12\n\n\n\n\n\n\n\n\n\n\n# ON TEST SET\npls = PLSRegression(n_components=n_best)\npls.fit(X_train, y_train)\ny_test_predicted = pls.predict(X_test)\nr2_score(y_test, y_test_predicted)\n\n0.006008064304613536\n\n\n\nsrc = '../../_data/fk-jumpei-tfm/im-targets-lut.csv'\ndf = pd.read_csv(src)\nprint(f'{df.shape[0]} samples')\ndf.head()\n\n635 samples\n\n\n\n\n\n\n\n\n\nfname\nsoil_total_Cs134\nsoil_total_Cs137\nsoil_ex_Cs137\nexCs137_totalCs137\nsoil_water_soluble_K2O\nsoil_ex_K2O\nTF_plant_totalCs137\nTF_plant_exCs137\nsoil_pH\n...\nsoil_CN_ratio\nsoil_CEC\nsoil_MgO\nsoil_CaO\nsoil_P_absorption_coefficient\navaiable_Pi\ncourse_sand\nfine_sand\nsilt\nclay\n\n\n\n\n0\n20-2013-paddy_rice.png\nNaN\n610.0\n70.6\n0.116\nNaN\n17.6\nNaN\nNaN\n6.0\n...\n12.0\n29.5\n64.1\n339.0\n1700.0\nNaN\n17.1\n34.1\n25.6\n23.2\n\n\n1\n28-2014-paddy_rice.png\nNaN\n273.5\n27.8\n0.102\nNaN\n62.1\nNaN\nNaN\n5.0\n...\n12.0\n19.6\n30.3\n217.0\n660.0\n12.2\nNaN\nNaN\nNaN\nNaN\n\n\n2\n33-2014-paddy_rice.png\nNaN\n28.1\n3.6\n0.127\nNaN\n22.3\nNaN\nNaN\n6.0\n...\n12.0\n13.8\n38.1\n96.1\n640.0\n6.8\nNaN\nNaN\nNaN\nNaN\n\n\n3\n35-2014-paddy_rice.png\nNaN\n897.8\n71.4\n0.080\nNaN\n33.6\nNaN\nNaN\n5.0\n...\n12.0\n15.4\n16.2\n119.0\n640.0\n34.2\nNaN\nNaN\nNaN\nNaN\n\n\n4\n36-2014-paddy_rice.png\nNaN\n964.3\n90.6\n0.094\nNaN\n57.0\nNaN\nNaN\n5.0\n...\n12.0\n17.7\n19.9\n151.0\n610.0\n40.0\nNaN\nNaN\nNaN\nNaN\n\n\n\n\n5 rows × 22 columns\n\n\n\n\ndef mg_100g_to_cmol_kg(x, log_tfm=False, atom_weight=39.1):\n    x_mg_kg = x * 10 \n    x_mg_kg_K = 0.83 * x_mg_kg\n    x_cmol_kg_K = x_mg_kg_K / (atom_weight*10)\n    return np.log1p(x_cmol_kg_K) if log_tfm else x_cmol_kg_K\n\n\nmg_100g_to_cmol_kg(df['soil_ex_K2O'], log_tfm=True).hist()\n\n\n\n\n\n\n\n\n\nprint('Before:', df.shape)\ndf.dropna(inplace=True, subset=['soil_ex_K2O'])\nprint('After:', df.shape)\n\nBefore: (635, 22)\nAfter: (634, 22)\n\n\n\ndf['soil_ex_K2O'] = df['soil_ex_K2O'].apply(lambda x: mg_100g_to_cmol_kg(x, log_tfm=True))\n df.soil_ex_K2O.hist()\n\n\n\n\n\n\n\n\n\nfor i, col in enumerate(df.columns):\n    print(f'{i}: {col}')\n\n0: fname\n1: soil_total_Cs134\n2: soil_total_Cs137\n3: soil_ex_Cs137\n4: exCs137_totalCs137\n5: soil_water_soluble_K2O\n6: soil_ex_K2O\n7: TF_plant_totalCs137\n8: TF_plant_exCs137\n9: soil_pH\n10: soil_C\n11: soil_N\n12: soil_CN_ratio\n13: soil_CEC\n14: soil_MgO\n15: soil_CaO\n16: soil_P_absorption_coefficient\n17: avaiable_Pi\n18: course_sand\n19: fine_sand\n20: silt\n21: clay",
    "crumbs": [
      "example",
      "Fukushima Jumpei classic"
    ]
  },
  {
    "objectID": "example/fk-jumpei-classic.html#fine-tuning",
    "href": "example/fk-jumpei-classic.html#fine-tuning",
    "title": "Fukushima Jumpei classic",
    "section": "Fine-tuning",
    "text": "Fine-tuning\n\nclass OrderedQuantize(Quantize):\n    order = 0  # Apply first\n\nclass OrderedRatioResize(RatioResize):\n    order = 1  # Apply second\n\n\ndef stratified_split(df, target, valid_size=0.2, test_size=0.2, num_bins=2, seed=41):\n    from sklearn.model_selection import train_test_split\n    df = df.copy()\n    df.reset_index(inplace=True, drop=True)\n    train_df, test_df = train_test_split(df, test_size=test_size, \n                                        stratify=pd.qcut(df[target], q=num_bins, labels=False), \n                                        random_state=seed)\n\n    train_df, valid_df = train_test_split(train_df, test_size=valid_size, \n                                        stratify=pd.qcut(train_df[target], q=num_bins, labels=False), \n                                        random_state=seed)\n    \n    return train_df, train_df.index, valid_df, valid_df.index, test_df, test_df.index\n\n\n# from sklearn.model_selection import StratifiedShuffleSplit\n\n# def stratified_split(df, target_col, n_bins=2, n_splits=2, test_size=0.2, random_state=42):\n#     # Create bins for the target values\n#     df_copy = df.copy()\n#     df_copy['target_bin'] = pd.cut(df_copy[target_col], bins=n_bins, labels=False)\n    \n#     # Create a StratifiedShuffleSplit object\n#     sss = StratifiedShuffleSplit(n_splits=n_splits, test_size=test_size, random_state=random_state)\n    \n#     # Get the indices for the splits\n#     splits = list(sss.split(df_copy, df_copy['target_bin']))\n    \n#     # Remove the temporary 'target_bin' column\n#     df_copy.drop('target_bin', axis=1, inplace=True)\n    \n#     return splits\n\n\ndf.head()\n\n\n\n\n\n\n\n\nfname\nsoil_total_Cs134\nsoil_total_Cs137\nsoil_ex_Cs137\nexCs137_totalCs137\nsoil_water_soluble_K2O\nsoil_ex_K2O\nTF_plant_totalCs137\nTF_plant_exCs137\nsoil_pH\n...\nsoil_CN_ratio\nsoil_CEC\nsoil_MgO\nsoil_CaO\nsoil_P_absorption_coefficient\navaiable_Pi\ncourse_sand\nfine_sand\nsilt\nclay\n\n\n\n\n0\n20-2013-paddy_rice.png\nNaN\n610.0\n70.6\n0.116\nNaN\n0.317439\nNaN\nNaN\n6.0\n...\n12.0\n29.5\n64.1\n339.0\n1700.0\nNaN\n17.1\n34.1\n25.6\n23.2\n\n\n1\n28-2014-paddy_rice.png\nNaN\n273.5\n27.8\n0.102\nNaN\n0.840806\nNaN\nNaN\n5.0\n...\n12.0\n19.6\n30.3\n217.0\n660.0\n12.2\nNaN\nNaN\nNaN\nNaN\n\n\n2\n33-2014-paddy_rice.png\nNaN\n28.1\n3.6\n0.127\nNaN\n0.387556\nNaN\nNaN\n6.0\n...\n12.0\n13.8\n38.1\n96.1\n640.0\n6.8\nNaN\nNaN\nNaN\nNaN\n\n\n3\n35-2014-paddy_rice.png\nNaN\n897.8\n71.4\n0.080\nNaN\n0.538391\nNaN\nNaN\n5.0\n...\n12.0\n15.4\n16.2\n119.0\n640.0\n34.2\nNaN\nNaN\nNaN\nNaN\n\n\n4\n36-2014-paddy_rice.png\nNaN\n964.3\n90.6\n0.094\nNaN\n0.792981\nNaN\nNaN\n5.0\n...\n12.0\n17.7\n19.9\n151.0\n610.0\n40.0\nNaN\nNaN\nNaN\nNaN\n\n\n\n\n5 rows × 22 columns\n\n\n\n\nidx = 6\ndf.columns[idx]\n\n'soil_ex_K2O'\n\n\n\ndata = stratified_split(df,  df.columns[idx], valid_size=0.2, test_size=0.2, num_bins=2)\ntrain_df, train_idx, valid_df, valid_idx, test_df, test_idx = data\n\n\n# # Usage example:\n# splits = stratified_split(df, df.columns[idx], n_bins=4, n_splits=2, random_state=41)\n\n# # For train-validation split\n# train_idx, valid_idx = splits[0]\n\n# # For train-test split (if needed)\n# train_valid_idx, test_idx = splits[1]\n\n# # Create DataFrames\n# train_df = df.iloc[train_idx]\n# valid_df = df.iloc[valid_idx]\n# test_df = df.iloc[test_idx]\n\n\nlen(train_df), len(valid_df), len(test_df)\n\n(405, 102, 127)\n\n\n\ntest_df[['fname', df.columns[idx]]]\n\n\n\n\n\n\n\n\nfname\nsoil_ex_K2O\n\n\n\n\n195\n758-2014-soybean.png\n0.973526\n\n\n77\n166-2016-paddy_rice.png\n0.571297\n\n\n224\n888-2014-paddy_rice.png\n0.329727\n\n\n580\n2391-2020-paddy_rice.png\n0.519631\n\n\n10\n51-2015-paddy_rice.png\n0.204683\n\n\n...\n...\n...\n\n\n520\n2131-2018-paddy_rice.png\n0.473116\n\n\n321\n1352-2014-paddy_rice.png\n0.739718\n\n\n226\n908-2014-paddy_rice.png\n0.202951\n\n\n137\n250-2017-paddy_rice.png\n0.095101\n\n\n378\n1988-2018-paddy_rice.png\n0.089294\n\n\n\n\n127 rows × 2 columns\n\n\n\n\ntrain_df['soil_ex_K2O'].hist()\n\n\n\n\n\n\n\n\n\nvalid_df['soil_ex_K2O'].hist()\n\n\n\n\n\n\n\n\n\ntest_df['soil_ex_K2O'].hist()\n\n\n\n\n\n\n\n\n\ndef stratified_splitter(items):\n    return [train_idx, valid_idx]\n\n\nlen(train_idx), len(valid_idx), len(test_idx)\n\n(405, 102, 127)\n\n\n\ndblock = DataBlock(\n    blocks=(ImageBlock, RegressionBlock),\n    get_x=ColReader(0, pref='../../_data/fk-jumpei-tfm/im/'),\n    get_y=ColReader(6),\n    splitter=stratified_splitter,\n    item_tfms=[OrderedQuantize(n_valid=len(valid_idx))],\n    batch_tfms=[\n        OrderedRatioResize(224),\n        Normalize.from_stats(*imagenet_stats)\n    ]\n)\n\n\n# dblock = DataBlock(blocks=(ImageBlock, RegressionBlock),\n#                    get_x=ColReader(0, pref='../../_data/fk-jumpei-tfm/im/'),\n#                    get_y=ColReader(idx),\n#                    splitter=stratified_splitter,\n#                    batch_tfms=[RatioResize(224)],\n#                    item_tfms=[Quantize(n_valid=len(valid_idx))])\n\n# # dblock.summary(df)\n\n\ndls = dblock.dataloaders(df, bs=16)\n\n\ndls.train.n, dls.valid.n\n\n(405, 102)\n\n\n\ndls.show_batch(nrows=6, ncols=2, figsize=(12, 13))\n\n\n\n\n\n\n\n\n\n# learn = load_learner('./models/650-4000-epoch-25-lr-3e-3.pkl', cpu=True)\nlearn = load_learner('./models/unfrozen-epoch-30-lr-1.5e-3-12102024.pkl', cpu=True)\n# learn = load_learner('./models/frozen-epoch-30-lr-1.5e-3-12102024.pkl', cpu=True)\n\n\nlearn.dls = dls\n\n\n# learn.summary()\n\n\nlearn.freeze()\n\n\n# learn.model[-1][-1]\n\n\n# model = learn.model\n# last_layer = model[-1][-1]\n# new_layer = nn.Linear(in_features=last_layer.in_features, \n#                       out_features=last_layer.out_features, \n#                       bias=True)\n# new_layer.weight.data = last_layer.weight.data\n# if hasattr(last_layer, 'bias') and last_layer.bias is not None:\n#     new_layer.bias.data = last_layer.bias.data\n# learn.model[-1][-1] = new_layer\n\n\n# learn.model[-1][-1]\n\n\nlearn.lr_find()\n\n\n\n\n\n\n\n\nSuggestedLRs(valley=0.0003981071640737355)\n\n\n\n\n\n\n\n\n\n\nlearn.fit_one_cycle(20, 4e-4)\n\n\n\n\n\n\n    \n      \n      30.00% [6/20 02:14&lt;05:14]\n    \n    \n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nr2_score\ntime\n\n\n\n\n0\n0.085307\n0.063526\n-0.155087\n00:21\n\n\n1\n0.073202\n0.090788\n-0.650800\n00:21\n\n\n2\n0.064845\n0.056194\n-0.021780\n00:22\n\n\n3\n0.058440\n0.168733\n-2.068068\n00:22\n\n\n4\n0.057954\n0.169698\n-2.085604\n00:22\n\n\n5\n0.058297\n0.072166\n-0.312190\n00:24\n\n\n\n\n\n    \n      \n      0.00% [0/7 00:00&lt;?]\n    \n    \n\n\n\n---------------------------------------------------------------------------\nKeyboardInterrupt                         Traceback (most recent call last)\nCell In[287], line 1\n----&gt; 1 learn.fit_one_cycle(20, 4e-4)\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/fastai/callback/schedule.py:121, in fit_one_cycle(self, n_epoch, lr_max, div, div_final, pct_start, wd, moms, cbs, reset_opt, start_epoch)\n    118 lr_max = np.array([h['lr'] for h in self.opt.hypers])\n    119 scheds = {'lr': combined_cos(pct_start, lr_max/div, lr_max, lr_max/div_final),\n    120           'mom': combined_cos(pct_start, *(self.moms if moms is None else moms))}\n--&gt; 121 self.fit(n_epoch, cbs=ParamScheduler(scheds)+L(cbs), reset_opt=reset_opt, wd=wd, start_epoch=start_epoch)\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/fastai/learner.py:266, in Learner.fit(self, n_epoch, lr, wd, cbs, reset_opt, start_epoch)\n    264 self.opt.set_hypers(lr=self.lr if lr is None else lr)\n    265 self.n_epoch = n_epoch\n--&gt; 266 self._with_events(self._do_fit, 'fit', CancelFitException, self._end_cleanup)\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/fastai/learner.py:201, in Learner._with_events(self, f, event_type, ex, final)\n    200 def _with_events(self, f, event_type, ex, final=noop):\n--&gt; 201     try: self(f'before_{event_type}');  f()\n    202     except ex: self(f'after_cancel_{event_type}')\n    203     self(f'after_{event_type}');  final()\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/fastai/learner.py:255, in Learner._do_fit(self)\n    253 for epoch in range(self.n_epoch):\n    254     self.epoch=epoch\n--&gt; 255     self._with_events(self._do_epoch, 'epoch', CancelEpochException)\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/fastai/learner.py:201, in Learner._with_events(self, f, event_type, ex, final)\n    200 def _with_events(self, f, event_type, ex, final=noop):\n--&gt; 201     try: self(f'before_{event_type}');  f()\n    202     except ex: self(f'after_cancel_{event_type}')\n    203     self(f'after_{event_type}');  final()\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/fastai/learner.py:250, in Learner._do_epoch(self)\n    248 def _do_epoch(self):\n    249     self._do_epoch_train()\n--&gt; 250     self._do_epoch_validate()\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/fastai/learner.py:246, in Learner._do_epoch_validate(self, ds_idx, dl)\n    244 if dl is None: dl = self.dls[ds_idx]\n    245 self.dl = dl\n--&gt; 246 with torch.no_grad(): self._with_events(self.all_batches, 'validate', CancelValidException)\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/fastai/learner.py:201, in Learner._with_events(self, f, event_type, ex, final)\n    200 def _with_events(self, f, event_type, ex, final=noop):\n--&gt; 201     try: self(f'before_{event_type}');  f()\n    202     except ex: self(f'after_cancel_{event_type}')\n    203     self(f'after_{event_type}');  final()\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/fastai/learner.py:207, in Learner.all_batches(self)\n    205 def all_batches(self):\n    206     self.n_iter = len(self.dl)\n--&gt; 207     for o in enumerate(self.dl): self.one_batch(*o)\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/fastai/data/load.py:129, in DataLoader.__iter__(self)\n    127 self.before_iter()\n    128 self.__idxs=self.get_idxs() # called in context of main process (not workers/subprocesses)\n--&gt; 129 for b in _loaders[self.fake_l.num_workers==0](self.fake_l):\n    130     # pin_memory causes tuples to be converted to lists, so convert them back to tuples\n    131     if self.pin_memory and type(b) == list: b = tuple(b)\n    132     if self.device is not None: b = to_device(b, self.device)\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/torch/utils/data/dataloader.py:630, in _BaseDataLoaderIter.__next__(self)\n    627 if self._sampler_iter is None:\n    628     # TODO(https://github.com/pytorch/pytorch/issues/76750)\n    629     self._reset()  # type: ignore[call-arg]\n--&gt; 630 data = self._next_data()\n    631 self._num_yielded += 1\n    632 if self._dataset_kind == _DatasetKind.Iterable and \\\n    633         self._IterableDataset_len_called is not None and \\\n    634         self._num_yielded &gt; self._IterableDataset_len_called:\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/torch/utils/data/dataloader.py:673, in _SingleProcessDataLoaderIter._next_data(self)\n    671 def _next_data(self):\n    672     index = self._next_index()  # may raise StopIteration\n--&gt; 673     data = self._dataset_fetcher.fetch(index)  # may raise StopIteration\n    674     if self._pin_memory:\n    675         data = _utils.pin_memory.pin_memory(data, self._pin_memory_device)\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py:42, in _IterableDatasetFetcher.fetch(self, possibly_batched_index)\n     40         raise StopIteration\n     41 else:\n---&gt; 42     data = next(self.dataset_iter)\n     43 return self.collate_fn(data)\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/fastai/data/load.py:140, in DataLoader.create_batches(self, samps)\n    138 if self.dataset is not None: self.it = iter(self.dataset)\n    139 res = filter(lambda o:o is not None, map(self.do_item, samps))\n--&gt; 140 yield from map(self.do_batch, self.chunkify(res))\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/fastcore/basics.py:245, in chunked(it, chunk_sz, drop_last, n_chunks)\n    243 if not isinstance(it, Iterator): it = iter(it)\n    244 while True:\n--&gt; 245     res = list(itertools.islice(it, chunk_sz))\n    246     if res and (len(res)==chunk_sz or not drop_last): yield res\n    247     if len(res)&lt;chunk_sz: return\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/fastai/data/load.py:170, in DataLoader.do_item(self, s)\n    169 def do_item(self, s):\n--&gt; 170     try: return self.after_item(self.create_item(s))\n    171     except SkipItemException: return None\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/fastcore/transform.py:210, in Pipeline.__call__(self, o)\n--&gt; 210 def __call__(self, o): return compose_tfms(o, tfms=self.fs, split_idx=self.split_idx)\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/fastcore/transform.py:160, in compose_tfms(x, tfms, is_enc, reverse, **kwargs)\n    158 for f in tfms:\n    159     if not is_enc: f = f.decode\n--&gt; 160     x = f(x, **kwargs)\n    161 return x\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/fastai/vision/augment.py:51, in RandTransform.__call__(self, b, split_idx, **kwargs)\n     45 def __call__(self, \n     46     b, \n     47     split_idx:int=None, # Index of the train/valid dataset\n     48     **kwargs\n     49 ):\n     50     self.before_call(b, split_idx=split_idx)\n---&gt; 51     return super().__call__(b, split_idx=split_idx, **kwargs) if self.do else b\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/fastcore/transform.py:83, in Transform.__call__(self, x, **kwargs)\n---&gt; 83 def __call__(self, x, **kwargs): return self._call('encodes', x, **kwargs)\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/fastcore/transform.py:93, in Transform._call(self, fn, x, split_idx, **kwargs)\n     91 def _call(self, fn, x, split_idx=None, **kwargs):\n     92     if split_idx!=self.split_idx and self.split_idx is not None: return x\n---&gt; 93     return self._do_call(getattr(self, fn), x, **kwargs)\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/fastcore/transform.py:100, in Transform._do_call(self, f, x, **kwargs)\n     98     ret = f.returns(x) if hasattr(f,'returns') else None\n     99     return retain_type(f(x, **kwargs), x, ret)\n--&gt; 100 res = tuple(self._do_call(f, x_, **kwargs) for x_ in x)\n    101 return retain_type(res, x)\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/fastcore/transform.py:100, in &lt;genexpr&gt;(.0)\n     98     ret = f.returns(x) if hasattr(f,'returns') else None\n     99     return retain_type(f(x, **kwargs), x, ret)\n--&gt; 100 res = tuple(self._do_call(f, x_, **kwargs) for x_ in x)\n    101 return retain_type(res, x)\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/fastcore/transform.py:99, in Transform._do_call(self, f, x, **kwargs)\n     97     if f is None: return x\n     98     ret = f.returns(x) if hasattr(f,'returns') else None\n---&gt; 99     return retain_type(f(x, **kwargs), x, ret)\n    100 res = tuple(self._do_call(f, x_, **kwargs) for x_ in x)\n    101 return retain_type(res, x)\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/fastcore/dispatch.py:122, in TypeDispatch.__call__(self, *args, **kwargs)\n    120 elif self.inst is not None: f = MethodType(f, self.inst)\n    121 elif self.owner is not None: f = MethodType(f, self.owner)\n--&gt; 122 return f(*args, **kwargs)\n\nFile ~/pro/dev/uhina/uhina/augment.py:50, in Quantize.encodes(self, x)\n     48 im_tensor = image2tensor(x)[0, :, :]\n     49 percentiles = self.get_percentiles()\n---&gt; 50 levels = torch.quantile(im_tensor.float(), percentiles / 100)\n     51 im_quant = torch.bucketize(im_tensor.float(), levels)\n     53 cmap = plt.get_cmap('Spectral_r')\n\nKeyboardInterrupt: \n\n\n\n\nval_preds, val_targets = learn.get_preds(dl=dls.valid)\nr2_score(val_targets, val_preds)\n\n\n\n\n\n\n\n\n0.23469541349548861\n\n\n\nlearn.unfreeze()\n\n\nlearn.lr_find()\n\n\n\n\n\n\n\n\nSuggestedLRs(valley=5.248074739938602e-05)\n\n\n\n\n\n\n\n\n\n\n# learn.fit_one_cycle(20, slice(1e-5, 1.5e-3))\nlearn.fit_one_cycle(20, 1.5e-3)\n\n\n\n\n\n\n    \n      \n      15.00% [3/20 01:05&lt;06:11]\n    \n    \n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nr2_score\ntime\n\n\n\n\n0\n0.043800\n0.053276\n0.031285\n00:22\n\n\n1\n0.046924\n0.054486\n0.009281\n00:21\n\n\n2\n0.051729\n0.184493\n-2.354623\n00:21\n\n\n\n\n\n    \n      \n      16.00% [4/25 00:03&lt;00:16 0.0514]\n    \n    \n\n\n\n---------------------------------------------------------------------------\nKeyboardInterrupt                         Traceback (most recent call last)\nCell In[183], line 2\n      1 # learn.fit_one_cycle(20, slice(1e-5, 1.5e-3))\n----&gt; 2 learn.fit_one_cycle(20, 1.5e-3)\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/fastai/callback/schedule.py:121, in fit_one_cycle(self, n_epoch, lr_max, div, div_final, pct_start, wd, moms, cbs, reset_opt, start_epoch)\n    118 lr_max = np.array([h['lr'] for h in self.opt.hypers])\n    119 scheds = {'lr': combined_cos(pct_start, lr_max/div, lr_max, lr_max/div_final),\n    120           'mom': combined_cos(pct_start, *(self.moms if moms is None else moms))}\n--&gt; 121 self.fit(n_epoch, cbs=ParamScheduler(scheds)+L(cbs), reset_opt=reset_opt, wd=wd, start_epoch=start_epoch)\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/fastai/learner.py:266, in Learner.fit(self, n_epoch, lr, wd, cbs, reset_opt, start_epoch)\n    264 self.opt.set_hypers(lr=self.lr if lr is None else lr)\n    265 self.n_epoch = n_epoch\n--&gt; 266 self._with_events(self._do_fit, 'fit', CancelFitException, self._end_cleanup)\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/fastai/learner.py:201, in Learner._with_events(self, f, event_type, ex, final)\n    200 def _with_events(self, f, event_type, ex, final=noop):\n--&gt; 201     try: self(f'before_{event_type}');  f()\n    202     except ex: self(f'after_cancel_{event_type}')\n    203     self(f'after_{event_type}');  final()\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/fastai/learner.py:255, in Learner._do_fit(self)\n    253 for epoch in range(self.n_epoch):\n    254     self.epoch=epoch\n--&gt; 255     self._with_events(self._do_epoch, 'epoch', CancelEpochException)\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/fastai/learner.py:201, in Learner._with_events(self, f, event_type, ex, final)\n    200 def _with_events(self, f, event_type, ex, final=noop):\n--&gt; 201     try: self(f'before_{event_type}');  f()\n    202     except ex: self(f'after_cancel_{event_type}')\n    203     self(f'after_{event_type}');  final()\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/fastai/learner.py:249, in Learner._do_epoch(self)\n    248 def _do_epoch(self):\n--&gt; 249     self._do_epoch_train()\n    250     self._do_epoch_validate()\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/fastai/learner.py:241, in Learner._do_epoch_train(self)\n    239 def _do_epoch_train(self):\n    240     self.dl = self.dls.train\n--&gt; 241     self._with_events(self.all_batches, 'train', CancelTrainException)\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/fastai/learner.py:201, in Learner._with_events(self, f, event_type, ex, final)\n    200 def _with_events(self, f, event_type, ex, final=noop):\n--&gt; 201     try: self(f'before_{event_type}');  f()\n    202     except ex: self(f'after_cancel_{event_type}')\n    203     self(f'after_{event_type}');  final()\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/fastai/learner.py:207, in Learner.all_batches(self)\n    205 def all_batches(self):\n    206     self.n_iter = len(self.dl)\n--&gt; 207     for o in enumerate(self.dl): self.one_batch(*o)\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/fastai/learner.py:237, in Learner.one_batch(self, i, b)\n    235 b = self._set_device(b)\n    236 self._split(b)\n--&gt; 237 self._with_events(self._do_one_batch, 'batch', CancelBatchException)\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/fastai/learner.py:203, in Learner._with_events(self, f, event_type, ex, final)\n    201 try: self(f'before_{event_type}');  f()\n    202 except ex: self(f'after_cancel_{event_type}')\n--&gt; 203 self(f'after_{event_type}');  final()\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/fastai/learner.py:174, in Learner.__call__(self, event_name)\n--&gt; 174 def __call__(self, event_name): L(event_name).map(self._call_one)\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/fastcore/foundation.py:159, in L.map(self, f, *args, **kwargs)\n--&gt; 159 def map(self, f, *args, **kwargs): return self._new(map_ex(self, f, *args, gen=False, **kwargs))\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/fastcore/basics.py:899, in map_ex(iterable, f, gen, *args, **kwargs)\n    897 res = map(g, iterable)\n    898 if gen: return res\n--&gt; 899 return list(res)\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/fastcore/basics.py:884, in bind.__call__(self, *args, **kwargs)\n    882     if isinstance(v,_Arg): kwargs[k] = args.pop(v.i)\n    883 fargs = [args[x.i] if isinstance(x, _Arg) else x for x in self.pargs] + args[self.maxi+1:]\n--&gt; 884 return self.func(*fargs, **kwargs)\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/fastai/learner.py:178, in Learner._call_one(self, event_name)\n    176 def _call_one(self, event_name):\n    177     if not hasattr(event, event_name): raise Exception(f'missing {event_name}')\n--&gt; 178     for cb in self.cbs.sorted('order'): cb(event_name)\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/fastai/callback/core.py:62, in Callback.__call__(self, event_name)\n     60 res = None\n     61 if self.run and _run: \n---&gt; 62     try: res = getcallable(self, event_name)()\n     63     except (CancelBatchException, CancelBackwardException, CancelEpochException, CancelFitException, CancelStepException, CancelTrainException, CancelValidException): raise\n     64     except Exception as e: raise modify_exception(e, f'Exception occured in `{self.__class__.__name__}` when calling event `{event_name}`:\\n\\t{e.args[0]}', replace=True)\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/fastai/learner.py:562, in Recorder.after_batch(self)\n    560 if len(self.yb) == 0: return\n    561 mets = self._train_mets if self.training else self._valid_mets\n--&gt; 562 for met in mets: met.accumulate(self.learn)\n    563 if not self.training: return\n    564 self.lrs.append(self.opt.hypers[-1]['lr'])\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/fastai/learner.py:511, in AvgSmoothLoss.accumulate(self, learn)\n    509 def accumulate(self, learn):\n    510     self.count += 1\n--&gt; 511     self.val = torch.lerp(to_detach(learn.loss.mean()), self.val, self.beta)\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/fastai/torch_core.py:246, in to_detach(b, cpu, gather)\n    244     if gather: x = maybe_gather(x)\n    245     return x.cpu() if cpu else x\n--&gt; 246 return apply(_inner, b, cpu=cpu, gather=gather)\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/fastai/torch_core.py:226, in apply(func, x, *args, **kwargs)\n    224 if is_listy(x): return type(x)([apply(func, o, *args, **kwargs) for o in x])\n    225 if isinstance(x,(dict,MutableMapping)): return {k: apply(func, v, *args, **kwargs) for k,v in x.items()}\n--&gt; 226 res = func(x, *args, **kwargs)\n    227 return res if x is None else retain_type(res, x)\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/fastai/torch_core.py:245, in to_detach.&lt;locals&gt;._inner(x, cpu, gather)\n    243 x = x.detach()\n    244 if gather: x = maybe_gather(x)\n--&gt; 245 return x.cpu() if cpu else x\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/fastai/torch_core.py:384, in TensorBase.__torch_function__(cls, func, types, args, kwargs)\n    382 if cls.debug and func.__name__ not in ('__str__','__repr__'): print(func, types, args, kwargs)\n    383 if _torch_handled(args, cls._opt, func): types = (torch.Tensor,)\n--&gt; 384 res = super().__torch_function__(func, types, args, ifnone(kwargs, {}))\n    385 dict_objs = _find_args(args) if args else _find_args(list(kwargs.values()))\n    386 if issubclass(type(res),TensorBase) and dict_objs: res.set_meta(dict_objs[0],as_copy=True)\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/torch/_tensor.py:1437, in Tensor.__torch_function__(cls, func, types, args, kwargs)\n   1434     return NotImplemented\n   1436 with _C.DisableTorchFunctionSubclass():\n-&gt; 1437     ret = func(*args, **kwargs)\n   1438     if func in get_default_nowrap_functions():\n   1439         return ret\n\nKeyboardInterrupt: \n\n\n\n\nval_preds, val_targets = learn.get_preds(dl=dls.valid)\nr2_score(val_targets, val_preds)\n\n\n\n\n\n\n\n\n0.36861295616974843\n\n\n\nEvaluate fine-tuned model\n\nlen(test_df)\n\n127\n\n\n\ndblock = DataBlock(blocks=(ImageBlock, RegressionBlock),\n                   get_x=ColReader(0, pref='../../_data/fk-jumpei-tfm/im/'),\n                   get_y=ColReader(idx),\n                   splitter=RandomSplitter(valid_pct=0, seed=41),\n                   batch_tfms=[RatioResize(224)],\n                   item_tfms=[Quantize(n_valid=len(test_df))])\n\ndls = dblock.dataloaders(test_df, bs=len(test_df))\n\n\nval_preds, val_targets = learn.get_preds(dl=dls.train)\n\n\n\n\n\n\n\n\n\nr2_score(val_targets, val_preds)\n\n-0.012676790057743803\n\n\n\nval_preds, val_targets = learn.tta(dl=dls.train, n=30)\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n---------------------------------------------------------------------------\nKeyboardInterrupt                         Traceback (most recent call last)\nCell In[120], line 1\n----&gt; 1 val_preds, val_targets = learn.tta(dl=dls.train, n=30)\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/fastai/learner.py:678, in tta(self, ds_idx, dl, n, item_tfms, batch_tfms, beta, use_max)\n    676     for i in self.progress.mbar if hasattr(self,'progress') else range(n):\n    677         self.epoch = i #To keep track of progress on mbar since the progress callback will use self.epoch\n--&gt; 678         aug_preds.append(self.get_preds(dl=dl, inner=True)[0][None])\n    679 aug_preds = torch.cat(aug_preds)\n    680 aug_preds = aug_preds.max(0)[0] if use_max else aug_preds.mean(0)\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/fastai/learner.py:310, in Learner.get_preds(self, ds_idx, dl, with_input, with_decoded, with_loss, act, inner, reorder, cbs, **kwargs)\n    308 if with_loss: ctx_mgrs.append(self.loss_not_reduced())\n    309 with ContextManagers(ctx_mgrs):\n--&gt; 310     self._do_epoch_validate(dl=dl)\n    311     if act is None: act = getcallable(self.loss_func, 'activation')\n    312     res = cb.all_tensors()\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/fastai/learner.py:246, in Learner._do_epoch_validate(self, ds_idx, dl)\n    244 if dl is None: dl = self.dls[ds_idx]\n    245 self.dl = dl\n--&gt; 246 with torch.no_grad(): self._with_events(self.all_batches, 'validate', CancelValidException)\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/fastai/learner.py:201, in Learner._with_events(self, f, event_type, ex, final)\n    200 def _with_events(self, f, event_type, ex, final=noop):\n--&gt; 201     try: self(f'before_{event_type}');  f()\n    202     except ex: self(f'after_cancel_{event_type}')\n    203     self(f'after_{event_type}');  final()\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/fastai/learner.py:207, in Learner.all_batches(self)\n    205 def all_batches(self):\n    206     self.n_iter = len(self.dl)\n--&gt; 207     for o in enumerate(self.dl): self.one_batch(*o)\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/fastai/data/load.py:129, in DataLoader.__iter__(self)\n    127 self.before_iter()\n    128 self.__idxs=self.get_idxs() # called in context of main process (not workers/subprocesses)\n--&gt; 129 for b in _loaders[self.fake_l.num_workers==0](self.fake_l):\n    130     # pin_memory causes tuples to be converted to lists, so convert them back to tuples\n    131     if self.pin_memory and type(b) == list: b = tuple(b)\n    132     if self.device is not None: b = to_device(b, self.device)\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/torch/utils/data/dataloader.py:630, in _BaseDataLoaderIter.__next__(self)\n    627 if self._sampler_iter is None:\n    628     # TODO(https://github.com/pytorch/pytorch/issues/76750)\n    629     self._reset()  # type: ignore[call-arg]\n--&gt; 630 data = self._next_data()\n    631 self._num_yielded += 1\n    632 if self._dataset_kind == _DatasetKind.Iterable and \\\n    633         self._IterableDataset_len_called is not None and \\\n    634         self._num_yielded &gt; self._IterableDataset_len_called:\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/torch/utils/data/dataloader.py:673, in _SingleProcessDataLoaderIter._next_data(self)\n    671 def _next_data(self):\n    672     index = self._next_index()  # may raise StopIteration\n--&gt; 673     data = self._dataset_fetcher.fetch(index)  # may raise StopIteration\n    674     if self._pin_memory:\n    675         data = _utils.pin_memory.pin_memory(data, self._pin_memory_device)\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py:42, in _IterableDatasetFetcher.fetch(self, possibly_batched_index)\n     40         raise StopIteration\n     41 else:\n---&gt; 42     data = next(self.dataset_iter)\n     43 return self.collate_fn(data)\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/fastai/data/load.py:140, in DataLoader.create_batches(self, samps)\n    138 if self.dataset is not None: self.it = iter(self.dataset)\n    139 res = filter(lambda o:o is not None, map(self.do_item, samps))\n--&gt; 140 yield from map(self.do_batch, self.chunkify(res))\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/fastcore/basics.py:245, in chunked(it, chunk_sz, drop_last, n_chunks)\n    243 if not isinstance(it, Iterator): it = iter(it)\n    244 while True:\n--&gt; 245     res = list(itertools.islice(it, chunk_sz))\n    246     if res and (len(res)==chunk_sz or not drop_last): yield res\n    247     if len(res)&lt;chunk_sz: return\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/fastai/data/load.py:170, in DataLoader.do_item(self, s)\n    169 def do_item(self, s):\n--&gt; 170     try: return self.after_item(self.create_item(s))\n    171     except SkipItemException: return None\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/fastcore/transform.py:210, in Pipeline.__call__(self, o)\n--&gt; 210 def __call__(self, o): return compose_tfms(o, tfms=self.fs, split_idx=self.split_idx)\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/fastcore/transform.py:160, in compose_tfms(x, tfms, is_enc, reverse, **kwargs)\n    158 for f in tfms:\n    159     if not is_enc: f = f.decode\n--&gt; 160     x = f(x, **kwargs)\n    161 return x\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/fastai/vision/augment.py:51, in RandTransform.__call__(self, b, split_idx, **kwargs)\n     45 def __call__(self, \n     46     b, \n     47     split_idx:int=None, # Index of the train/valid dataset\n     48     **kwargs\n     49 ):\n     50     self.before_call(b, split_idx=split_idx)\n---&gt; 51     return super().__call__(b, split_idx=split_idx, **kwargs) if self.do else b\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/fastcore/transform.py:83, in Transform.__call__(self, x, **kwargs)\n---&gt; 83 def __call__(self, x, **kwargs): return self._call('encodes', x, **kwargs)\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/fastcore/transform.py:93, in Transform._call(self, fn, x, split_idx, **kwargs)\n     91 def _call(self, fn, x, split_idx=None, **kwargs):\n     92     if split_idx!=self.split_idx and self.split_idx is not None: return x\n---&gt; 93     return self._do_call(getattr(self, fn), x, **kwargs)\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/fastcore/transform.py:100, in Transform._do_call(self, f, x, **kwargs)\n     98     ret = f.returns(x) if hasattr(f,'returns') else None\n     99     return retain_type(f(x, **kwargs), x, ret)\n--&gt; 100 res = tuple(self._do_call(f, x_, **kwargs) for x_ in x)\n    101 return retain_type(res, x)\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/fastcore/transform.py:100, in &lt;genexpr&gt;(.0)\n     98     ret = f.returns(x) if hasattr(f,'returns') else None\n     99     return retain_type(f(x, **kwargs), x, ret)\n--&gt; 100 res = tuple(self._do_call(f, x_, **kwargs) for x_ in x)\n    101 return retain_type(res, x)\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/fastcore/transform.py:99, in Transform._do_call(self, f, x, **kwargs)\n     97     if f is None: return x\n     98     ret = f.returns(x) if hasattr(f,'returns') else None\n---&gt; 99     return retain_type(f(x, **kwargs), x, ret)\n    100 res = tuple(self._do_call(f, x_, **kwargs) for x_ in x)\n    101 return retain_type(res, x)\n\nFile ~/mambaforge/envs/uhina/lib/python3.12/site-packages/fastcore/dispatch.py:122, in TypeDispatch.__call__(self, *args, **kwargs)\n    120 elif self.inst is not None: f = MethodType(f, self.inst)\n    121 elif self.owner is not None: f = MethodType(f, self.owner)\n--&gt; 122 return f(*args, **kwargs)\n\nFile ~/pro/dev/uhina/uhina/augment.py:51, in Quantize.encodes(self, x)\n     49 percentiles = self.get_percentiles()\n     50 levels = torch.quantile(im_tensor.float(), percentiles / 100)\n---&gt; 51 im_quant = torch.bucketize(im_tensor.float(), levels)\n     53 cmap = plt.get_cmap('Spectral_r')\n     54 im_color = tensor(cmap(im_quant.float() / im_quant.max())[:,:,:3])\n\nKeyboardInterrupt: \n\n\n\n\nnp.c_[val_preds, val_targets][:10]\n\narray([[0.6631091 , 0.7696582 ],\n       [0.45307112, 0.5359099 ],\n       [0.28646332, 0.25363058],\n       [0.891094  , 0.96547544],\n       [0.47445062, 0.54948056],\n       [1.4899724 , 1.4513922 ],\n       [0.3082603 , 0.25363058],\n       [0.41703525, 0.27481836],\n       [0.42921203, 0.4435868 ],\n       [0.77836686, 0.80633885]], dtype=float32)\n\n\n\nx, y = val_preds, val_targets\nplt.plot(x, y, '.')\n# Add the diagonal line\nmin_val = min(y.min(), x.min())\nmax_val = max(y.max(), x.max())\nplt.plot([min_val, max_val], [min_val, max_val], 'k--', lw=1)\n\n\n\n\n\n\n\n\n\nr2_score(val_targets, val_preds)\n\n0.8264008364793762\n\n\n\n\nOn single images\n\ndef predict_with_transforms(learn, img_path, n_predictions=5):\n    # Load the image\n    img = PILImage.create(img_path)\n    \n    # Create instances of the transforms\n    ratio_resize = RatioResize(224)\n    quantize = Quantize()\n    \n    predictions = []\n    for _ in range(n_predictions):\n        # Apply transforms\n        img_resized = ratio_resize(img)\n        img_quantized = quantize(img_resized)\n        \n        # Predict\n        pred, _, _ = learn.predict(img_quantized)\n        predictions.append(pred[0])\n    \n    from statistics import mode\n    # Calculate mean and standard deviation\n    mean_pred = np.mean(predictions)\n    std_pred = np.std(predictions)\n    median_pred = np.median(predictions)\n    mode_pred = mode(predictions)\n    return mean_pred, std_pred, median_pred, mode_pred, predictions\n\n\ntest_df[['fname', df.columns[idx]]]\n\n\n\n\n\n\n\n\nfname\nsoil_ex_K2O\n\n\n\n\n217\n859-2014-paddy_rice.png\n0.539629\n\n\n163\n278-2018-paddy_rice.png\n0.341865\n\n\n243\n968-2014-paddy_rice.png\n0.578465\n\n\n467\n2076-2018-paddy_rice.png\n0.338844\n\n\n513\n2123-2018-paddy_rice.png\n1.048431\n\n\n...\n...\n...\n\n\n605\n2419-2020-paddy_rice.png\n0.274818\n\n\n352\n1473-2014-paddy_rice.png\n0.407526\n\n\n0\n20-2013-paddy_rice.png\n0.317439\n\n\n355\n1477-2014-paddy_rice.png\n0.337330\n\n\n424\n2033-2018-buckwheat.png\n0.806339\n\n\n\n\n127 rows × 2 columns\n\n\n\n\nlearn.predict('/Users/franckalbinet/pro/dev/uhina/_data/fk-jumpei-tfm/im/859-2014-paddy_rice.png')\n\n\n\n\n\n\n\n\n((0.5223042368888855,), tensor([0.5223]), tensor([0.5223]))\n\n\n\ndef predict_with_tta_histogram(learn, img_path, n_tta=30):\n    # Load the image\n    img = PILImage.create(img_path)\n    \n    # Create a test DataLoader with a single image\n    test_dl = learn.dls.test_dl([img])\n    \n    # Collect predictions\n    all_preds = []\n    for _ in range(n_tta):\n        # Get prediction with TTA (n=1 for a single augmentation each time)\n        preds, _ = learn.tta(dl=test_dl, n=1)\n        all_preds.append(preds[0][0].item())  # Assuming single output\n    \n    all_preds = np.array(all_preds)\n    \n    # Calculate statistics\n    mean_pred = np.mean(all_preds)\n    std_pred = np.std(all_preds)\n    median_pred = np.median(all_preds)\n    min_pred = np.min(all_preds)\n    max_pred = np.max(all_preds)\n    \n    return mean_pred, std_pred, median_pred, min_pred, max_pred, all_preds\n\n\n# Use the function\nfname = '859-2014-paddy_rice.png'\nimg_path = Path('/Users/franckalbinet/pro/dev/uhina/_data/fk-jumpei-tfm/im/') / fname\nmean, std, median, min_pred, max_pred, all_preds = predict_with_tta_histogram(learn, img_path, n_tta=30)\n\nprint(f\"Min prediction: {min_pred:.4f}\")\nprint(f\"Max prediction: {max_pred:.4f}\")\nprint(f\"Mean prediction: {mean:.4f}\")\nprint(f\"Standard deviation: {std:.4f}\")\nprint(f\"Median prediction: {median:.4f}\")\nprint(f\"All predictions: {all_preds}\")\n\n# If you want to compare with the ground truth\nprint('Ground truth:', df[df.fname == fname][df.columns[idx]].values[0])\n\n# Plot histogram\nplt.hist(all_preds, bins=10)\nplt.title('Histogram of TTA Predictions')\nplt.xlabel('Predicted Value')\nplt.ylabel('Frequency')\nplt.show()\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\nMin prediction: 0.4531\nMax prediction: 0.5795\nMean prediction: 0.5275\nStandard deviation: 0.0282\nMedian prediction: 0.5272\nAll predictions: [0.54436386 0.55598998 0.56092638 0.57104981 0.52798319 0.57950228\n 0.50701064 0.52194297 0.51890564 0.53010362 0.50141889 0.53311121\n 0.51312613 0.53879243 0.50901508 0.51508129 0.54903734 0.51155448\n 0.53831923 0.50822324 0.52851534 0.57572448 0.51641762 0.51522946\n 0.45307761 0.52632904 0.53577548 0.56359959 0.51006508 0.46458086]\nGround truth: 0.5396292928049117\n\n\n\n\n\n\n\n\n\n\n# Canonical fine-tuning\n# from fastai.vision.all import *\n\n# # Load the pretrained model\n# learn = load_learner('./models/650-4000-epoch-25-lr-3e-3.pkl', cpu=False)\n\n# # Prepare your new data\n# path = 'path/to/your/data'\n# dls = ImageDataLoaders.from_folder(path, valid_pct=0.2, item_tfms=Resize(224), batch_tfms=aug_transforms())\n\n# # Set the new data\n# learn.dls = dls\n\n# # Fine-tune the head of the model\n# learn.freeze()\n# # alternatively: learn.freeze_to(n)\n# learn.lr_find()\n# learn.fit_one_cycle(5, 3e-3)\n\n# # Fine-tune the entire model\n# learn.unfreeze()\n# learn.lr_find()\n# learn.fit_one_cycle(5, slice(1e-5, 1e-3))\n\n\n# learn = vision_learner(dls, resnet18, pretrained=False, metrics=R2Score()).to_fp16()\n\n\n# learn.lr_find()\n\n\n# learn.lr_find()\n\n\n\n\n\n\n\n\nSuggestedLRs(valley=0.002511886414140463)\n\n\n\n\n\n\n\n\n\n\n# learn.fit_one_cycle(5, 3e-3)",
    "crumbs": [
      "example",
      "Fukushima Jumpei classic"
    ]
  },
  {
    "objectID": "example/fk-jumpei-classic.html#evaluation",
    "href": "example/fk-jumpei-classic.html#evaluation",
    "title": "Fukushima Jumpei classic",
    "section": "Evaluation",
    "text": "Evaluation\n\n# Convert predictions and targets to numpy arrays\ndef assess_model(val_preds, val_targets):\n    val_preds = val_preds.numpy().flatten()\n    val_targets = val_targets.numpy()\n\n    # Create a DataFrame with the results\n    results_df = pd.DataFrame({\n        'Predicted': val_preds,\n        'Actual': val_targets\n    })\n\n    # Display the first few rows of the results\n    print(results_df.head())\n\n    # Calculate and print the R2 score\n    from sklearn.metrics import r2_score\n    r2 = r2_score(val_targets, val_preds)\n    print(f\"R2 Score on validation set: {r2:.4f}\")\n\n\ndls.train.n\n\n69\n\n\n\nval_preds, val_targets = learn.get_preds(dl=dls.train)\nassess_model(val_preds, val_targets)\n\n\n\n\n\n\n\n\n   Predicted    Actual\n0   0.046272  0.210804\n1   0.528189  0.976900\n2   0.465372  0.469860\n3   0.258100  0.338556\n4   0.112802  0.147696\nR2 Score on validation set: 0.7392\n\n\n\nval_preds, val_targets = learn.get_preds(dl=dls.train)\nr2 = r2_score(val_targets, val_preds); r2\n\n\nr2 = r2_score(val_targets, val_preds); r2\n\n0.7391959435205914\n\n\n\nscores = []\nfor n in range(1, 20):\n    val_preds, val_targets = learn.tta(dl=dls.train, n=n)\n    scores.append(r2_score(val_targets, val_preds))\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n\nx = list(range(1, 20))\nplt.plot(x, scores)\n\n\n\n\n\n\n\n\n\n# EXAMPLE of TTA on single item\n# from fastai.vision.all import *\n\n# # Define your TTA transforms\n# tta_tfms = [\n#     RandomResizedCrop(224, min_scale=0.5),\n#     Flip(),\n#     Rotate(degrees=(-15, 15)),\n#     Brightness(max_lighting=0.2),\n#     Contrast(max_lighting=0.2)\n# ]\n\n# # Create a pipeline of TTA transformations\n# tta_pipeline = Pipeline(tta_tfms)\n\n# # Load your model\n# learn = load_learner('path/to/your/model.pkl')\n\n# # Define the input data (e.g., an image)\n# input_data = PILImage.create('path/to/your/image.jpg')\n\n# # Apply TTA transforms to the input data and make predictions\n# predictions = []\n# for _ in range(5):  # Apply 5 different augmentations\n#     augmented_data = tta_pipeline(input_data)\n#     prediction = learn.predict(augmented_data)\n#     predictions.append(prediction)\n\n# # Average the predictions\n# average_prediction = sum(predictions) / len(predictions)\n\n# print(average_prediction)\n\n\n# Assuming you have a new CSV file for your test data\n# test_source = '../../_data/ossl-tfm/ossl-tfm-test.csv'\n# test_df = pd.read_csv(test_source)\n\n# # Create a new DataLoader for the test data\n# test_dl = learn.dls.test_dl(test_df)\n\n# # Get predictions on the test set\n# test_preds, test_targets = learn.get_preds(dl=test_dl)\n\n# # Now you can use test_preds and test_targets for further analysis\n\n\nassess_model(val_preds, val_targets)\n\n   Predicted    Actual\n0   0.312483  0.000000\n1   0.126990  0.184960\n2   0.365726  0.194201\n3   0.239089  0.262364\n4   0.402980  0.355799\nR2 Score on validation set: 0.8325\n\n\n\nassess_model(val_preds_tta, val_targets_tta)\n\n   Predicted    Actual\n0   0.246857  0.000000\n1   0.148590  0.184960\n2   0.371643  0.194201\n3   0.226535  0.262364\n4   0.407333  0.355799\nR2 Score on validation set: 0.8378\n\n\n\nval_preds_np = val_preds\nval_targets_np = val_targets\n\n# Apply the transformation: exp(y) - 1\nval_preds_transformed = np.exp(val_preds_np) - 1\nval_targets_transformed = np.exp(val_targets_np) - 1\n\n# Create a DataFrame with the results\nresults_df = pd.DataFrame({\n    'Predicted': val_preds_transformed,\n    'Actual': val_targets_transformed\n})\n\n# Display the first few rows of the results\nprint(results_df.head())\n\n# Calculate and print the R2 score\nfrom sklearn.metrics import r2_score\nr2 = r2_score(val_targets_transformed, val_preds_transformed)\nprint(f\"R2 Score on validation set (after transformation): {r2:.4f}\")\n\n# Calculate and print the MAPE, handling zero values\ndef mean_absolute_percentage_error(y_true, y_pred):\n    non_zero = (y_true != 0)\n    return np.mean(np.abs((y_true[non_zero] - y_pred[non_zero]) / y_true[non_zero])) * 100\n\nmape = mean_absolute_percentage_error(val_targets_transformed, val_preds_transformed)\nprint(f\"Mean Absolute Percentage Error (MAPE) on validation set: {mape:.2f}%\")\n\n# Calculate and print the MAE as an alternative metric\nfrom sklearn.metrics import mean_absolute_error\nmae = mean_absolute_error(val_targets_transformed, val_preds_transformed)\nprint(f\"Mean Absolute Error (MAE) on validation set: {mae:.4f}\")\n\n   Predicted   Actual\n0   0.366814  0.00000\n1   0.135405  0.20317\n2   0.441560  0.21434\n3   0.270092  0.30000\n4   0.496277  0.42732\nR2 Score on validation set (after transformation): 0.6936\nMean Absolute Percentage Error (MAPE) on validation set: 50.72%\nMean Absolute Error (MAE) on validation set: 0.1956\n\n\n\nplt.figure(figsize=(6, 6))\n\n# Use logarithmic bins for the colormap\nh = plt.hexbin(val_targets, val_preds, gridsize=65, \n               bins='log', cmap='Spectral_r', mincnt=1,\n               alpha=0.9)\n\n# Get the actual min and max counts from the hexbin data\ncounts = h.get_array()\nmin_count = counts[counts &gt; 0].min()  # Minimum non-zero count\nmax_count = counts.max()\n\n# Create a logarithmic colorbar\ncb = plt.colorbar(h, label='Count in bin', shrink=0.73)\ntick_locations = np.logspace(np.log10(min_count), np.log10(max_count), 5)\ncb.set_ticks(tick_locations)\ncb.set_ticklabels([f'{int(x)}' for x in tick_locations])\n\n# Add the diagonal line\nmin_val = min(val_targets.min(), val_preds.min())\nmax_val = max(val_targets.max(), val_preds.max())\nplt.plot([min_val, max_val], [min_val, max_val], 'k--', lw=1)\n\n# Set labels and title\nplt.xlabel('Actual Values')\nplt.ylabel('Predicted Values')\nplt.title('Predicted vs Actual Values (Hexbin with Log Scale)')\n\n# Add grid lines\nplt.grid(True, linestyle='--', alpha=0.65)\n\n# Set the same limits for both axes\nplt.xlim(min_val, max_val)\nplt.ylim(min_val, max_val)\n\n# Make the plot square\nplt.gca().set_aspect('equal', adjustable='box')\n\nplt.tight_layout()\nplt.show()\n\n# Print the range of counts in the hexbins\nprint(f\"Min non-zero count in hexbins: {min_count}\")\nprint(f\"Max count in hexbins: {max_count}\")\n\n\n\n\n\n\n\n\nMin non-zero count in hexbins: 1.0\nMax count in hexbins: 157.0\n\n\n\npath_model = Path('./models')\nlearn.export(path_model / '0.pkl')",
    "crumbs": [
      "example",
      "Fukushima Jumpei classic"
    ]
  },
  {
    "objectID": "example/fk-jumpei-classic.html#inference",
    "href": "example/fk-jumpei-classic.html#inference",
    "title": "Fukushima Jumpei classic",
    "section": "Inference",
    "text": "Inference\n\nossl_source = Path('../../_data/ossl-tfm/img')\nlearn.predict(ossl_source / '0a0a0c647671fd3030cc13ba5432eb88.png')\n\n\n\n\n\n\n\n\n((0.5229991674423218,), tensor([0.5230]), tensor([0.5230]))\n\n\n\ndf[df['fname'] == '0a0a0c647671fd3030cc13ba5432eb88.png']\n\n\n\n\n\n\n\n\nfname\nkex\n\n\n\n\n28867\n0a0a0c647671fd3030cc13ba5432eb88.png\n0.525379",
    "crumbs": [
      "example",
      "Fukushima Jumpei classic"
    ]
  },
  {
    "objectID": "example/history_runpod/fastai-bw-augment-03-10-2024.html",
    "href": "example/history_runpod/fastai-bw-augment-03-10-2024.html",
    "title": "Fastai BW data augmentation",
    "section": "",
    "text": "# Todo:\n#   - generate transformed OSSL dataset from 650-4000\n#   - retrained model on OSSL dataset using this wavenumber range\n#   - generate transformed ringtrial dataset\n#   - generate transformed Fukushima dataset",
    "crumbs": [
      "example",
      "history_runpod",
      "Fastai BW data augmentation"
    ]
  },
  {
    "objectID": "example/history_runpod/fastai-bw-augment-03-10-2024.html#runpod-setup",
    "href": "example/history_runpod/fastai-bw-augment-03-10-2024.html#runpod-setup",
    "title": "Fastai BW data augmentation",
    "section": "Runpod setup",
    "text": "Runpod setup\n\n# setting up pod and pip install uhina\n# accessing a pod terminal\n\n# 1. To get access to the pod ip adress: runpodctl get pod -a\n# 2. ssh into the pod: ssh root@&lt;ip-address&gt; -p 58871 -i ~/.ssh/id_ed25519\n\n# git clone https://github.com/franckalbinet/uhina.git\n# pip install uhina\n# runpodctl send im-bw \n# runpodctl send ossl-tfm.csv",
    "crumbs": [
      "example",
      "history_runpod",
      "Fastai BW data augmentation"
    ]
  },
  {
    "objectID": "example/history_runpod/fastai-bw-augment-03-10-2024.html#loading-data",
    "href": "example/history_runpod/fastai-bw-augment-03-10-2024.html#loading-data",
    "title": "Fastai BW data augmentation",
    "section": "Loading data",
    "text": "Loading data\n\nimport pandas as pd\nfrom pathlib import Path\n    import fastcore.all as fc\n\n    from fastai.data.all import *\n    from fastai.vision.all import *\nfrom multiprocessing import cpu_count\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\n\nossl_source = '../../_data/ossl-tfm/ossl-tfm.csv'\ndf = pd.read_csv(ossl_source); df.head()\n\n\n\n\n\n\n\n\nfname\nkex\n\n\n\n\n0\n3998362dd2659e2252cd7f38b43c9b1f.png\n0.182895\n\n\n1\n2bab4dbbac073b8648475ad50d40eb95.png\n0.082741\n\n\n2\n29213d2193232be8867d85dec463ec00.png\n0.089915\n\n\n3\n8b1ee9146c026faee20a40df86736864.png\n0.135030\n\n\n4\n6e8e9d1105e7da7055555cb5d310df5f.png\n0.270421\n\n\n\n\n\n\n\n\ndf['kex'].min(), df['kex'].max()\n\n(0.0, 3.6521352871126975)\n\n\n\n# image size is 750x281\n\n\n# start = np.random.uniform(1, 50); print(start)\n# end = np.random.uniform(90.1, 99.5); print(end)\n# steps = np.random.randint(5, 100); print(steps)\n# percentiles = torch.linspace(start=start, end=end, steps=steps)\n# percentiles\n\n\n@delegates()\nclass Quantize(RandTransform):\n    # split_idx,mode,mode_mask,order = None,BILINEAR,NEAREST,1\n    \"Quantize B&W image into `num_colors` colors.\"\n    split_idx = None\n    def __init__(self, \n        num_colors:int=10,\n        verbose:bool=False,\n        n_percentiles_valid:int=100, # how many different quantization to generate for valid set\n        seed:int|None=41, # Seed for random number generator used to generate fixed augmentation for validation set\n        **kwargs\n    ):\n        store_attr()\n        super().__init__(**kwargs)\n        self.counter_valid = 0\n        self.percentiles = None\n        self.percentiles_valid = self.generate_percentiles_valid(n=n_percentiles_valid, seed=self.seed)\n\n    def before_call(self, \n        b, \n        split_idx:int # Index of the train/valid dataset (0: train, 1: valid)\n    ):\n        self.idx = split_idx\n        \n    def get_random_percentiles(self, seed:int|None=None):\n        if seed is not None:\n            np.random.seed(seed)\n        start = np.random.uniform(1, 50)\n        \n        end = np.random.uniform(90.1, 99.5)\n        steps = np.random.randint(5, 100)\n        return torch.linspace(start=start, end=end, steps=steps)\n\n    def generate_percentiles_valid(self, n:int=100, seed:int|None=None):\n        return [self.get_random_percentiles(seed=self.seed) for i in range(n)]\n    \n    def get_percentiles(self):\n        if self.idx == 1:\n            return self.percentiles_valid[self.counter_valid%len(self.percentiles_valid)]\n        else:\n            return self.get_random_percentiles()\n    \n    def encodes(self, x:Image.Image):\n        im_tensor = image2tensor(x)[0, :, :]\n        \n        percentiles = self.get_percentiles()\n        levels = torch.quantile(im_tensor.float(), percentiles / 100)\n        im_quant = torch.bucketize(im_tensor.float(), levels)\n        \n        cmap = plt.get_cmap('Spectral_r')\n        im_color = tensor(cmap(im_quant.float() / im_quant.max())[:,:,:3])\n        im_color = im_color.permute(2, 0, 1)\n        return to_image(im_color)\n\n\n# Image.Image\nim_path = '../../_data/all-grey-255.png'\nim = PILImage.create(im_path)\n# type(im)\n# im = Image.open(im_path)\n# PILImageBW\n# fastai_im = PILImageBW(im_path) # fastai.vision.core.PILImage\n# fastai_im.show(figsize=(10,10))\n\nim = Quantize(verbose=False)(im)\nim\n\n\n\n\n\n\n\n\n\nim_path = '../../_data/all-grey-255.png'\nim = PILImage.create(im_path)\nprint(f'original shape: {im.shape}')\n\nim_tensor = image2tensor(im)\nprint(f'tensor shape: {im_tensor.shape} which is simply each pixel value replicated 3 times (R, G, B)')\n\nim_tensor = im_tensor[0, :, :]\nprint(f'tensor shape: {im_tensor.shape}')\n\npercentiles = torch.arange(40, 99, 1, dtype=torch.float32)\nprint(f'percentiles: {percentiles}')\n\nlevels = torch.quantile(im_tensor.float(), percentiles / 100)\nprint(f'levels: {levels}')\n\nim_quant = torch.bucketize(im_tensor.float(), levels)\nprint(f'im_quant: {im_quant}, # unique values: {im_quant.unique()}')\n\n# Color map: takes values between 0 and 1 and returns a color (RGBA)\ncmap = plt.get_cmap('Spectral_r')\n\nim_color = tensor(cmap(im_quant.float() / im_quant.max())[:,:,:3])\nprint(f'im_color shape: {im_color.shape}')\nim_color = im_color.permute(2, 0, 1)\nprint(f'im_color permuted to (C, H, W): {im_color.shape}')\nim_color_fastai = to_image(im_color)\nprint(f'im_color_fastai: {im_color_fastai}')\nim_color_fastai\n\noriginal shape: (221, 669)\ntensor shape: torch.Size([3, 221, 669]) which is simply each pixel value replicated 3 times (R, G, B)\ntensor shape: torch.Size([221, 669])\npercentiles: tensor([40., 41., 42., 43., 44., 45., 46., 47., 48., 49., 50., 51., 52., 53.,\n        54., 55., 56., 57., 58., 59., 60., 61., 62., 63., 64., 65., 66., 67.,\n        68., 69., 70., 71., 72., 73., 74., 75., 76., 77., 78., 79., 80., 81.,\n        82., 83., 84., 85., 86., 87., 88., 89., 90., 91., 92., 93., 94., 95.,\n        96., 97., 98.])\nlevels: tensor([182., 183., 185., 187., 189., 191., 192., 194., 195., 198., 200., 202.,\n        204., 206., 207., 209., 210., 211., 213., 214., 215., 216., 217., 218.,\n        219., 220., 220., 221., 222., 223., 224., 225., 226., 227., 229., 230.,\n        231., 232., 232., 233., 234., 235., 236., 237., 238., 238., 239., 240.,\n        240., 241., 241., 242., 243., 243., 243., 245., 246., 248., 250.])\nim_quant: tensor([[41, 41, 41,  ..., 46, 46, 46],\n        [41, 41, 41,  ..., 46, 46, 46],\n        [35, 36, 36,  ..., 44, 44, 44],\n        ...,\n        [10,  7,  0,  ...,  0,  0,  0],\n        [10,  7,  0,  ...,  0,  0,  0],\n        [10,  7,  0,  ...,  0,  0,  0]]), # unique values: tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n        18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36,\n        37, 39, 40, 41, 42, 43, 44, 46, 47, 49, 51, 52, 55, 56, 57, 58, 59])\nim_color shape: torch.Size([221, 669, 3])\nim_color permuted to (C, H, W): torch.Size([3, 221, 669])\nim_color_fastai: &lt;PIL.Image.Image image mode=RGB size=669x221&gt;\n\n\n\n\n\n\n\n\n\n\nossl = DataBlock(blocks=(ImageBlock, RegressionBlock),\n                get_x=ColReader(0, pref='../../_data/ossl-tfm/im/'),\n                get_y=ColReader(1),\n                # batch_tfms=Normalize.from_stats(*imagenet_stats),\n                batch_tfms=[RatioResize(224)],\n                item_tfms=[Quantize()],\n                splitter=RandomSplitter(valid_pct=0.1, seed=41)\n#    batch_tfms=aug_transforms()\n)\n\n\n# ossl.summary(df)\n\n\n#cpu_count()\n\n\n# dls = ossl.dataloaders(df, num_workers=cpu_count())\ndls = ossl.dataloaders(df)\n\n\ndls.show_batch(nrows=5, ncols=1, figsize=(10, 15))\n\n\n\n\n\n\n\n\n\n#learn = vision_learner(dls, resnet18, pretrained=False, metrics=R2Score()).to_fp16()\nlearn = vision_learner(dls, resnet18, pretrained=False, metrics=R2Score())\n\n\n#learn = load_learner('./models/bw-data-augment-0.pkl', cpu=True)\n\n\nlearn.lr_find()\n\n\n\n\n\n\n\n\nSuggestedLRs(valley=0.0030199517495930195)\n\n\n\n\n\n\n\n\n\n\nlearn.fit_one_cycle(25, 3e-3)\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nr2_score\ntime\n\n\n\n\n0\n0.965983\n0.168971\n-0.212750\n03:28\n\n\n1\n0.126813\n1.278555\n-8.176533\n03:28\n\n\n2\n0.092299\n0.075169\n0.460494\n03:33\n\n\n3\n0.079262\n0.058242\n0.581981\n03:41\n\n\n4\n0.073574\n0.072033\n0.482998\n03:48\n\n\n5\n0.063900\n0.046245\n0.668084\n03:37\n\n\n6\n0.051317\n0.041811\n0.699914\n03:46\n\n\n7\n0.042400\n0.035283\n0.746765\n03:34\n\n\n8\n0.041587\n0.035850\n0.742691\n04:01\n\n\n9\n0.039711\n0.034675\n0.751131\n04:08\n\n\n10\n0.036430\n0.032221\n0.768739\n04:04\n\n\n11\n0.034432\n0.031230\n0.775856\n03:49\n\n\n12\n0.029793\n0.029620\n0.787409\n03:40\n\n\n13\n0.029803\n0.028552\n0.795076\n03:47\n\n\n14\n0.027022\n0.029088\n0.791229\n03:51\n\n\n15\n0.025353\n0.030500\n0.781095\n03:53\n\n\n16\n0.023718\n0.026129\n0.812462\n03:33\n\n\n17\n0.021063\n0.024969\n0.820793\n03:33\n\n\n18\n0.019587\n0.024076\n0.827199\n03:30\n\n\n19\n0.017989\n0.023424\n0.831881\n03:33\n\n\n20\n0.016224\n0.023345\n0.832445\n03:30\n\n\n21\n0.015382\n0.022867\n0.835880\n03:28\n\n\n22\n0.015437\n0.023114\n0.834103\n03:34\n\n\n23\n0.015099\n0.022699\n0.837085\n03:31\n\n\n24\n0.013830\n0.022753\n0.836699\n03:35\n\n\n\n\n\n\npath_model = Path('./models')\nlearn.export(path_model / '650-4000-epoch-25-lr-3e-3.pkl')",
    "crumbs": [
      "example",
      "history_runpod",
      "Fastai BW data augmentation"
    ]
  },
  {
    "objectID": "example/history_runpod/fastai-bw-augment-03-10-2024.html#evaluation",
    "href": "example/history_runpod/fastai-bw-augment-03-10-2024.html#evaluation",
    "title": "Fastai BW data augmentation",
    "section": "Evaluation",
    "text": "Evaluation\n\nval_preds, val_targets = learn.get_preds(dl=dls.valid)\nassess_model(val_preds, val_targets)\n\n\n\n\n\n\n\n\n   Predicted    Actual\n0   0.277349  0.000000\n1   0.207959  0.184960\n2   0.495959  0.194201\n3   0.266406  0.262364\n4   0.373048  0.355799\nR2 Score on validation set: 0.8367\n\n\n\nval_preds_tta, val_targets_tta = learn.tta(dl=dls.valid, n=20)\nassess_model(val_preds_tta, val_targets_tta)\n\n\n\n\n\n\n    \n      \n      \n    \n    \n\n\n\n\n\n\n\n\n\n   Predicted    Actual\n0   0.231803  0.000000\n1   0.205699  0.184960\n2   0.468034  0.194201\n3   0.263332  0.262364\n4   0.381026  0.355799\nR2 Score on validation set: 0.8418\n\n\n\n# EXAMPLE of TTA on single item\n# from fastai.vision.all import *\n\n# # Define your TTA transforms\n# tta_tfms = [\n#     RandomResizedCrop(224, min_scale=0.5),\n#     Flip(),\n#     Rotate(degrees=(-15, 15)),\n#     Brightness(max_lighting=0.2),\n#     Contrast(max_lighting=0.2)\n# ]\n\n# # Create a pipeline of TTA transformations\n# tta_pipeline = Pipeline(tta_tfms)\n\n# # Load your model\n# learn = load_learner('path/to/your/model.pkl')\n\n# # Define the input data (e.g., an image)\n# input_data = PILImage.create('path/to/your/image.jpg')\n\n# # Apply TTA transforms to the input data and make predictions\n# predictions = []\n# for _ in range(5):  # Apply 5 different augmentations\n#     augmented_data = tta_pipeline(input_data)\n#     prediction = learn.predict(augmented_data)\n#     predictions.append(prediction)\n\n# # Average the predictions\n# average_prediction = sum(predictions) / len(predictions)\n\n# print(average_prediction)\n\n\n# Assuming you have a new CSV file for your test data\n# test_source = '../../_data/ossl-tfm/ossl-tfm-test.csv'\n# test_df = pd.read_csv(test_source)\n\n# # Create a new DataLoader for the test data\n# test_dl = learn.dls.test_dl(test_df)\n\n# # Get predictions on the test set\n# test_preds, test_targets = learn.get_preds(dl=test_dl)\n\n# # Now you can use test_preds and test_targets for further analysis\n\n\n# Convert predictions and targets to numpy arrays\ndef assess_model(val_preds, val_targets):\n    val_preds = val_preds.numpy().flatten()\n    val_targets = val_targets.numpy()\n\n    # Create a DataFrame with the results\n    results_df = pd.DataFrame({\n        'Predicted': val_preds,\n        'Actual': val_targets\n    })\n\n    # Display the first few rows of the results\n    print(results_df.head())\n\n    # Calculate and print the R2 score\n    from sklearn.metrics import r2_score\n    r2 = r2_score(val_targets, val_preds)\n    print(f\"R2 Score on validation set: {r2:.4f}\")\n\n\nassess_model(val_preds, val_targets)\n\n   Predicted    Actual\n0   0.312483  0.000000\n1   0.126990  0.184960\n2   0.365726  0.194201\n3   0.239089  0.262364\n4   0.402980  0.355799\nR2 Score on validation set: 0.8325\n\n\n\nassess_model(val_preds_tta, val_targets_tta)\n\n   Predicted    Actual\n0   0.246857  0.000000\n1   0.148590  0.184960\n2   0.371643  0.194201\n3   0.226535  0.262364\n4   0.407333  0.355799\nR2 Score on validation set: 0.8378\n\n\n\nval_preds_np = val_preds\nval_targets_np = val_targets\n\n# Apply the transformation: exp(y) - 1\nval_preds_transformed = np.exp(val_preds_np) - 1\nval_targets_transformed = np.exp(val_targets_np) - 1\n\n# Create a DataFrame with the results\nresults_df = pd.DataFrame({\n    'Predicted': val_preds_transformed,\n    'Actual': val_targets_transformed\n})\n\n# Display the first few rows of the results\nprint(results_df.head())\n\n# Calculate and print the R2 score\nfrom sklearn.metrics import r2_score\nr2 = r2_score(val_targets_transformed, val_preds_transformed)\nprint(f\"R2 Score on validation set (after transformation): {r2:.4f}\")\n\n# Calculate and print the MAPE, handling zero values\ndef mean_absolute_percentage_error(y_true, y_pred):\n    non_zero = (y_true != 0)\n    return np.mean(np.abs((y_true[non_zero] - y_pred[non_zero]) / y_true[non_zero])) * 100\n\nmape = mean_absolute_percentage_error(val_targets_transformed, val_preds_transformed)\nprint(f\"Mean Absolute Percentage Error (MAPE) on validation set: {mape:.2f}%\")\n\n# Calculate and print the MAE as an alternative metric\nfrom sklearn.metrics import mean_absolute_error\nmae = mean_absolute_error(val_targets_transformed, val_preds_transformed)\nprint(f\"Mean Absolute Error (MAE) on validation set: {mae:.4f}\")\n\n   Predicted   Actual\n0   0.366814  0.00000\n1   0.135405  0.20317\n2   0.441560  0.21434\n3   0.270092  0.30000\n4   0.496277  0.42732\nR2 Score on validation set (after transformation): 0.6936\nMean Absolute Percentage Error (MAPE) on validation set: 50.72%\nMean Absolute Error (MAE) on validation set: 0.1956\n\n\n\nplt.figure(figsize=(6, 6))\n\n# Use logarithmic bins for the colormap\nh = plt.hexbin(val_targets, val_preds, gridsize=65, \n               bins='log', cmap='Spectral_r', mincnt=1,\n               alpha=0.9)\n\n# Get the actual min and max counts from the hexbin data\ncounts = h.get_array()\nmin_count = counts[counts &gt; 0].min()  # Minimum non-zero count\nmax_count = counts.max()\n\n# Create a logarithmic colorbar\ncb = plt.colorbar(h, label='Count in bin', shrink=0.73)\ntick_locations = np.logspace(np.log10(min_count), np.log10(max_count), 5)\ncb.set_ticks(tick_locations)\ncb.set_ticklabels([f'{int(x)}' for x in tick_locations])\n\n# Add the diagonal line\nmin_val = min(val_targets.min(), val_preds.min())\nmax_val = max(val_targets.max(), val_preds.max())\nplt.plot([min_val, max_val], [min_val, max_val], 'k--', lw=1)\n\n# Set labels and title\nplt.xlabel('Actual Values')\nplt.ylabel('Predicted Values')\nplt.title('Predicted vs Actual Values (Hexbin with Log Scale)')\n\n# Add grid lines\nplt.grid(True, linestyle='--', alpha=0.65)\n\n# Set the same limits for both axes\nplt.xlim(min_val, max_val)\nplt.ylim(min_val, max_val)\n\n# Make the plot square\nplt.gca().set_aspect('equal', adjustable='box')\n\nplt.tight_layout()\nplt.show()\n\n# Print the range of counts in the hexbins\nprint(f\"Min non-zero count in hexbins: {min_count}\")\nprint(f\"Max count in hexbins: {max_count}\")\n\n\n\n\n\n\n\n\nMin non-zero count in hexbins: 1.0\nMax count in hexbins: 157.0\n\n\n\npath_model = Path('./models')\nlearn.export(path_model / '0.pkl')",
    "crumbs": [
      "example",
      "history_runpod",
      "Fastai BW data augmentation"
    ]
  },
  {
    "objectID": "example/history_runpod/fastai-bw-augment-03-10-2024.html#inference",
    "href": "example/history_runpod/fastai-bw-augment-03-10-2024.html#inference",
    "title": "Fastai BW data augmentation",
    "section": "Inference",
    "text": "Inference\n\nossl_source = Path('../../_data/ossl-tfm/img')\nlearn.predict(ossl_source / '0a0a0c647671fd3030cc13ba5432eb88.png')\n\n\n\n\n\n\n\n\n((0.5229991674423218,), tensor([0.5230]), tensor([0.5230]))\n\n\n\ndf[df['fname'] == '0a0a0c647671fd3030cc13ba5432eb88.png']\n\n\n\n\n\n\n\n\nfname\nkex\n\n\n\n\n28867\n0a0a0c647671fd3030cc13ba5432eb88.png\n0.525379\n\n\n\n\n\n\n\n\nnp.exp(3) - 1\n\n19.085536923187668",
    "crumbs": [
      "example",
      "history_runpod",
      "Fastai BW data augmentation"
    ]
  },
  {
    "objectID": "example/history_runpod/fastai-bw-augment-03-10-2024.html#experiments",
    "href": "example/history_runpod/fastai-bw-augment-03-10-2024.html#experiments",
    "title": "Fastai BW data augmentation",
    "section": "Experiments:",
    "text": "Experiments:\nColor scale: viridis | Discretization: percentiles = [i for i in range(60, 100)]\n\n\n\n\n\n\n\n\n\n\n\n\n\nModel\nImage Size\nLearning Rate\nEpochs\nR2 Score\nTime per Epoch\nFinetuning\nwith axis ticks\n\n\n\n\nResNet-18\n100\n1e-3\n10\n0.648\n05:12\nNo\nYes\n\n\nResNet-18\n224\n2e-3\n10\n0.69\n07:30\nNo\nYes\n\n\nResNet-18\n750 (original size)\n1e-3\n10\n0.71\n36:00\nNo\nYes\n\n\nResNet-18\n224\n2e-3\n20\n0.704\n07:30\nNo\nYes\n\n\nResNet-18\n224\n2e-3\n10\n0.71\n07:00\nNo\nNo\n\n\n\nDiscretization: percentiles = [i for i in range(20, 100)]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nModel\nImage Size\nLearning Rate\nEpochs\nR2 Score\nTime per Epoch\nFinetuning\nwith axis ticks\ncolour scale\n\n\n\n\nResNet-18\n224\n2e-3\n10\n0.7\n05:12\nNo\nNo\nviridis\n\n\nResNet-18\n224\n3e-3\n10\n0.71\n05:12\nNo\nNo\njet\n\n\n\nFrom now on with axis ticks is always No.\nDiscretization: esimated on 10000 cwt power percentiles [20, 30, 40, 50, 60, 70, 80, 90, 95, 97, 99]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nModel\nImage Size\nLearning Rate\nEpochs\nR2 Score\nTime per Epoch\nFinetuning\nremark\ncolour scale\n\n\n\n\nResNet-18\n224\n2e-3\n10\n0.71\n05:12\nNo\nNone\njet\n\n\nResNet-18\n224\n2e-3\n10\n0.685\n05:12\nNo\ny range added\njet\n\n\n\nFrom now on random splitter with 10% validation and random seed 41.\nDiscretization: esimated on 10000 cwt power percentiles [20, 30, 40, 50, 60, 70, 80, 90, 95, 97, 99]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nModel\nImage Size\nLearning Rate\nEpochs\nR2 Score\nTime per Epoch\nFinetuning\nremark\ncolour scale\n\n\n\n\nResNet-18\n224\n2e-3\n10\n0.7\n05:12\nNo\nPre-train & normalize: True\njet\n\n\nResNet-18\n224\n2e-3\n10\n0.796\n08:12\nNo\nNo Pre-train\njet\n\n\nResNet-18\n224\n3e-3\n10\n0.7\n05:12\nNo\nPre-train & normalize: False\njet\n\n\nResNet-18 (id=0)\n224\n2e-3\n20\n0.829\n08:12\nNo\nNo Pre-train (try 18 epochs)\njet",
    "crumbs": [
      "example",
      "history_runpod",
      "Fastai BW data augmentation"
    ]
  }
]