"""Load data from spectral libraries."""

# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/00_loading.ipynb.

# %% auto 0
__all__ = ['fname_ossl', 'src_dir_rt', 'plot_spectra', 'SpectralData', 'DataLoader', 'OSSLLoader', 'FukushimaJumpeiLoader',
           'RingtrialLoader', 'LoaderFactory']

# %% ../nbs/00_loading.ipynb 2
from abc import ABC, abstractmethod
from dataclasses import dataclass
import fastcore.all as fc
from fastcore.basics import patch
import pandas as pd
from pathlib import Path
from sklearn.preprocessing import LabelEncoder
import numpy as np
import matplotlib.pyplot as plt
import re
from typing import List
from .preprocessing import SNV

# %% ../nbs/00_loading.ipynb 3
def plot_spectra(data, 
                 var: str = 'X',
                 n_spectra=None,  # Number of random spectra to plot (None for all)
                 snv: bool = False, # Apply SNV normalization
                 xlabel='Wavenumber ($cm^{-1}$)', ylabel='Absorbance',
                 figsize=(12, 4), locator=250, lw=1,
                 color='steelblue', alpha=0.1,  # Single color with opacity
                 tight_layout=False):
    
    fig, ax = plt.subplots(figsize=figsize)
    
    X_data = getattr(data, var)
    if n_spectra is not None and n_spectra < data.X.shape[0]:
        # Select n random spectra
        indices = np.random.choice(X_data.shape[0], n_spectra, replace=False)
        X_subset = X_data[indices]
    else:
        X_subset = X_data
    
    
    X_subset = SNV().fit_transform(X_subset) if snv else X_subset
    
    for i in range(X_subset.shape[0]):
        ax.plot(data.X_names, X_subset[i], lw=lw, color=color, alpha=alpha)
    
    ax.xaxis.set_major_locator(plt.MultipleLocator(locator))
    ax.grid(True)
    ax.invert_xaxis()
    ax.set_xlabel(xlabel)
    ax.set_ylabel(ylabel)
    
    if tight_layout:
        plt.tight_layout()
    
    return fig, ax

# %% ../nbs/00_loading.ipynb 4
@dataclass
class SpectralData:
    X: np.ndarray
    X_names: np.ndarray
    y: np.ndarray
    y_names: np.ndarray
    sample_indices: np.ndarray
    dataset_names: np.ndarray
    dataset_labels: np.ndarray

# %% ../nbs/00_loading.ipynb 5
fname_ossl = Path.home() / '.lssm/data/ossl/ossl_all_L0_v1.2.csv.gz'

# %% ../nbs/00_loading.ipynb 6
class DataLoader(ABC):
    "Abstract class for data loading."
    @abstractmethod
    def load_data(self, 
                  analytes: str|list, # Analyte(s) of interest
                  ) -> tuple: # Return a tuple of the form (X, y, X_names, smp_idx, ds_name, ds_label)
        """Load data and return (X, y, X_names, smp_idx, ds_name, ds_label)."""
        pass

# %% ../nbs/00_loading.ipynb 9
class OSSLLoader(DataLoader):
    "Load OSSL data and filter it by spectra type and analytes of interest."
    DTYPE_DICT = {
        'id.layer_local_c': 'object',
        'id.location_olc_txt': 'object',
        'id.dataset.site_ascii_txt': 'object',
        'id.scan_local_c': 'object',
        'layer.texture_usda_txt': 'object',
        'pedon.taxa_usda_txt': 'object',
        'horizon.designation_usda_txt': 'object',
        'location.country_iso.3166_txt': 'object',
        'surveyor.address_utf8_txt': 'object',
        'efferv_usda.a479_class': 'object',
        'scan.mir.date.begin_iso.8601_yyyy.mm.dd': 'object',
        'scan.mir.date.end_iso.8601_yyyy.mm.dd': 'object',
        'scan.mir.model.name_utf8_txt': 'object',
        'scan.mir.model.code_any_txt': 'object',
        'scan.mir.method.optics_any_txt': 'object',
        'scan.mir.method.preparation_any_txt': 'object',
        'scan.mir.license.title_ascii_txt': 'object',
        'scan.mir.license.address_idn_url': 'object',
        'scan.mir.doi_idf_url': 'object',
        'scan.mir.contact.name_utf8_txt': 'object',
        'scan.mir.contact.email_ietf_txt': 'object',
        'scan.visnir.date.begin_iso.8601_yyyy.mm.dd': 'object',
        'scan.visnir.date.end_iso.8601_yyyy.mm.dd': 'object',
        'scan.visnir.model.name_utf8_txt': 'object',
        'scan.visnir.model.code_any_txt': 'object',
        'scan.visnir.method.optics_any_txt': 'object',
        'scan.visnir.method.preparation_any_txt': 'object',
        'scan.visnir.license.title_ascii_txt': 'object',
        'scan.visnir.license.address_idn_url': 'object',
        'scan.visnir.doi_idf_url': 'object',
        'scan.visnir.contact.name_utf8_txt': 'object',
        'scan.visnir.contact.email_ietf_txt': 'object'
    }
    def __init__(self, 
                 src: Path = Path.home() / '.lssm/data/ossl/ossl_all_L0_v1.2.csv.gz', # Data source file name
                 spectra_type: str='visnir', # Spectra type
                 cfgs: dict=None): # Spectra type configuration
        self.src = src
        self.spectra_type = spectra_type
        self.df = None
        self.ds_name_encoder = LabelEncoder()
        self.cfgs = cfgs or {
            'visnir': {'ref_col': 'scan_visnir.1500_ref', 'range': [400, 2500]},
            'mir': {'ref_col': 'scan_mir.1500_abs', 'range': [650, 4000]}
        }

    def _get_spectra(self, 
                    spectra_type: str # Spectra type
                    ):
        cols_ref = [name for name in self.df.columns if f'scan_{spectra_type}.' in name]
        X = self.df[cols_ref].values
        X_names = self._get_wavelengths(spectra_type)
        lower_limit, upper_limit = self.cfgs[spectra_type]['range']
        idxs = np.where((X_names >= lower_limit) & (X_names <= upper_limit))[0]
        return X[:, idxs], X_names[idxs]

    def _encode_dataset_names(self):
        return self.ds_name_encoder.fit_transform(self.df['dataset.code_ascii_txt'])

    def _get_wavelengths(self, 
                            spectra_type: str # Spectra type
                            ):
        pattern = r"scan_{}\.(\d+)_".format(spectra_type)
        return np.array([int(re.search(pattern, name).group(1)) for name in self.df.columns
                            if re.search(pattern, name)])
        
    def load_data(self, 
                  analytes: str|list, # Analyte(s) of interest
                  ) -> tuple: # Return a tuple of the form (X, y, X_names, smp_idx, ds_name, ds_label)
        "Load OSSL data and filter it by spectra type and analytes of interest."
        print(f'Loading data from {self.src} ...')
        self.df = pd.read_csv(self.src, dtype=self.DTYPE_DICT,
                              compression='infer', low_memory=True)

        analytes = [analytes] if isinstance(analytes, str) else analytes
        y_names = np.array(analytes)
        subset = analytes + [self.cfgs[self.spectra_type]['ref_col']]
        self.df = self.df.dropna(subset=subset, how='any')

        X, X_names = self._get_spectra(self.spectra_type)
        y = self.df[analytes].values
        smp_indices = self.df['id.layer_uuid_txt'].values
        ds_name = self._encode_dataset_names()
        
        return SpectralData(
            X=X,
            X_names=X_names,
            y=y,
            y_names=y_names,
            sample_indices=smp_indices,
            dataset_names=ds_name,
            dataset_labels=self.ds_name_encoder.classes_
        )

        # return X, y, X_names, smp_idx, ds_name, self.ds_name_encoder.classes_, np.array(analytes)

# %% ../nbs/00_loading.ipynb 14
class FukushimaJumpeiLoader(DataLoader):
    "Load Fukushima (Jumpei) data."
    fname = 'Fukushimaall_Average.csv'
    analytes = ['soil_total_Cs134',
                'soil_total_Cs137',
                'soil_ex_Cs137',
                'exCs137_totalCs137',
                'soil_water_soluble_K2O',
                'soil_ex_K2O',
                'TF_plant_totalCs137',
                'TF_plant_exCs137',
                'soil_pH',
                'soil_C',
                'soil_N',
                'soil_CN_ratio',
                'soil_CEC',
                'soil_MgO',
                'soil_CaO',
                'soil_P_absorption_coefficient',
                'avaiable_Pi',
                'course_sand',
                'fine_sand',
                'silt',
                'clay']
    
    def __init__(self, 
                 src: Path|str, # Source directory
                 ): 
        self.src = src if isinstance(src, Path) else Path(src)
        self.ds_name_encoder = LabelEncoder()
        
    def load_mir(self, df):
        wn_cols = [col for col in df.columns if col.isdigit()]
        return df[wn_cols].values, np.array([int(col) for col in wn_cols])
    
    def load_wetchem(self):
        fname = self.src / self.fname_wetchem
        return pd.read_csv(fname)
    
    def separate_spectra_and_others(self, df_merged: pd.DataFrame) -> tuple:
        "Separate the merged dataframe into spectral data and metadata."
        spectral_cols = [col for col in df_merged.columns if col.isdigit()]
        metadata_cols = [col for col in df_merged.columns if not col.isdigit()]
        df_spectra = df_merged[spectral_cols]
        df_others = df_merged[metadata_cols]
        return df_spectra, df_others
        
    def make_idx(self, df: pd.DataFrame) -> pd.DataFrame:
        "Make a unique index for the samples."
        return (df.iloc[:, :3].astype(str).apply('-'.join, axis=1))
    
    def _encode_dataset_names(self, df: pd.DataFrame):
        return self.ds_name_encoder.fit_transform(df)

    def load_data(self,
                  analytes: str|list=None, # Analytes of interest
                  ) -> tuple:
        "Load Ringtrial data and return SpectralData."
        df = pd.read_csv(self.src / self.fname, low_memory=False)
        X, X_names = self.load_mir(df)
    
        if analytes is None: analytes = self.analytes
    
        # y = df[analytes].values
        y = df[analytes].apply(pd.to_numeric, errors='coerce').values
        y_names = np.array(analytes)
        smp_indices = self.make_idx(df).values
        ds_name = self._encode_dataset_names(pd.Series(['fukushima-jumpei'] * len(df), index=df.index))
        
        return SpectralData(
            X=X,
            X_names=X_names,
            y=y,
            y_names=y_names,
            sample_indices=smp_indices,
            dataset_names=ds_name,
            dataset_labels=self.ds_name_encoder.classes_
        )

# %% ../nbs/00_loading.ipynb 17
src_dir_rt = Path.home() / 'pro/data/woodwell-ringtrial/drive-download-20231013T123706Z-001'

# %% ../nbs/00_loading.ipynb 18
class RingtrialLoader(DataLoader):
    "Load Ringtrial data."
    fname_mir = 'RT_STD_allMIRspectra_raw.csv'
    fname_wetchem = 'RT_wetchem_soildata.csv'
    def __init__(self, 
                 src: Path|str = src_dir_rt, # Source directory
                #  target: str = 'soil_ex_K2O', # Target analyte
                 ): # Spectra type configuration
        self.src = src if isinstance(src, Path) else Path(src)
        self.ds_name_encoder = LabelEncoder()
        
    def load_mir(self):
        fname = self.src / self.fname_mir
        return pd.read_csv(fname)
    
    def load_wetchem(self):
        fname = self.src / self.fname_wetchem
        return pd.read_csv(fname)
    
    def separate_spectra_and_others(self, df_merged: pd.DataFrame) -> tuple:
        "Separate the merged dataframe into spectral data and metadata."
        spectral_cols = [col for col in df_merged.columns if col.isdigit()]
        metadata_cols = [col for col in df_merged.columns if not col.isdigit()]
        df_spectra = df_merged[spectral_cols]
        df_others = df_merged[metadata_cols]
        return df_spectra, df_others
        
    def make_idx(self, df: pd.DataFrame) -> pd.DataFrame:
        "Make a unique index for the samples."
        return (df['organization'] + '-' + df['sample_id']).str.lower().str.replace('_', '-')
    
    def _encode_dataset_names(self, df: pd.DataFrame):
        return self.ds_name_encoder.fit_transform(df)

    def load_data(self,
                  analytes: str|list='potassium_cmolkg', # Analytes of interest
                  ) -> tuple:
        "Load Ringtrial data and return (X, y, X_names, smp_idx, ds_name, ds_label)."
        df_merged = pd.merge(self.load_mir(), 
                            self.load_wetchem().rename(columns={'\tsample_id': 'sample_id'}),
                            on='sample_id', how='inner')
        
        df_spectra, df_others = self.separate_spectra_and_others(df_merged)
        
        X = df_spectra.values
        analytes = [analytes] if isinstance(analytes, str) else analytes
        y = df_others[analytes].values
        y_names = np.array(analytes)
        X_names = df_spectra.columns.astype(int).values
        smp_indices = self.make_idx(df_others).values
        ds_name = self._encode_dataset_names(df_others['organization'])
        
        return SpectralData(
            X=X,
            X_names=X_names,
            y=y,
            y_names=y_names,
            sample_indices=smp_indices,
            dataset_names=ds_name,
            dataset_labels=self.ds_name_encoder.classes_
        )

# %% ../nbs/00_loading.ipynb 21
class LoaderFactory:
    @staticmethod
    def get_loader(src: Path, dataset: str, **kwargs) -> DataLoader:
        if dataset == 'ossl':
            return OSSLLoader(src, **kwargs)
        elif dataset == 'ringtrial':
            return RingtrialLoader(src)
        elif dataset == 'fk-jumpei':
            return FukushimaJumpeiLoader(src)
        else:
            raise ValueError(f"Dataset {dataset} not supported yet ...")
